# ğŸš€ SamPredictor GPU-Resident Refactoring

## ğŸ“‹ RÃ©sumÃ© des changements

La mÃ©thode `SamPredictor.predict()` a Ã©tÃ© refactorisÃ©e pour Ã©liminer les transferts GPUâ†’CPU inutiles qui causaient des spikes de latence.

## âš¡ Avant/AprÃ¨s

### âŒ Avant (version originale)
```python
# ForÃ§ait 3 transferts GPUâ†’CPU Ã  chaque prÃ©diction
masks_np = masks[0].detach().cpu().numpy()
iou_predictions_np = iou_predictions[0].detach().cpu().numpy()
low_res_masks_np = low_res_masks[0].detach().cpu().numpy()
return masks_np, iou_predictions_np, low_res_masks_np
```

### âœ… AprÃ¨s (version optimisÃ©e)
```python
# Mode GPU-resident par dÃ©faut (as_numpy=False)
masks, iou, low_res = predictor.predict()  # Retourne des tensors CUDA

# Mode compatibilitÃ© (as_numpy=True) 
masks, iou, low_res = predictor.predict(as_numpy=True)  # Retourne des numpy arrays
```

## ğŸ¯ Utilisation

### Mode GPU-resident (recommandÃ©)
```python
# Nouveau comportement par dÃ©faut - garde tout sur GPU
masks, iou_predictions, low_res_masks = predictor.predict(
    point_coords=coords,
    point_labels=labels,
    # as_numpy=False par dÃ©faut
)

# Les rÃ©sultats sont des torch.Tensor sur CUDA
assert isinstance(masks, torch.Tensor)
assert masks.is_cuda  # Si GPU disponible
```

### Mode compatibilitÃ© (legacy)
```python
# Pour la rÃ©trocompatibilitÃ© avec le code existant
masks, iou_predictions, low_res_masks = predictor.predict(
    point_coords=coords,
    point_labels=labels,
    as_numpy=True  # Force la conversion en numpy
)

# Les rÃ©sultats sont des np.ndarray
assert isinstance(masks, np.ndarray)
```

## ğŸ“Š Monitoring KPI

L'instrumentation KPI log automatiquement:
```json
{
    "ts": 1698765432.0,
    "event": "sam_predict_output", 
    "as_numpy": 0,  // 0=GPU-resident, 1=numpy mode
    "mask_device": "cuda:0",
    "iou_device": "cuda:0", 
    "low_device": "cuda:0"
}
```

## ğŸ§­ Migration pour les modules existants

### 1. Orchestrator (temporaire)
```python
# Migration temporaire - ajouter as_numpy=True
masks, iou, low = predictor.predict(..., as_numpy=True)
```

### 2. Modules optimisÃ©s (recommandÃ©)
```python
# Garder sur GPU jusqu'au ResultPacket final
masks, iou, low = predictor.predict(...)  # as_numpy=False par dÃ©faut
# ... traitement sur GPU ...
# Conversion finale seulement si nÃ©cessaire
final_result = masks.detach().cpu().numpy() if need_numpy else masks
```

## âš ï¸ Gestion d'erreurs

Si vous voyez `TypeError: Object of type Tensor is not JSON serializable`:
- C'est normal: le code s'attend encore Ã  du numpy
- Solution temporaire: ajoutez `as_numpy=True`
- Solution permanente: refactorisez le module pour accepter les tensors

## ğŸ§ª Tests

Les tests sont dans `tests/test_sam_predictor_gpu_resident.py`:
```bash
# Lancer les tests
cd ultramotion-igt-inference
python -m pytest tests/test_sam_predictor_gpu_resident.py -v
```

## ğŸ“ˆ BÃ©nÃ©fices attendus

1. **ğŸš€ Latence rÃ©duite**: Plus de synchronisation GPUâ†’CPU forcÃ©e
2. **ğŸ“Š Pics Ã©liminÃ©s**: Plus de spikes "GPU Copy" dans les mÃ©triques  
3. **âš¡ Pipeline fluide**: SAM reste entiÃ¨rement sur GPU
4. **ğŸ”„ CompatibilitÃ©**: Code existant continue de fonctionner avec `as_numpy=True`

## ğŸ”— Ã‰tapes suivantes

1. âœ… **Refactoring SamPredictor** (cette Ã©tape - TERMINÃ‰)
2. â³ **Refactoring Orchestrator**: Modifier pour accepter les tensors
3. â³ **Tests d'intÃ©gration**: Valider le pipeline complet
4. â³ **Monitoring**: VÃ©rifier les KPI en production

## ğŸ”„ Rollback

En cas de problÃ¨me:
```python
# Forcer le mode legacy en changeant la valeur par dÃ©faut
def predict(..., as_numpy: bool = True):  # Temporaire
```

Ou revenir Ã  la version prÃ©cÃ©dente du fichier.