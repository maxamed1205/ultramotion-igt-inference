#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Diagnostic des pics RX‚ÜíPROC √† 2ms malgr√© l'optimisation Event
Objectif : Identifier POURQUOI certaines frames ont encore 1-2ms de latence
"""

import re
from collections import defaultdict

# Pattern pour extraire timestamp et frame_id des logs
RX_PATTERN = re.compile(
    r'\[(?P<ts>[\d\-: ,]+)\].*\[RX-SIM\] Generated frame #(?P<frame_id>\d+)'
)
PROC_PATTERN = re.compile(
    r'\[(?P<ts>[\d\-: ,]+)\].*\[PROC-SIM\] Processing frame #(?P<frame_id>\d+)'
)

def parse_timestamp(ts_str):
    """Convertit '[2025-10-29 09:11:47,944]' en millisecondes"""
    parts = ts_str.replace('[', '').replace(']', '').strip()
    time_part = parts.split(' ')[-1]  # '09:11:47,944'
    h, m, s = time_part.split(':')
    sec, ms = s.split(',')
    total_ms = int(h) * 3600000 + int(m) * 60000 + int(sec) * 1000 + int(ms)
    return total_ms

def analyze_spikes(log_path="logs/pipeline.log"):
    """Analyse d√©taill√©e des pics de latence RX‚ÜíPROC"""
    rx_frames = {}
    proc_frames = {}
    
    with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            rx_match = RX_PATTERN.search(line)
            if rx_match:
                frame_id = int(rx_match.group('frame_id'))
                ts_ms = parse_timestamp(rx_match.group('ts'))
                rx_frames[frame_id] = ts_ms
            
            proc_match = PROC_PATTERN.search(line)
            if proc_match:
                frame_id = int(proc_match.group('frame_id'))
                ts_ms = parse_timestamp(proc_match.group('ts'))
                proc_frames[frame_id] = ts_ms
    
    # Calculer les latences et identifier les patterns
    latencies = []
    spike_frames = []  # Frames avec latence >= 1ms
    perfect_frames = []  # Frames avec latence = 0ms
    
    for frame_id in sorted(rx_frames.keys()):
        if frame_id in proc_frames:
            latency_ms = proc_frames[frame_id] - rx_frames[frame_id]
            latencies.append((frame_id, latency_ms))
            
            if latency_ms >= 1:
                spike_frames.append(frame_id)
            else:
                perfect_frames.append(frame_id)
    
    if not latencies:
        print("‚ùå Aucune donn√©e trouv√©e dans les logs")
        return
    
    print("=" * 80)
    print("üî¨ DIAGNOSTIC DES PICS RX‚ÜíPROC (malgr√© threading.Event)")
    print("=" * 80)
    print()
    
    # 1. Vue d'ensemble
    total = len(latencies)
    spikes = len(spike_frames)
    perfect = len(perfect_frames)
    
    print(f"üìä VUE D'ENSEMBLE ({total} frames analys√©es) :")
    print(f"   ‚úÖ Frames instantan√©es (0ms)    : {perfect:3d} ({perfect/total*100:5.1f}%)")
    print(f"   ‚ö†Ô∏è  Frames avec latence (‚â•1ms)  : {spikes:3d} ({spikes/total*100:5.1f}%)")
    print()
    
    # 2. Distribution d√©taill√©e
    distribution = defaultdict(int)
    for _, lat in latencies:
        distribution[lat] += 1
    
    print("üìà DISTRIBUTION DES LATENCES :")
    for latency in sorted(distribution.keys()):
        count = distribution[latency]
        percentage = (count / total) * 100
        bar = "‚ñà" * int(percentage / 2)
        marker = "‚úÖ" if latency == 0 else "‚ö†Ô∏è " if latency >= 2 else "‚ö°"
        print(f"   {marker} {latency:2.0f} ms : {count:3d} frames ({percentage:5.1f}%) {bar}")
    print()
    
    # 3. Analyse des patterns temporels
    print("=" * 80)
    print("üîç ANALYSE DES PATTERNS (pics >= 1ms)")
    print("=" * 80)
    print()
    
    if not spike_frames:
        print("‚úÖ Aucun pic d√©tect√© - performance parfaite !")
        return
    
    # Espacements entre pics
    spike_intervals = []
    for i in range(1, len(spike_frames)):
        interval = spike_frames[i] - spike_frames[i-1]
        spike_intervals.append(interval)
    
    if spike_intervals:
        print(f"üìè ESPACEMENTS ENTRE PICS :")
        print(f"   Min     : {min(spike_intervals):3d} frames")
        print(f"   Max     : {max(spike_intervals):3d} frames")
        print(f"   Moyenne : {sum(spike_intervals)/len(spike_intervals):5.1f} frames")
        print()
        
        # Distribution des intervalles
        interval_dist = defaultdict(int)
        for interval in spike_intervals:
            # Grouper par buckets
            if interval <= 5:
                bucket = interval
            elif interval <= 10:
                bucket = 10
            elif interval <= 20:
                bucket = 20
            elif interval <= 50:
                bucket = 50
            else:
                bucket = 100
            interval_dist[bucket] += 1
        
        print("   Distribution des intervalles :")
        for bucket in sorted(interval_dist.keys()):
            count = interval_dist[bucket]
            label = f"{bucket}" if bucket <= 5 else f"~{bucket}"
            print(f"      {label:>3} frames : {count:2d} occurrences")
        print()
    
    # 4. Liste des frames avec pics (premi√®res et derni√®res)
    print("üéØ FRAMES AVEC PICS (d√©tails) :")
    print()
    print("   Premi√®res frames avec latence :")
    for frame_id in spike_frames[:10]:
        lat = proc_frames[frame_id] - rx_frames[frame_id]
        print(f"      Frame #{frame_id:03d} : {lat:.0f} ms")
    
    if len(spike_frames) > 20:
        print("      [...]")
        print("   Derni√®res frames avec latence :")
        for frame_id in spike_frames[-10:]:
            lat = proc_frames[frame_id] - rx_frames[frame_id]
            print(f"      Frame #{frame_id:03d} : {lat:.0f} ms")
    elif len(spike_frames) > 10:
        print("   Autres frames avec latence :")
        for frame_id in spike_frames[10:]:
            lat = proc_frames[frame_id] - rx_frames[frame_id]
            print(f"      Frame #{frame_id:03d} : {lat:.0f} ms")
    print()
    
    # 5. Hypoth√®ses sur les causes
    print("=" * 80)
    print("üí° HYPOTH√àSES SUR LES CAUSES DES PICS")
    print("=" * 80)
    print()
    
    avg_interval = sum(spike_intervals) / len(spike_intervals) if spike_intervals else 0
    
    print("üî¨ ANALYSE :")
    print()
    
    # Hypoth√®se 1 : GIL contention
    if spikes / total < 0.10:  # Moins de 10% de pics
        print("‚úÖ Hypoth√®se #1 : GIL (Global Interpreter Lock)")
        print("   ‚Üí Les pics sont RARES (<10%) ‚Üí Normal pour Python threading")
        print("   ‚Üí Le GIL peut bloquer PROC pendant 0-2ms quand :")
        print("      ‚Ä¢ RX thread d√©tient le GIL (cr√©ation numpy array)")
        print("      ‚Ä¢ Async logging thread √©crit sur disque")
        print("      ‚Ä¢ Garbage collector s'ex√©cute")
        print("   ‚Üí Solution : ACCEPTER ces pics (overhead Python incompressible)")
        print()
    
    # Hypoth√®se 2 : Batch processing
    if avg_interval > 10:
        print("‚ö†Ô∏è  Hypoth√®se #2 : Windows Scheduler (time slicing)")
        print(f"   ‚Üí Pics espac√©s en moyenne de {avg_interval:.1f} frames")
        print("   ‚Üí Windows alloue du CPU aux autres threads tous les ~10-15ms")
        print("   ‚Üí Quand PROC perd son time slice, wait() peut durer 1-2ms")
        print("   ‚Üí Solution :")
        print("      ‚Ä¢ Option A : Augmenter priorit√© thread PROC (THREAD_PRIORITY_ABOVE_NORMAL)")
        print("      ‚Ä¢ Option B : Accepter ces pics (scheduler OS incompressible)")
        print()
    
    # Hypoth√®se 3 : I/O async logging
    io_frames = [fid for fid in spike_frames if fid % 10 == 0]
    if len(io_frames) / len(spike_frames) > 0.3:
        print("‚ö†Ô∏è  Hypoth√®se #3 : Async Logging I/O")
        print(f"   ‚Üí {len(io_frames)} pics ({len(io_frames)/spikes*100:.0f}%) proches de frames multiples de 10")
        print("   ‚Üí Le QueueListener flush sur disque peut bloquer le GIL")
        print("   ‚Üí Solution : Augmenter buffer size du QueueHandler")
        print()
    
    # Hypoth√®se 4 : Clear tardif
    consecutive_spikes = 0
    for i in range(1, len(spike_frames)):
        if spike_frames[i] - spike_frames[i-1] == 1:
            consecutive_spikes += 1
    
    if consecutive_spikes > 0:
        print("‚ùå Hypoth√®se #4 : frame_ready.clear() manquant ou tardif")
        print(f"   ‚Üí {consecutive_spikes} paires de frames cons√©cutives avec pics")
        print("   ‚Üí Possible race condition : wait() retourne mais clear() pas encore appel√©")
        print("   ‚Üí Solution : V√©rifier que clear() est IMM√âDIATEMENT apr√®s wait()")
        print()
    
    # 6. Conclusion
    print("=" * 80)
    print("üìã CONCLUSION")
    print("=" * 80)
    print()
    
    if spikes / total <= 0.08 and consecutive_spikes == 0:
        print("‚úÖ DIAGNOSTIC : Performance EXCELLENTE")
        print()
        print("   Les pics observ√©s (~5-8%) sont NORMAUX pour Python threading :")
        print("   ‚Ä¢ GIL switching : 0.1-0.5ms overhead incompressible")
        print("   ‚Ä¢ OS scheduler   : Windows time slicing ~15ms")
        print("   ‚Ä¢ Async I/O      : QueueListener flush p√©riodique")
        print()
        print("   üéØ RECOMMANDATION : AUCUNE action n√©cessaire")
        print("      ‚Üí L'optimisation Event a atteint son maximum (~92% √† 0ms)")
        print("      ‚Üí Les 8% restants sont l'overhead Python/OS incompressible")
        print()
    elif consecutive_spikes > spikes * 0.2:
        print("‚ö†Ô∏è  DIAGNOSTIC : Possible probl√®me de synchronisation")
        print()
        print("   üéØ RECOMMANDATION : V√©rifier le code :")
        print("      1. clear() est-il appel√© IMM√âDIATEMENT apr√®s wait() ?")
        print("      2. Y a-t-il du code entre wait() et receive_image() ?")
        print("      3. Le timeout de wait() est-il trop long (>0.01s) ?")
        print()
    else:
        print("‚ö†Ô∏è  DIAGNOSTIC : Pics dus au scheduler OS + GIL")
        print()
        print("   üéØ RECOMMANDATION : Augmenter priorit√© thread PROC")
        print("      ‚Üí Ajouter dans simulate_processing() :")
        print("         import win32process, win32api")
        print("         handle = win32api.GetCurrentThread()")
        print("         win32process.SetThreadPriority(handle, win32process.THREAD_PRIORITY_ABOVE_NORMAL)")
        print()

if __name__ == "__main__":
    analyze_spikes()
