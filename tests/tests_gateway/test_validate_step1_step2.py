"""
Test de Validation : Ã‰tapes 1 et 2 de la Pipeline
=================================================

Ce test valide isolÃ©ment les 2 premiÃ¨res Ã©tapes :

Ã‰tape 1: read_dataset_images() â†’ RawFrame (numpy)
  âœ… Lit 213 JPEGs du dataset
  âœ… Convertit en numpy array (512x512 uint8 grayscale)
  âœ… Appelle gateway._inject_frame()
  âœ… Appelle gateway.stats.mark_rx() pour KPI
  âœ… Logs "RX frame #N" Ã  ~100 Hz

Ã‰tape 2: prepare_frame_for_gpu() â†’ GpuFrame (torch.Tensor CUDA)
  âœ… Convertit numpy â†’ torch.Tensor
  âœ… Transfert CPU â†’ GPU (asynchrone)
  âœ… Normalisation [0,255] â†’ [0,1]
  âœ… copy_async sur stream CUDA
  âœ… VÃ©rifie tensor.device == 'cuda'

ScÃ©nario de test :
- Lit les 10 premiÃ¨res images du dataset
- Pour chaque image :
  1. CrÃ©e RawFrame (simule read_dataset_images)
  2. TransfÃ¨re vers GPU via prepare_frame_for_gpu()
  3. VÃ©rifie shape, dtype, device, valeurs
  4. Mesure latence CPUâ†’GPU

Sortie attendue :
- 10 frames traitÃ©es avec succÃ¨s
- Latence CPUâ†’GPU : < 5ms par frame
- Tensors sur GPU avec bonnes dimensions
- Aucune erreur CUDA
"""

import os
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["LOG_MODE"] = "dev"

import sys
import time
import numpy as np
from pathlib import Path
from PIL import Image
import glob

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  PrÃ©paration du contexte
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = Path(__file__).resolve().parent.parent.parent
SRC = str(ROOT / "src")
if SRC not in sys.path:
    sys.path.insert(0, SRC)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Imports
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from core.types import RawFrame, FrameMeta, Pose
from core.preprocessing.cpu_to_gpu import (
    init_transfer_runtime,
    prepare_frame_for_gpu,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Setup Logging Asynchrone (pour KPI)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import logging
import logging.config
import yaml

def setup_async_logging():
    """Configure le systÃ¨me de logging asynchrone pour Ã©crire dans kpi.log."""
    logging_config_path = ROOT / "src" / "config" / "logging.yaml"
    
    if logging_config_path.exists():
        with open(logging_config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        
        # Setup via async_logging module
        from core.monitoring import async_logging
        async_logging.setup_async_logging(yaml_cfg=config)
        async_logging.start_health_monitor()
    else:
        # Fallback: basic config
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        )

LOG = logging.getLogger("test.validation")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATASET_PATH = Path(r"C:\Users\maxam\Desktop\TM\dataset\HUMERUS LATERAL XG SW_cropped\JPEGImages\Video_001")
TARGET_SIZE = (512, 512)
NUM_FRAMES_TO_TEST = None  # None = toutes les images (213), sinon spÃ©cifier un nombre

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Test Principal
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def test_step1_step2():
    """Valide Ã‰tape 1 (load images) + Ã‰tape 2 (CPUâ†’GPU transfer)."""
    
    # Setup async logging AVANT le test
    setup_async_logging()
    
    LOG.info("=" * 70)
    LOG.info("TEST VALIDATION : Ã‰tape 1 + Ã‰tape 2")
    LOG.info("=" * 70)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 1 : Charger les images du dataset
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    LOG.info("\n[Ã‰TAPE 1] Chargement des images du dataset...")
    
    if not DATASET_PATH.exists():
        LOG.error(f"âŒ Dataset path does not exist: {DATASET_PATH}")
        return False
    
    # Lister les fichiers JPEG
    image_files = sorted(glob.glob(str(DATASET_PATH / "*.jpg")))
    
    if not image_files:
        LOG.error(f"âŒ No JPEG images found in {DATASET_PATH}")
        return False
    
    LOG.info(f"âœ… Found {len(image_files)} images")
    LOG.info(f"   First: {Path(image_files[0]).name}")
    LOG.info(f"   Last: {Path(image_files[-1]).name}")
    
    # Limiter au nombre de frames Ã  tester (ou prendre toutes si None)
    if NUM_FRAMES_TO_TEST is not None:
        image_files = image_files[:NUM_FRAMES_TO_TEST]
        LOG.info(f"   Testing with first {len(image_files)} images")
    else:
        LOG.info(f"   Testing with ALL {len(image_files)} images")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 2 : Initialiser le runtime GPU
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    LOG.info("\n[Ã‰TAPE 2] Initialisation du runtime GPU...")
    
    try:
        import torch
        if not torch.cuda.is_available():
            LOG.warning("âš ï¸ CUDA not available, using CPU (slower)")
            device = "cpu"
        else:
            device = "cuda"
            LOG.info(f"âœ… CUDA available: {torch.cuda.get_device_name(0)}")
    except ImportError:
        LOG.error("âŒ PyTorch not installed")
        return False
    
    # Initialiser le runtime de transfert (stream + pinned buffers)
    try:
        init_transfer_runtime(device=device, pool_size=2, shape_hint=(512, 512))
        LOG.info(f"âœ… Transfer runtime initialized (device={device})")
    except Exception as e:
        LOG.exception(f"âŒ Failed to initialize transfer runtime: {e}")
        return False
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 3 : Boucle de traitement
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    LOG.info("\n[Ã‰TAPE 3] Test CPU â†’ GPU transfer...")
    LOG.info("-" * 70)
    
    latencies = []
    success_count = 0
    
    for frame_id, img_path in enumerate(image_files):
        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 1.1 : Lire l'image (simule read_dataset_images)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            with Image.open(img_path) as pil_img:
                pil_img = pil_img.convert("L")  # Grayscale
                pil_img = pil_img.resize(TARGET_SIZE, Image.BILINEAR)
                img_np = np.array(pil_img, dtype=np.uint8)
            
            # CrÃ©er RawFrame avec mÃ©tadonnÃ©es
            pose = Pose()
            ts = time.time()
            meta = FrameMeta(
                frame_id=frame_id,
                ts=ts,
                pose=pose,
                spacing=(0.3, 0.3, 1.0),
                orientation="UN",
                coord_frame="Image",
                device_name="Dataset",
            )
            raw_frame = RawFrame(image=img_np, meta=meta)
            
            # Log seulement toutes les 20 frames pour Ã©viter spam
            if frame_id % 20 == 0 or frame_id < 3:
                LOG.info(f"  Frame #{frame_id:03d}: Loaded {Path(img_path).name} â†’ shape={img_np.shape} dtype={img_np.dtype}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 2.1 : TransfÃ©rer CPU â†’ GPU
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            t0 = time.perf_counter()
            gpu_frame = prepare_frame_for_gpu(raw_frame, device=device)
            t1 = time.perf_counter()
            latency_ms = (t1 - t0) * 1000.0
            latencies.append(latency_ms)
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 2.2 : VÃ©rifier le rÃ©sultat
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            tensor = gpu_frame.tensor
            
            # VÃ©rifications
            checks = []
            
            # Check 1: Est-ce un torch.Tensor ?
            is_tensor = hasattr(tensor, "device") and hasattr(tensor, "dtype")
            checks.append(("is_tensor", is_tensor))
            
            # Check 2: Device correct ?
            if is_tensor:
                actual_device = str(tensor.device)
                device_ok = device in actual_device
                checks.append(("device", device_ok, actual_device))
            
            # Check 3: Shape correcte ?
            expected_shape = (1, 1, 512, 512)  # [B, C, H, W]
            shape_ok = tuple(tensor.shape) == expected_shape
            checks.append(("shape", shape_ok, tuple(tensor.shape)))
            
            # Check 4: Dtype float32 ?
            dtype_ok = tensor.dtype == torch.float32
            checks.append(("dtype", dtype_ok, tensor.dtype))
            
            # Check 5: Valeurs normalisÃ©es [0, 1] ?
            if device == "cuda":
                # Copier sur CPU pour vÃ©rifier
                cpu_tensor = tensor.cpu()
            else:
                cpu_tensor = tensor
            
            min_val = cpu_tensor.min().item()
            max_val = cpu_tensor.max().item()
            normalized_ok = (0.0 <= min_val <= 1.0) and (0.0 <= max_val <= 1.0)
            checks.append(("normalized", normalized_ok, f"[{min_val:.3f}, {max_val:.3f}]"))
            
            # Check 6: MÃ©tadonnÃ©es prÃ©servÃ©es ?
            meta_ok = hasattr(gpu_frame, "meta") and gpu_frame.meta.frame_id == frame_id
            checks.append(("meta", meta_ok))
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Afficher rÃ©sultats (seulement toutes les 20 frames)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            all_ok = all(c[1] for c in checks)
            status = "âœ…" if all_ok else "âŒ"
            
            # Afficher dÃ©tails seulement pour les premiÃ¨res frames et toutes les 20
            if frame_id % 20 == 0 or frame_id < 3 or not all_ok:
                LOG.info(f"  {status} GPU Transfer: latency={latency_ms:.2f}ms")
                for check in checks:
                    if len(check) == 2:
                        name, ok = check
                        LOG.info(f"      {name}: {'âœ…' if ok else 'âŒ'}")
                    else:
                        name, ok, value = check
                        LOG.info(f"      {name}: {'âœ…' if ok else 'âŒ'} ({value})")
            
            if all_ok:
                success_count += 1
            
            # Afficher progression toutes les 50 frames
            if (frame_id + 1) % 50 == 0:
                LOG.info(f"  â³ Progress: {frame_id + 1}/{len(image_files)} frames processed...")
            
        except Exception as e:
            LOG.exception(f"  âŒ Frame #{frame_id:02d} FAILED: {e}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RÃ‰SUMÃ‰ FINAL
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    LOG.info("-" * 70)
    LOG.info("\n[RÃ‰SUMÃ‰]")
    LOG.info(f"  Frames testÃ©es : {len(image_files)}")
    LOG.info(f"  SuccÃ¨s         : {success_count}/{len(image_files)}")
    LOG.info(f"  Ã‰checs         : {len(image_files) - success_count}")
    
    if latencies:
        avg_lat = np.mean(latencies)
        min_lat = np.min(latencies)
        max_lat = np.max(latencies)
        LOG.info(f"  Latence CPUâ†’GPU:")
        LOG.info(f"    - Moyenne : {avg_lat:.2f} ms")
        LOG.info(f"    - Min     : {min_lat:.2f} ms")
        LOG.info(f"    - Max     : {max_lat:.2f} ms")
        
        # Objectif : < 5ms par frame
        if avg_lat < 5.0:
            LOG.info(f"  âœ… Objectif atteint (< 5ms)")
        else:
            LOG.warning(f"  âš ï¸ Latence Ã©levÃ©e (objectif: < 5ms)")
    
    LOG.info("\n" + "=" * 70)
    
    if success_count == len(image_files):
        LOG.info("ðŸŽ‰ TEST RÃ‰USSI : Ã‰tapes 1 et 2 validÃ©es !")
        return True
    else:
        LOG.error("âŒ TEST Ã‰CHOUÃ‰ : Certaines frames ont Ã©chouÃ©")
        return False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Point d'entrÃ©e
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    success = test_step1_step2()
    sys.exit(0 if success else 1)
