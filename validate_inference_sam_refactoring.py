#!/usr/bin/env python3
"""
Script de validation pour la refactorisation inference_sam.py
"""

import os
import sys
import time

def test_syntax_validation():
    """Test que le module peut Ãªtre parsÃ© sans erreurs de syntaxe"""
    print("ğŸ” Testing syntax validation...")
    
    import ast
    try:
        with open("src/core/inference/engine/inference_sam.py", "r") as f:
            content = f.read()
        ast.parse(content)
        print("âœ… Syntax validation passed")
        return True
    except SyntaxError as e:
        print(f"âŒ Syntax error: {e}")
        return False
    except Exception as e:
        print(f"âš ï¸  File read error: {e}")
        return False

def test_signature_and_parameters():
    """Test que la nouvelle signature est correcte"""
    print("ğŸ” Testing function signatures...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    # VÃ©rifier que as_numpy est dans la signature de run_segmentation
    if 'as_numpy: bool = False,' not in content:
        print("âŒ Parameter as_numpy not found in run_segmentation signature")
        return False
    print("âœ… Parameter as_numpy found in run_segmentation signature")
    
    # VÃ©rifier que _run_segmentation_legacy a aussi le paramÃ¨tre
    if 'def _run_segmentation_legacy(sam_model: Any, roi: np.ndarray, as_numpy: bool = False)' not in content:
        print("âŒ Parameter as_numpy not found in _run_segmentation_legacy signature")
        return False
    print("âœ… Parameter as_numpy found in _run_segmentation_legacy signature")
    
    # VÃ©rifier la documentation
    if 'as_numpy: Si True, retourne numpy array' not in content:
        print("âŒ as_numpy not documented")
        return False
    print("âœ… as_numpy parameter documented")
    
    return True

def test_gpu_resident_implementation():
    """Test que l'implÃ©mentation GPU-resident est prÃ©sente"""
    print("ğŸ” Testing GPU-resident implementation...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    required_elements = [
        "Nouveau chemin GPU-resident",
        "if not as_numpy:",
        "return mask.detach()",
        "mode",
        "mask.detach().cpu().numpy()",
    ]
    
    for element in required_elements:
        if element not in content:
            print(f"âŒ GPU-resident element not found: {element}")
            return False
    
    print("âœ… GPU-resident implementation found")
    return True

def test_conditional_processing():
    """Test que le traitement conditionnel est correct"""
    print("ğŸ” Testing conditional processing...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    # VÃ©rifier la rÃ©duction dimensionnelle conditionnelle
    if 'if as_numpy:' not in content:
        print("âŒ Conditional as_numpy processing not found")
        return False
    
    # VÃ©rifier que le GPU tensor path existe
    if 'GPU tensor' not in content and 'ne le rÃ©duit pas ici' not in content:
        print("âŒ GPU tensor processing comment not found")
        return False
    
    print("âœ… Conditional processing found")
    return True

def test_legacy_calls_updated():
    """Test que les appels Ã  _run_segmentation_legacy ont Ã©tÃ© mis Ã  jour"""
    print("ğŸ” Testing legacy calls...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    # Compter les appels avec as_numpy
    legacy_calls_with_as_numpy = content.count("_run_segmentation_legacy(sam_model, image, as_numpy")
    if legacy_calls_with_as_numpy < 2:
        print(f"âŒ Expected at least 2 updated legacy calls, found {legacy_calls_with_as_numpy}")
        return False
    
    print(f"âœ… Found {legacy_calls_with_as_numpy} updated legacy calls")
    return True

def test_mask_astype_adaptation():
    """Test que mask.astype(bool) a Ã©tÃ© adaptÃ©"""
    print("ğŸ” Testing mask.astype adaptation...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    # Il ne devrait plus y avoir de mask.astype(bool) direct
    if content.count("mask.astype(bool)") > 1:
        print("âŒ Found unconditional mask.astype(bool) calls")
        return False
    
    # VÃ©rifier qu'il y a un mode conditionnel
    if 'if as_numpy:' not in content or 'return mask.astype(bool)' not in content:
        print("âŒ Conditional mask.astype(bool) not found")
        return False
    
    # VÃ©rifier le mode GPU
    if 'mask_t = torch.from_numpy(mask).to(device)' not in content:
        print("âŒ GPU tensor conversion not found")
        return False
    
    print("âœ… mask.astype adaptation found")
    return True

def test_kpi_instrumentation():
    """Test que l'instrumentation KPI est prÃ©sente"""
    print("ğŸ” Testing KPI instrumentation...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    required_kpi_elements = [
        "safe_log_kpi",
        "format_kpi",
        '"event": "sam_mask_output"',
        '"as_numpy": int(as_numpy)',
        '"device": str(getattr(mask, "device"',
    ]
    
    for element in required_kpi_elements:
        if element not in content:
            print(f"âŒ KPI element not found: {element}")
            return False
    
    print("âœ… KPI instrumentation found")
    return True

def test_imports():
    """Test que les imports nÃ©cessaires sont prÃ©sents"""
    print("ğŸ” Testing imports...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    required_imports = [
        "import time",
    ]
    
    for imp in required_imports:
        if imp not in content:
            print(f"âŒ Missing import: {imp}")
            return False
    
    print("âœ… All required imports found")
    return True

def count_gpu_cpu_transfers():
    """Compter les transferts GPUâ†’CPU restants"""
    print("ğŸ” Counting GPUâ†’CPU transfers...")
    
    with open("src/core/inference/engine/inference_sam.py", "r") as f:
        content = f.read()
    
    lines = content.split('\n')
    gpu_cpu_transfers = [line for line in lines if '.detach().cpu().numpy()' in line]
    
    print(f"ğŸ“Š Found {len(gpu_cpu_transfers)} .detach().cpu().numpy() calls")
    
    # VÃ©rifier qu'ils sont tous conditionnels
    for i, line in enumerate(gpu_cpu_transfers):
        line_num = None
        for j, content_line in enumerate(lines):
            if content_line.strip() == line.strip():
                line_num = j + 1
                break
        
        print(f"   Line {line_num}: {line.strip()}")
    
    # Tous les transferts devraient Ãªtre conditionnels maintenant
    if len(gpu_cpu_transfers) > 1:
        print("âš ï¸  Multiple GPUâ†’CPU transfers found - verify they are all conditional")
    else:
        print("âœ… GPUâ†’CPU transfers are properly conditioned")
    
    return True

def test_file_structure():
    """Test que tous les fichiers nÃ©cessaires existent"""
    print("ğŸ” Testing file structure...")
    
    required_files = [
        "src/core/inference/engine/inference_sam.py",
        "tests/test_inference_sam_gpu_resident.py",
    ]
    
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"âŒ Required file not found: {file_path}")
            return False
        
        # VÃ©rifier que le fichier n'est pas vide
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        if len(content) < 100:
            print(f"âŒ File seems too small: {file_path}")
            return False
    
    print("âœ… File structure validation passed")
    return True

def main():
    """Run all validation tests"""
    print("ğŸ§ª inference_sam.py Refactoring Validation")
    print("=" * 50)
    
    start_time = time.time()
    
    try:
        success = True
        success &= test_file_structure()
        print()
        success &= test_syntax_validation()
        print()
        success &= test_imports()
        print()
        success &= test_signature_and_parameters()
        print()
        success &= test_gpu_resident_implementation()
        print()
        success &= test_conditional_processing()
        print()
        success &= test_legacy_calls_updated()
        print()
        success &= test_mask_astype_adaptation()
        print()
        success &= test_kpi_instrumentation()
        print()
        success &= count_gpu_cpu_transfers()
        
        elapsed = time.time() - start_time
        
        if success:
            print()
            print("ğŸ‰ ALL VALIDATIONS PASSED!")
            print(f"â±ï¸  Completed in {elapsed:.2f} seconds")
            print()
            print("ğŸ“‹ Summary of inference_sam.py changes:")
            print("â€¢ âœ… Added as_numpy=False parameter for GPU-resident mode")
            print("â€¢ âœ… GPU-first path: keeps masks on GPU for pipeline")
            print("â€¢ âœ… Legacy CPU path: preserved for backward compatibility")
            print("â€¢ âœ… Conditional processing for dimensional reduction")
            print("â€¢ âœ… Modified mask.astype(bool) to be conditional")
            print("â€¢ âœ… KPI instrumentation for monitoring mask device")
            print("â€¢ âœ… Comprehensive test suite created")
            print()
            print("ğŸš€ inference_sam.py ready for integration testing!")
            print("   GPU-resident pipeline: DFINE â†’ Orchestrator â†’ SAM â†’ ResultPacket")
            print("   No more premature GPUâ†’CPU transfers!")
        else:
            print()
            print("âŒ SOME VALIDATIONS FAILED")
            sys.exit(1)
        
    except Exception as e:
        print(f"\nâŒ VALIDATION FAILED: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()