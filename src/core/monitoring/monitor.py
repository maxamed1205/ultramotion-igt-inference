"""Monitoring thread et helpers (Thread M)

Description
-----------
Module charg√© de surveiller la pipeline en temps r√©el :
- calcul et publication des m√©triques (fps_in, fps_out, latence E2E),
- relev√© de l'utilisation GPU (si disponible),
- statistiques sur la taille/consommation des queues,
- ajustement de `Queue_RT_dyn` via `adaptive_queue_resize`.

Responsabilit√©s
----------------
- d√©marrer un thread p√©riodique qui collecte m√©triques,
- exposer une API pour journaliser des m√©triques ponctuelles,
- appliquer des r√®gles d'ajustement sur les queues.

D√©pendances attendues
---------------------
- acc√®s aux queues (module `core.queues.buffers`),
- utilitaire de logging (configuration via `src/config/logging.yaml`),
- possibilit√© d'utiliser `pynvml` ou `nvidia-smi` pour r√©cup√©ration GPU (optionnel).

Fonctions principales
---------------------
- start_monitor_thread(config=None)
- log_pipeline_metrics(fps_in, fps_out, latency_ms, gpu_util, extras=None)
- adjust_rt_queue_size(current_size, metrics) -> int

Note
----
Les fonctions ci-dessous ne contiennent pas d'impl√©mentation r√©elle ‚Äî
elles servent de contrat pour l'impl√©mentation ult√©rieure.
"""

from typing import Dict, Optional   # pour indiquer les types de retour (dictionnaire, optionnel)
import time                         # utilis√© pour mesurer le temps et horodater les m√©triques
import logging                      # syst√®me de journalisation Python
import json                         # pour exporter les m√©triques en JSON
from pathlib import Path             # pour manipuler les chemins de fichiers (logs, snapshots)

LOG = logging.getLogger("igt.monitor")  # cr√©ation d‚Äôun logger nomm√© "igt.monitor" (thread de monitoring)

from core.queues.buffers import collect_queue_metrics  # fonction utilitaire pour extraire les m√©triques des files (queues)
from collections import deque                          # structure de donn√©es (file circulaire) utilis√©e pour stocker un historique des m√©triques
from core.monitoring.kpi import safe_log_kpi, is_kpi_enabled  # fonctions utilitaires pour √©crire les KPI en toute s√©curit√©

# Petite m√©moire tampon (deque) conservant un historique des m√©triques r√©centes (ex: pour calculer une moyenne glissante)
_METRICS_HISTORY = deque(maxlen=30)
# Nombre minimum de points requis avant de calculer une moyenne liss√©e (√©vite de calculer avec trop peu d'√©chantillons)
_SMOOTH_MIN_POINTS = 10

# üéØ R√©f√©rence globale au gateway actif pour r√©cup√©ration des vraies m√©triques
_ACTIVE_GATEWAY = None


def set_active_gateway(gateway):
    """D√©finit la r√©f√©rence au gateway actif pour la collecte de m√©triques.
    
    Args:
        gateway: Instance du gateway IGT ou None pour d√©sactiver
    """
    global _ACTIVE_GATEWAY
    _ACTIVE_GATEWAY = gateway
    LOG.debug("Active gateway set: %s", gateway is not None)


def get_active_gateway():
    """Retourne la r√©f√©rence au gateway actif ou None si aucun gateway configur√©."""
    return _ACTIVE_GATEWAY


def aggregate_metrics(fps_in: float, fps_out: float, latency_ms: float, gpu_util: float):
    """Ajoute un nouvel √©chantillon de m√©triques et retourne la moyenne liss√©e si suffisamment de donn√©es ont √©t√© accumul√©es."""
    _METRICS_HISTORY.append({  # ajoute un dictionnaire contenant les mesures actuelles dans l‚Äôhistorique
        "ts": time.time(),          # horodatage en secondes
        "fps_in": fps_in,           # fr√©quence d‚Äôimages en entr√©e
        "fps_out": fps_out,         # fr√©quence d‚Äôimages en sortie
        "latency_ms": latency_ms,   # latence moyenne en millisecondes
        "gpu_util": gpu_util,       # taux d‚Äôutilisation GPU en pourcentage
    })
    # Ne retourne une moyenne liss√©e que si on a un nombre suffisant d‚Äô√©chantillons
    if len(_METRICS_HISTORY) < _SMOOTH_MIN_POINTS:
        return None  # pas encore assez de points pour lisser
    avg = {  # calcul d‚Äôune moyenne simple pour chaque cl√© sur l‚Äôensemble de l‚Äôhistorique
        k: sum(m[k] for m in _METRICS_HISTORY) / len(_METRICS_HISTORY)
        for k in ("fps_in", "fps_out", "latency_ms", "gpu_util")
    }
    LOG.debug("Smoothed KPIs: %s", avg)  # log interne pour indiquer les valeurs liss√©es calcul√©es
    return avg  # renvoie le dictionnaire contenant les moyennes liss√©es


def get_aggregated_metrics(gateway=None) -> Optional[Dict[str, float]]:
    """Retourne la moyenne liss√©e actuelle calcul√©e √† partir de l'historique en m√©moire.
    
    Si un gateway est fourni, r√©cup√®re les vraies m√©triques du gateway et les fusionne
    avec les m√©triques simul√©es. Si aucun gateway n'est fourni, utilise le gateway actif global.

    Args:
        gateway: Instance optionnelle du gateway IGT pour r√©cup√©rer les vraies m√©triques
                Si None, utilise le gateway actif global (_ACTIVE_GATEWAY)

    Returns:
        Dictionnaire des m√©triques agr√©g√©es ou None si insuffisamment de donn√©es
    """
    if len(_METRICS_HISTORY) < _SMOOTH_MIN_POINTS:  # si on n'a pas assez de donn√©es accumul√©es
        return None
    
    # Calcul de la moyenne liss√©e √† partir de l'historique simul√©
    avg = {  # m√™me logique que aggregate_metrics, mais sans ajout de nouveau point
        k: sum(m[k] for m in _METRICS_HISTORY) / len(_METRICS_HISTORY)
        for k in ("fps_in", "fps_out", "latency_ms", "gpu_util")
    }
    
    # üéØ FUSION avec les vraies m√©triques du gateway si disponible
    active_gw = gateway or _ACTIVE_GATEWAY
    if active_gw is not None:
        try:
            gw_metrics = collect_gateway_metrics(active_gw)
            if gw_metrics:
                # Remplace les m√©triques simul√©es par les vraies m√©triques du gateway
                avg.update({
                    "fps_rx": gw_metrics.get('fps_rx', avg.get('fps_in', 0.0)),
                    "fps_tx": gw_metrics.get('fps_tx', avg.get('fps_out', 0.0)),
                    "latency_ms": gw_metrics.get('avg_latency_ms', avg.get('latency_ms', 0.0)),
                    "bytes_rx_MB": gw_metrics.get('bytes_rx_MB', 0.0),
                    "bytes_tx_MB": gw_metrics.get('bytes_tx_MB', 0.0),
                    "drops_rx_total": gw_metrics.get('drops_rx_total', 0),
                    "drops_tx_total": gw_metrics.get('drops_tx_total', 0),
                    
                    # üéØ Nouvelles m√©triques inter-√©tapes d√©taill√©es
                    "interstage_rx_to_cpu_gpu_ms": gw_metrics.get('interstage_rx_to_cpu_gpu_ms', 0.0),
                    "interstage_cpu_gpu_to_proc_ms": gw_metrics.get('interstage_cpu_gpu_to_proc_ms', 0.0),
                    "interstage_proc_to_gpu_cpu_ms": gw_metrics.get('interstage_proc_to_gpu_cpu_ms', 0.0),
                    "interstage_gpu_cpu_to_tx_ms": gw_metrics.get('interstage_gpu_cpu_to_tx_ms', 0.0),
                    "interstage_rx_to_cpu_gpu_p95_ms": gw_metrics.get('interstage_rx_to_cpu_gpu_p95_ms', 0.0),
                    "interstage_cpu_gpu_to_proc_p95_ms": gw_metrics.get('interstage_cpu_gpu_to_proc_p95_ms', 0.0),
                    "interstage_proc_to_gpu_cpu_p95_ms": gw_metrics.get('interstage_proc_to_gpu_cpu_p95_ms', 0.0),
                    "interstage_gpu_cpu_to_tx_p95_ms": gw_metrics.get('interstage_gpu_cpu_to_tx_p95_ms', 0.0),
                    "interstage_samples": gw_metrics.get('interstage_samples', 0),
                })
                LOG.debug("Fused gateway metrics into aggregated: inter-stage samples=%d", 
                         gw_metrics.get('interstage_samples', 0))
        except Exception as e:
            LOG.debug("Failed to collect gateway metrics: %s", e)
    
    return avg  # renvoie les valeurs moyennes (simul√©es ou fusionn√©es avec gateway)


def get_gpu_utilization() -> float:
    """Retourne le pourcentage d‚Äôutilisation du GPU si disponible, sinon 0.0."""
    try:
        import pynvml  # biblioth√®que NVIDIA pour acc√©der aux informations GPU

        pynvml.nvmlInit()  # initialise la biblioth√®que NVML
        handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # r√©cup√®re le premier GPU (index 0)
        util = float(pynvml.nvmlDeviceGetUtilizationRates(handle).gpu)  # lit le taux d‚Äôutilisation GPU
        try:
            pynvml.nvmlShutdown()  # tente de fermer proprement la session NVML
        except Exception:
            pass  # ignore les erreurs √† la fermeture
        return util  # retourne le pourcentage d‚Äôutilisation GPU
    except Exception:
        return 0.0  # en cas d‚Äôerreur (absence de GPU ou NVML), retourne 0.0


def collect_gateway_metrics(gw) -> Dict[str, float]:
    """Collecte les m√©triques dynamiques √† partir d‚Äôun objet de type IGTGateway.

    Retourne un dictionnaire pr√™t √† √™tre int√©gr√© dans une ligne de KPI.
    Si `gw` est None (aucun gateway actif), retourne un dictionnaire vide.
    """
    if gw is None:  # si aucun objet gateway n‚Äôest fourni
        return {}  # retourne un dictionnaire vide
    try:
        snap = gw.stats.snapshot()  # tente de r√©cup√©rer un instantan√© des statistiques depuis le gateway
    except Exception:
        snap = {}  # si l‚Äôappel √©choue, on utilise un dictionnaire vide

    # inclut des champs suppl√©mentaires utiles si pr√©sents dans le snapshot
    return {
        "fps_rx": float(snap.get("avg_fps_rx", 0.0)),  # fr√©quence moyenne des frames re√ßues (RX)
        "fps_tx": float(snap.get("avg_fps_tx", 0.0)),  # fr√©quence moyenne des frames envoy√©es (TX)
        "bytes_rx_MB": float(snap.get("bytes_rx", 0)) / 1e6,  # octets re√ßus convertis en m√©gaoctets
        "bytes_tx_MB": float(snap.get("bytes_tx", 0)) / 1e6,  # octets envoy√©s convertis en m√©gaoctets
        # le gateway peut exposer une latence moyenne; sinon, on r√©cup√®re la derni√®re mesur√©e
        "latency_ms": float(snap.get("avg_latency_ms", getattr(gw, "last_latency_ms", 0.0) or 0.0)),
        "avg_latency_ms": float(snap.get("avg_latency_ms", getattr(gw, "last_latency_ms", 0.0) or 0.0)),
        # compteurs de pertes (drops) si disponibles
        "drops_rx_total": int(snap.get("drops_rx_total", snap.get("drops_rx", 0) or 0)),
        "drops_tx_total": int(snap.get("drops_tx_total", snap.get("drops_tx", 0) or 0)),
        # fr√©quence cible configur√©e dans le gateway
        "fps_target": float(getattr(getattr(gw, "config", None), "target_fps", 0.0) or 0.0),
        
        # üéØ NOUVELLES M√âTRIQUES INTER-√âTAPES D√âTAILL√âES (Workflow GPU-r√©sident)
        # Latences moyennes par √©tape
        "interstage_rx_to_cpu_gpu_ms": float(snap.get("interstage_rx_to_cpu_gpu_ms", 0.0)),
        "interstage_cpu_gpu_to_proc_ms": float(snap.get("interstage_cpu_gpu_to_proc_ms", 0.0)),
        "interstage_proc_to_gpu_cpu_ms": float(snap.get("interstage_proc_to_gpu_cpu_ms", 0.0)),
        "interstage_gpu_cpu_to_tx_ms": float(snap.get("interstage_gpu_cpu_to_tx_ms", 0.0)),
        
        # Percentiles P95 par √©tape
        "interstage_rx_to_cpu_gpu_p95_ms": float(snap.get("interstage_rx_to_cpu_gpu_p95_ms", 0.0)),
        "interstage_cpu_gpu_to_proc_p95_ms": float(snap.get("interstage_cpu_gpu_to_proc_p95_ms", 0.0)),
        "interstage_proc_to_gpu_cpu_p95_ms": float(snap.get("interstage_proc_to_gpu_cpu_p95_ms", 0.0)),
        "interstage_gpu_cpu_to_tx_p95_ms": float(snap.get("interstage_gpu_cpu_to_tx_p95_ms", 0.0)),
        
        # M√©tadonn√©es inter-√©tapes
        "interstage_samples": int(snap.get("interstage_samples", 0)),
    }


def log_kpi_tick(fps_in: float, fps_out: float, latency_ms: float, gpu_util: float = 0.0) -> None:
    """√âcrit une ligne de KPI analysable dans le logger d√©di√© aux KPI."""
    q_metrics = collect_queue_metrics()  # collecte les statistiques courantes sur les queues
    # compose un message compact au format cl√©=valeur
    try:
        from core.monitoring.kpi import format_kpi, safe_log_kpi  # import local des utilitaires KPI

        kmsg = format_kpi({  # cr√©ation d‚Äôun message structur√© avec les mesures principales
            "ts": time.time(),                                  # horodatage en secondes (√©poque)
            "fps_in": f"{fps_in:.2f}",                          # fr√©quence d‚Äôentr√©e
            "fps_out": f"{fps_out:.2f}",                        # fr√©quence de sortie
            "latency_ms": f"{latency_ms:.1f}",                  # latence en millisecondes
            "gpu_util": f"{gpu_util:.1f}",                      # utilisation GPU
            "q_rt": q_metrics['Queue_RT_dyn']['size'],          # taille de la queue temps r√©el
            "q_gpu": q_metrics['Queue_GPU']['size'],            # taille de la queue GPU
            "drops_rt": q_metrics['Queue_RT_dyn']['drops'],     # nombre de pertes RT
            "drops_gpu": q_metrics['Queue_GPU']['drops'],       # nombre de pertes GPU
        })
        if is_kpi_enabled():  # si la journalisation des KPI est activ√©e
            safe_log_kpi(kmsg)  # √©crit la ligne dans logs/kpi.log (via le logger igt.kpi)
    except Exception:
        # en cas d‚Äôerreur du module KPI, tentative de repli pour √©mettre un message structur√©
        try:
            from core.monitoring.kpi import format_kpi, safe_log_kpi
            kmsg = format_kpi({
                "ts": time.time(),
                "fps_in": f"{fps_in:.2f}",
                "fps_out": f"{fps_out:.2f}",
                "latency_ms": f"{latency_ms:.1f}",
                "gpu_util": f"{gpu_util:.1f}",
                "q_rt": q_metrics['Queue_RT_dyn']['size'],
                "q_gpu": q_metrics['Queue_GPU']['size'],
                "drops_rt": q_metrics['Queue_RT_dyn']['drops'],
                "drops_gpu": q_metrics['Queue_GPU']['drops'],
            })
            if is_kpi_enabled():
                safe_log_kpi(kmsg)
        except Exception:
            LOG.debug("KPI fallback emission failed; skipping")  # journalise un message si l‚Äô√©mission √©choue totalement


def export_kpi_snapshot(filepath: str = "logs/kpi_snapshot.json") -> None:
    """Sauvegarde le dernier instantan√© de m√©triques agr√©g√©es dans un fichier JSON.

    Cr√©e les r√©pertoires parents si n√©cessaire.
    """
    try:
        avg = aggregate_metrics(0.0, 0.0, 0.0, 0.0)  # tente d‚Äôagr√©ger des m√©triques par d√©faut (peut retourner None)
        # si aggregate_metrics retourne None (aucune donn√©e encore disponible), on cr√©e un snapshot vide
        if avg is None:
            avg = {"fps_in": 0.0, "fps_out": 0.0, "latency_ms": 0.0, "gpu_util": 0.0}
        p = Path(filepath)  # convertit le chemin en objet Path
        p.parent.mkdir(parents=True, exist_ok=True)  # cr√©e le dossier logs/ s‚Äôil n‚Äôexiste pas
        # √©crit un fichier JSON horodat√© et met √† jour la version la plus r√©cente
        ts = time.strftime("%Y%m%d-%H%M%S", time.gmtime())  # format d‚Äôhorodatage lisible (UTC)
        stamped = p.parent / f"kpi_snapshot_{ts}.json"       # nom de fichier unique par date
        stamped.write_text(json.dumps(avg, indent=2))         # √©crit le fichier horodat√©
        # met √† jour le fichier principal (dernier snapshot courant)
        p.write_text(json.dumps(avg, indent=2))
        # effectue la rotation et compression des anciens fichiers de snapshot
        try:
            rotate_snapshots(p.parent, keep=10)  # conserve les 10 plus r√©cents
        except Exception:
            pass  # ignore les erreurs de rotation
    except Exception:
        LOG.exception("Failed to export KPI snapshot")  # journalise une erreur si l‚Äôexport √©choue


def rotate_snapshots(base_dir: str = "logs", keep: int = 10):
    """Effectue la rotation des fichiers de snapshots KPI dans `base_dir`, en conservant les `keep` plus r√©cents.

    Les fichiers plus anciens que ce seuil sont compress√©s au format `.json.gz`
    afin de pr√©server l‚Äôhistorique tout en √©conomisant de l‚Äôespace disque.
    Le fichier principal `kpi_snapshot.json` est toujours r√©√©crit avec la derni√®re version,
    sans lien symbolique, pour garantir la compatibilit√© entre plateformes.
    """
    base = Path(base_dir)  # cr√©e un objet Path repr√©sentant le dossier de base
    if not base.exists():  # si le dossier n‚Äôexiste pas, on ne fait rien
        return
    # recherche tous les fichiers "kpi_snapshot_*.json" tri√©s du plus r√©cent au plus ancien
    files = sorted(base.glob("kpi_snapshot_*.json"), key=lambda x: x.stat().st_mtime, reverse=True)
    # garde les `keep` fichiers les plus r√©cents, compresse les autres
    for old in files[keep:]:
        try:
            gz = old.with_suffix(old.suffix + ".gz")  # cr√©e le nom du fichier compress√©
            # si la version compress√©e existe d√©j√†, on supprime simplement l‚Äôancienne
            if gz.exists():
                try:
                    old.unlink()  # supprime l‚Äôancien fichier non compress√©
                except Exception:
                    pass
                continue
            import gzip  # module standard Python pour la compression Gzip

            # ouverture du fichier source en lecture binaire et cr√©ation du fichier compress√©
            with old.open("rb") as fh_in, gzip.open(str(gz), "wb") as fh_out:
                fh_out.writelines(fh_in)  # √©crit le contenu compress√©
            # si la compression r√©ussit, on supprime le fichier original
            try:
                old.unlink()
            except Exception:
                pass
        except Exception:
            # en cas d‚Äô√©chec de compression, on tente de supprimer le fichier pour limiter la taille disque
            try:
                old.unlink()
            except Exception:
                pass


def start_monitor_thread(config: Optional[Dict] = None) -> None:
    """D√©marre un thread p√©riodique qui collecte et journalise les m√©triques de la pipeline.

    Args:
        config: dictionnaire optionnel contenant les param√®tres (intervalle, files √† surveiller, niveau de log, etc.)
    """
    interval = (config or {}).get("interval_sec", 1.0)  # intervalle de collecte par d√©faut (1 seconde)
    LOG.info("Monitor thread started (interval=%.2fs)", interval)  # message de d√©marrage

    def _loop():  # fonction interne ex√©cut√©e dans un thread ind√©pendant

        while True: # boucle l√©g√®re : √©met des valeurs fictives par d√©faut sauf si remplac√©e par des hooks r√©els
            try:
                # ‚ö†Ô∏è TODO Remplacer les valeurs simul√©es par de vrais compteurs de la pipeline
                fps_in, fps_out, latency_ms = 25.0, 25.0, 40.0 # Ces valeurs sont simul√©es ici ; elles seront remplac√©es plus tard par de vrais compteurs
                gpu_util = get_gpu_utilization() # essaie d‚Äôobtenir l‚Äôutilisation r√©elle du GPU (si pynvml est disponible)
                
                gw = (config or {}).get("gateway") if isinstance(config, dict) else None # collecte les m√©triques du gateway s‚Äôil a √©t√© pass√© dans la configuration
                gw_metrics = collect_gateway_metrics(gw) if gw is not None else {}  
                agg = aggregate_metrics(fps_in, fps_out, latency_ms, gpu_util) # enregistre cet √©chantillon dans l‚Äôhistorique m√©moire pour lisser les valeurs
                
                q_metrics = collect_queue_metrics() # compose un message de monitoring contenant les valeurs instantan√©es et les m√©triques de queue
                
                msg = (  # construit le message de monitoring complet (toutes les m√©triques cl√©s)
                    f"[monitor] ts={time.time():.3f} "  # horodatage courant (secondes depuis epoch, arrondi √† 3 d√©cimales)
                    f"fps_in={fps_in:.2f} fps_out={fps_out:.2f} "  # fr√©quences d'entr√©e/sortie de la pipeline (images/s)
                    f"latency_ms={latency_ms:.1f} gpu_util={gpu_util:.1f} "  # latence moyenne (ms) et taux d‚Äôutilisation GPU (%)
                    f"q_rt={q_metrics.get('Queue_RT_dyn', {}).get('size', 0)} "  # taille actuelle de la queue temps r√©el (nombre d‚Äô√©l√©ments)
                    f"drops_rt={q_metrics.get('Queue_RT_dyn', {}).get('drops', 0)} "  # nombre d‚Äôimages perdues dans la queue temps r√©el
                )


                if gw_metrics: # ajoute les champs relatifs au gateway si pr√©sents
                    msg += (  # ajoute au message principal les m√©triques sp√©cifiques au gateway (r√©seau IGTLink)
                        f" fps_rx={gw_metrics.get('fps_rx', 0.0):.1f} "  # fr√©quence de r√©ception depuis PlusServer (images/s)
                        f"fps_tx={gw_metrics.get('fps_tx', 0.0):.1f} "  # fr√©quence d‚Äô√©mission vers Slicer ou autres clients (images/s)
                        f"MB_rx={gw_metrics.get('bytes_rx_MB', 0.0):.3f} "  # d√©bit de r√©ception (m√©gaoctets/s)
                        f"MB_tx={gw_metrics.get('bytes_tx_MB', 0.0):.3f} "  # d√©bit d‚Äô√©mission (m√©gaoctets/s)
                        f"latency_gw={gw_metrics.get('latency_ms', 0.0):.1f} "  # latence moyenne mesur√©e au niveau du gateway (ms)
                        f"fps_target={gw_metrics.get('fps_target', 0.0):.1f}"  # fr√©quence cible configur√©e pour la capture (images/s)
                    )


                if agg is not None: # si une moyenne liss√©e est disponible, on l‚Äôutilise pour remplacer les valeurs brutes
                    try:
                        msg = (  # reconstruit un message de monitoring √† partir des moyennes glissantes (valeurs liss√©es)
                            f"[monitor] ts={time.time():.3f} "  # horodatage courant (en secondes, 3 d√©cimales)
                            f"fps_in={agg['fps_in']:.2f} fps_out={agg['fps_out']:.2f} "  # fr√©quences d‚Äôentr√©e/sortie moyennes (images/s)
                            f"latency_ms={agg['latency_ms']:.1f} gpu_util={agg['gpu_util']:.1f} "  # latence moyenne et taux d‚Äôutilisation GPU (%)
                        ) + (  # ajoute la fin du message pr√©c√©dent contenant les m√©triques de queue si elles existaient
                            msg.split('q_rt=')[-1] if 'q_rt=' in msg else ''  # pr√©serve les m√©triques de queue et drops si d√©j√† pr√©sentes
                        )
                    except Exception:
                        LOG.debug("√âchec du formatage de la moyenne liss√©e ; utilisation des valeurs instantan√©es")
                
                if is_kpi_enabled(): # si le syst√®me KPI est activ√©, on logge les m√©triques sous forme structur√©e
                    try:
                        from core.monitoring.kpi import format_kpi
                        kdata = {  # dictionnaire complet contenant les donn√©es KPI (Key Performance Indicators)
                            "ts": time.time(),  # horodatage actuel en secondes (timestamp UNIX)
                            "fps_in": fps_in,  # fr√©quence d‚Äôarriv√©e des images dans la pipeline (images/s)
                            "fps_out": fps_out,  # fr√©quence de sortie des images trait√©es (images/s)
                            "latency_ms": latency_ms,  # latence moyenne observ√©e entre r√©ception et sortie (millisecondes)
                            "gpu_util": gpu_util,  # taux d‚Äôutilisation GPU actuel (%)

                            # informations sur les files internes (queues)
                            "q_rt": q_metrics.get('Queue_RT_dyn', {}).get('size', 0),  # taille de la queue temps r√©el (nombre d‚Äô√©l√©ments)
                            "q_gpu": q_metrics.get('Queue_GPU', {}).get('size', 0),  # taille de la queue GPU (frames en attente d‚Äôinf√©rence)
                            "drops_rt": q_metrics.get('Queue_RT_dyn', {}).get('drops', 0),  # nombre d‚Äôimages perdues dans la queue temps r√©el
                            "drops_gpu": q_metrics.get('Queue_GPU', {}).get('drops', 0),  # nombre d‚Äôimages perdues dans la queue GPU
                        }

                        if gw_metrics:  # ajout des m√©triques du gateway si disponibles (r√©seau IGTLink actif)
                            kdata.update({  # fusionne les m√©triques du gateway dans le dictionnaire KPI global
                                "fps_rx": gw_metrics.get('fps_rx', 0.0),  # fr√©quence de r√©ception d‚Äôimages depuis PlusServer (images/s)
                                "fps_tx": gw_metrics.get('fps_tx', 0.0),  # fr√©quence d‚Äôenvoi des images trait√©es vers Slicer ou autres clients (images/s)
                                "MB_rx": gw_metrics.get('bytes_rx_MB', 0.0),  # d√©bit de r√©ception r√©seau (m√©gaoctets/s)
                                "MB_tx": gw_metrics.get('bytes_tx_MB', 0.0),  # d√©bit d‚Äô√©mission r√©seau (m√©gaoctets/s)
                                "avg_latency_ms": gw_metrics.get('avg_latency_ms', gw_metrics.get('latency_ms', 0.0)),  # latence moyenne mesur√©e au niveau du gateway (ms)
                                "drops_rx_total": gw_metrics.get('drops_rx_total', 0),  # nombre total de paquets ou images perdues en r√©ception
                                "drops_tx_total": gw_metrics.get('drops_tx_total', 0),  # nombre total de paquets ou images perdues en √©mission
                            })
                        kmsg = format_kpi(kdata)  # formate les donn√©es KPI en texte cl√©=valeur
                        safe_log_kpi(kmsg)  # envoie le message vers logs/kpi.log via le logger igt.kpi
                    except Exception:
                        LOG.exception("safe_log_kpi a √©chou√© (monitor)")  # journalise une erreur si l‚Äô√©mission KPI √©choue
                else:
                    LOG.info("KPI: %s", msg)  # sinon logge le message textuel dans le logger g√©n√©ral
                
                try: # export p√©riodique d‚Äôun snapshot JSON (tous les N ticks, configurable)
                    tick = getattr(start_monitor_thread, "_tick_counter", 0) + 1  # incr√©mente le compteur interne
                    setattr(start_monitor_thread, "_tick_counter", tick)  # stocke le compteur interne de ticks dans la fonction (sert √† suivre le nombre d‚Äôit√©rations du thread)
                    export_every = (config or {}).get("snapshot_every", 10) if isinstance(config, dict) else 10  # d√©finit la fr√©quence d‚Äôexport ou de snapshot des m√©triques (par d√©faut toutes les 10 it√©rations)
                    if tick % export_every == 0:  # tous les N intervalles, on exporte un snapshot
                        export_kpi_snapshot("logs/kpi_snapshot.json")
                except Exception:
                    LOG.debug("export_kpi_snapshot ignor√© (erreur mineure)")
                time.sleep(interval)  # attend la dur√©e sp√©cifi√©e avant la prochaine it√©ration
            except Exception:
                LOG.exception("Exception dans la boucle du thread de monitoring")  # capture toute erreur pour √©viter l‚Äôarr√™t du thread

    import threading
    # ‚ö†Ô∏è TODO S‚Äôex√©cute ind√©finiment tant que le programme tourne, Pas de stop_event ‚Üí le thread ne peut pas √™tre arr√™t√© proprement pour l‚Äôinstant.
    threading.Thread(target=_loop, name="MonitorThread", daemon=True).start()  # d√©marre le thread en mode d√©mon
    # note : impl√©mentation compl√®te (join, stop event, etc.) non encore pr√©sente
    return


def log_pipeline_metrics(
    fps_in: float,
    fps_out: float,
    latency_ms: float,
    gpu_util: float,
    extras: Optional[Dict] = None
) -> None:
    """Journalise les m√©triques principales de la pipeline.

    Args:
        fps_in: nombre d'images par seconde en entr√©e (avant traitement)
        fps_out: nombre d'images par seconde en sortie (apr√®s traitement)
        latency_ms: latence totale de la pipeline en millisecondes
        gpu_util: taux d'utilisation du GPU en pourcentage
        extras: dictionnaire optionnel contenant des m√©triques additionnelles personnalis√©es
    """
    # √âcrit un message d'information standard dans le logger principal
    LOG.info(
        "Pipeline metrics fps_in=%s fps_out=%s latency_ms=%s gpu_util=%s",
        fps_in, fps_out, latency_ms, gpu_util
    )
    # Si des m√©triques suppl√©mentaires sont pr√©sentes et que le niveau DEBUG est activ√©, on les loggue
    if extras and LOG.isEnabledFor(logging.DEBUG):
        LOG.debug("Extra metrics: %s", extras)
    return  # rien √† renvoyer (simple enregistrement de logs)


def adjust_rt_queue_size(current_size: int, metrics: Dict) -> int:
    # ‚ö†Ô∏è TODO fonction utilitaire pr√©vue pour ajuster dynamiquement la taille de la file temps r√©el principale (Queue_RT_dyn)
    # future impl√©mentation PID
    """Calcule et retourne la nouvelle taille souhait√©e pour la file (queue) temps r√©el dynamique.

    Args:
        current_size: taille actuelle de la queue
        metrics: dictionnaire de m√©triques r√©centes (ex : tailles des queues, fps, latence)

    Returns:
        La nouvelle taille (int), ajust√©e selon les m√©triques. Ici, retourne la taille actuelle (fonction factice).
    """
    # ‚ö†Ô∏è TODO Fonction encore non impl√©ment√©e : pour l‚Äôinstant, renvoie simplement la taille actuelle.
    # future impl√©mentation PID
    LOG.debug("adjust_rt_queue_size appel√© avec current_size=%s", current_size)
    return current_size  # aucune modification de la taille n‚Äôest encore appliqu√©e


def get_pipeline_metrics() -> Dict:
    """Retourne un instantan√© des m√©triques courantes de la pipeline, incluant les KPI des files et un horodatage.

    Structure du retour :
        {
            "queues": { ... },   # dictionnaire des m√©triques par queue (taille, drops, etc.)
            "timestamp": <float> # horodatage UNIX (secondes)
        }
    """
    # collect_queue_metrics() retourne l‚Äô√©tat actuel de chaque file : taille, nombre de drops, etc.
    return {"queues": collect_queue_metrics(), "timestamp": time.time()}
