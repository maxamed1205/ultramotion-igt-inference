import logging  # module standard de journalisation Python
import queue  # file FIFO thread-safe, utilis√©e pour transporter les logs vers le listener
from logging.handlers import QueueHandler, QueueListener, RotatingFileHandler  # handlers pour logging asynchrone + rotation
from typing import Optional, Dict  # annotations de types (optionnel, dict)

# Module-level references for health checks
_log_queue: Optional[queue.Queue] = None  # Conteneur FIFO central pour les messages, r√©f√©rence globale vers la file de logs (pour diagnostics)
_listener_obj = None  # Thread de consommation/√©criture vers les fichiers., r√©f√©rence globale vers l‚Äôobjet QueueListener (pour v√©rifier s‚Äôil est vivant), R√©f√©rence au thread consommateur qui √©crit sur disque
_health_thread = None  # Surveillant automatique du syst√®me de logs, r√©f√©rence globale vers le thread de sant√© (surveillance du syst√®me de logs asynchrone)


def setup_async_logging(  # fonction d‚Äôinstallation du sous-syst√®me de logging asynchrone
    log_dir: Optional[str] = None,  # r√©pertoire cible des fichiers de log (par d√©faut "logs")
    attach_to_logger: str = "igt",  # logger racine auquel attacher le QueueHandler (ex: "igt")
    yaml_cfg: Optional[Dict] = None,  # dict de la config YAML charg√©e (pour r√©cup√©rer formatters/niveaux)
    remove_yaml_file_handlers: bool = True,  # supprime les handlers fichiers d√©j√† pr√©sents (√©vite doublons)
    replace_root: bool = False,  # si True, remplace les handlers du logger racine par le QueueHandler
    create_error_handler: bool = True,  # si True, cr√©e un handler d√©di√© error.log (sink unique des erreurs)
    ):
    """Configure an asynchronous logging subsystem with a central queue.  # docstring : configure un logging asynchrone √† file centrale

    Behavior:  # comportement global
    - Creates a QueueListener with file handlers for pipeline and kpi (and optionally error).  # cr√©e un QueueListener avec handlers pipeline/kpi/(error)
    - Attaches a QueueHandler to the named logger (default 'igt').  # attache un QueueHandler au logger nomm√© (par d√©faut "igt")
    - If remove_yaml_file_handlers is True, attempts to remove RotatingFileHandler instances  # si True, retire les RotatingFileHandler d√©j√† configur√©s
      from the named logger to avoid duplicate writes.  # afin d‚Äô√©viter les √©critures en double

    Parameters:  # param√®tres
    - yaml_cfg: the dictConfig loaded YAML; used to copy formatters/levels when present.  # dict de logging.yaml pour reproduire formats/niveaux si disponibles

    Returns the started QueueListener which should be .stop()'ed on shutdown.  # retourne la file et le listener (√† .stop() lors de l‚Äôarr√™t)
    """
    global _listener_obj, _log_queue  # acc√®s global

    # üö´ Protection : emp√™che double initialisation
    if _listener_obj is not None and _log_queue is not None:
        logging.getLogger("igt.monitor").warning(
            "Async logging already active ‚Äî skipping reconfiguration."
        )
        return _log_queue, _listener_obj

    if log_dir is None:  # si aucun r√©pertoire n‚Äôest fourni
        log_dir = "logs"  # valeur par d√©faut : "logs"

    import os  # import local d‚Äôos pour cr√©er le r√©pertoire
    os.makedirs(log_dir, exist_ok=True)  # cr√©e le dossier s‚Äôil n‚Äôexiste pas (idempotent)


    log_queue: queue.Queue = queue.Queue(-1)  # file non born√©e (-1) qui recevra tous les messages de logs

    std_formatter = None  # formatter standard (pipeline.log)
    kpi_formatter = None  # formatter KPI (kpi.log)
    if yaml_cfg and isinstance(yaml_cfg, dict):  # si une config YAML valide est fournie
        fmts = yaml_cfg.get("formatters", {})  # r√©cup√®re la section "formatters" de logging.yaml
        # construit les objets logging.Formatter si des formats sont d√©finis
        if "standard" in fmts and isinstance(fmts["standard"], dict):  # si un formatter "standard" est d√©crit
            std_fmt = fmts["standard"].get("format")  # lit la cha√Æne de format associ√©e
            if std_fmt:  # si non vide
                std_formatter = logging.Formatter(std_fmt)  # cr√©e l‚Äôobjet Formatter pour le format standard
        if "kpi" in fmts and isinstance(fmts["kpi"], dict):  # si un formatter "kpi" est d√©crit
            kpi_fmt = fmts["kpi"].get("format")  # lit la cha√Æne de format associ√©e
            if kpi_fmt:  # si non vide
                kpi_formatter = logging.Formatter(kpi_fmt)  # cr√©e l‚Äôobjet Formatter pour le format KPI

     # valeurs de repli si YAML n‚Äôa pas fourni les formats
    if std_formatter is None:  # si aucun formatter standard n‚Äôa √©t√© trouv√©
        std_formatter = logging.Formatter("[%(asctime)s] [%(levelname)s] %(processName)s/%(threadName)s | %(name)s | %(message)s")  # format par d√©faut complet
    if kpi_formatter is None:  # si aucun formatter KPI n‚Äôa √©t√© trouv√©
        kpi_formatter = logging.Formatter("%(asctime)s | %(processName)s | %(threadName)s | %(name)s | %(message)s")  # format KPI de repli

    handler_main = RotatingFileHandler(f"{log_dir}/pipeline.log", maxBytes=10_000_000, backupCount=5)  # handler fichier avec rotation pour pipeline.log (10 Mo, 5 backups)
    handler_main.setLevel(logging.DEBUG)  # capte tous les niveaux jusqu‚Äô√† DEBUG
    handler_main.setFormatter(std_formatter)  # applique le formatter standard
    
    try: # exclut ERROR+ de pipeline.log (redirig√©s vers error.log)
        from core.monitoring.filters import NoErrorFilter  # filtre maison pour retirer ERROR des handlers non d√©di√©s
        handler_main.addFilter(NoErrorFilter())  # ajoute le filtre NoErrorFilter sur pipeline.log
    except Exception:
        pass  # tol√®re l‚Äôabsence du filtre sans casser l‚Äôinitialisation

    handler_kpi = RotatingFileHandler(f"{log_dir}/kpi.log", maxBytes=5_000_000, backupCount=3)  # handler fichier pour kpi.log (5 Mo, 3 backups)
    handler_kpi.setLevel(logging.INFO)  # n‚Äôaccepte que INFO et plus
    handler_kpi.setFormatter(kpi_formatter)  # applique le formatter KPI

    # option d‚Äôun sink KPI au format JSONL via variable d‚Äôenvironnement
    import os  # r√©-import local (autoris√©, inoffensif)
    kpi_jsonl_handler = None  # handler JSONL optionnel initialis√© √† None
    listener_handlers = [handler_main, handler_kpi]  # liste des handlers g√©r√©s par le QueueListener

    if os.getenv("KPI_JSONL", "0") not in ("0", "false", "False"):  # si KPI_JSONL activ√© (‚â† 0/false)
        try:
            from core.monitoring.kpi import KpiJsonFormatter  # formatter sp√©cialis√© JSONL pour KPI
            kpi_jsonl_handler = RotatingFileHandler(f"{log_dir}/kpi.jsonl", maxBytes=5_000_000, backupCount=3)  # handler fichier JSONL (rotation 5 Mo, 3 backups)
            kpi_jsonl_handler.setLevel(logging.INFO)  # niveau INFO et sup√©rieurs
            kpi_jsonl_handler.setFormatter(KpiJsonFormatter())  # applique le formatter JSONL
            listener_handlers.append(kpi_jsonl_handler)  # ajoute le handler JSONL au listener
        except Exception:
            pass  # si indisponible, on ignore sans interrompre l‚Äôinstallation

    if create_error_handler:  # si l‚Äôoption de cr√©ation du handler d‚Äôerreurs est activ√©e
        handler_err = RotatingFileHandler(f"{log_dir}/error.log", maxBytes=7_340_032, backupCount=3)  # error.log (‚âà7 Mo, 3 backups)
        handler_err.setLevel(logging.ERROR)  # ne prend que ERROR et CRITICAL
        handler_err.setFormatter(std_formatter)  # format standard pour les erreurs
        listener_handlers.append(handler_err)  # ajoute le handler d‚Äôerreurs √† la liste du listener


    # üßπ Supprime les handlers existants du logger "igt" et du root avant d‚Äôajouter le QueueHandler
    root_logger = logging.getLogger()
    for h in list(root_logger.handlers):
        root_logger.removeHandler(h)

    target_logger = logging.getLogger(attach_to_logger)
    for h in list(target_logger.handlers):
        target_logger.removeHandler(h)

    listener = QueueListener(log_queue, *listener_handlers)  # cr√©e le QueueListener avec tous les handlers de sortie
    listener.start()  # d√©marre le thread interne du QueueListener

    _log_queue = log_queue  # une copie de la r√©f√©rence dans une variable globale, ce qui permet √† d‚Äôautres fonctions d‚Äôy acc√©der plus tard, m√©morise la file globale
    _listener_obj = listener  # m√©morise le listener global


    # üî• √âlimine tous les handlers pr√©c√©dents de la hi√©rarchie avant ajout du QueueHandler
    mgr = logging.Logger.manager
    for logger_name, logger_obj in list(mgr.loggerDict.items()):
        # On ne garde que les vrais loggers (pas les PlaceHolder)
        try:
            if not isinstance(logger_obj, logging.Logger):
                continue
            if logger_name.startswith("igt"):
                for h in list(logger_obj.handlers):
                    logger_obj.removeHandler(h)
        except Exception:
            continue

    # Nettoyage aussi du root logger
    root_logger = logging.getLogger()
    for h in list(root_logger.handlers):
        try:
            root_logger.removeHandler(h)
        except Exception:
            pass



    queue_handler = QueueHandler(log_queue)  # cr√©e un QueueHandler qui poussera les logs dans la file centrale

    target_logger = logging.getLogger(attach_to_logger) if attach_to_logger else logging.getLogger()  # r√©cup√®re le logger cible (ou root si vide)

    if remove_yaml_file_handlers:  # seulement si demand√©
        # parcours des loggers descendants pour nettoyage
        prefix = attach_to_logger + "." if attach_to_logger else ""  # pr√©fixe de la hi√©rarchie (ex: "igt.")
        # Remove from the direct target logger  # suppression sur le logger cible direct
        def remove_file_handlers_from_logger(lgr):  # fonction utilitaire de retrait de handlers fichiers
            for h in list(lgr.handlers):  # it√®re sur une copie de la liste des handlers
                try:
                    from logging.handlers import RotatingFileHandler as _RFH  # type √† v√©rifier
                    if isinstance(h, _RFH):  # si le handler est un RotatingFileHandler
                        lgr.removeHandler(h)  # le retirer pour √©viter la double √©criture
                except Exception:
                    pass  # ignorer toute erreur de retrait

        remove_file_handlers_from_logger(target_logger)  # applique le nettoyage sur le logger cible

        # Also remove file handlers from all descendant loggers registered in logging.Logger.manager.loggerDict  # nettoie aussi les enfants enregistr√©s
        try:
            mgr = logging.Logger.manager  # acc√®s au gestionnaire global des loggers
            for name, obj in list(mgr.loggerDict.items()):  # parcourt tous les loggers connus
                # We only want logger objects (not PlaceHolder)  # on vise les vrais loggers uniquement
                try:
                    if not name.startswith(prefix.rstrip('.')):  # ignore ceux hors du pr√©fixe cible
                        continue  # passe au suivant
                    child = logging.getLogger(name)  # r√©cup√®re le logger enfant par son nom
                    remove_file_handlers_from_logger(child)  # retire ses handlers fichiers
                except Exception:
                    pass  # ignore toute anomalie lors du parcours
        except Exception:
            pass  # si l‚Äôacc√®s au manager √©choue, on continue sans bloquer

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üîó Attache le QueueHandler √† la hi√©rarchie de loggers (sans doublon)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    for h in list(target_logger.handlers):  # cr√©e une copie de la liste des handlers du logger cible
        if isinstance(h, QueueHandler):  # v√©rifie si le handler actuel est d√©j√† un QueueHandler
            target_logger.removeHandler(h)  # le retire pour √©viter une double √©criture asynchrone
    target_logger.addHandler(queue_handler)  # attache le nouveau QueueHandler unique au logger cible

    # üëâ Active la propagation pour les loggers enfants "igt.*" (√©vite duplication)
    # Au lieu d'ajouter un QueueHandler √† chaque enfant, on active propagate=True
    # pour que les messages remontent vers le parent "igt" qui a le QueueHandler
    prefix = (attach_to_logger + ".") if attach_to_logger else ""  # construit le pr√©fixe hi√©rarchique (ex: "igt.")
    for name, obj in list(logging.Logger.manager.loggerDict.items()):  # parcourt tous les loggers connus du gestionnaire
        if name.startswith(prefix):  # ne traite que ceux appartenant √† la hi√©rarchie cibl√©e
            try:
                child = logging.getLogger(name)  # r√©cup√®re le logger enfant √† partir de son nom
                # ‚ö†Ô∏è IMPORTANT : On active propagate au lieu d'ajouter un handler
                # Sinon chaque logger envoie √† la queue ‚Üí duplication !
                child.propagate = True  # les messages remontent vers le parent "igt"
            except Exception:  # capture toute erreur inattendue pour ne jamais interrompre la configuration
                pass  # ignore silencieusement les exceptions (s√©curit√©)


    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # ‚öôÔ∏è Ajustement des niveaux de log si n√©cessaire
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    try:
        root_logger = logging.getLogger()  # r√©cup√®re le logger racine
        if target_logger is root_logger:  # si le logger cible est le root
            if root_logger.level > logging.INFO:  # test du niveau actuel
                root_logger.setLevel(logging.INFO)  # abaisse le niveau √† INFO
        else:
            if target_logger.level == 0:  # 0 signifie ‚Äúpas de niveau d√©fini‚Äù
                target_logger.setLevel(logging.INFO)  # fixe √† INFO pour garantir la remont√©e des KPI
    except Exception:
        pass  # on ignore toute erreur silencieusement (s√©curit√©)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üåê Option : remplacer les handlers du root logger
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if replace_root:  # si demand√© par l‚Äôappelant
        root = logging.getLogger()  # r√©cup√®re le logger racine
        for h in list(root.handlers):  # it√®re sur copie pour modifier en s√©curit√©
            try:
                root.removeHandler(h)  # retire chaque handler existant
            except Exception:
                pass  # ignore les erreurs de retrait
        root.addHandler(queue_handler)  # attache le QueueHandler au root (pipeline asynchrone global)

    return log_queue, listener  # tuple (file de logs, QueueListener d√©marr√©)



def get_log_queue() -> Optional[queue.Queue]:  # retourne la file interne du syst√®me de logging asynchrone
    """Return the internal log queue (if created).  # renvoie la file interne (si elle a √©t√© cr√©√©e)

    This is useful for health-checks to read queue.qsize().  # utile pour lire la taille actuelle de la file (surveillance)
    """
    return _log_queue  # renvoie la r√©f√©rence globale de la file (ou None si non initialis√©e)


def is_listener_alive() -> bool:  # v√©rifie si le thread QueueListener est encore actif
    """Return True if the QueueListener thread appears alive.  # retourne True si le thread du listener est vivant

    Note: uses public attributes when available.  # utilise les attributs publics du listener si disponibles
    """
    try:
        if _listener_obj is None:  # si aucun listener n‚Äôa √©t√© cr√©√©
            return False  # consid√©r√© comme inactif
        th = getattr(_listener_obj, "thread", None) or getattr(_listener_obj, "_thread", None)  # tente de r√©cup√©rer le thread interne du listener (selon version Python)
        return bool(th and getattr(th, "is_alive", lambda: False)())  # renvoie True si le thread existe et est vivant
    except Exception:
        return False  # en cas d‚Äôerreur, consid√®re que le listener n‚Äôest pas vivant


def start_health_monitor(interval: float = 5.0, depth_warn: int = 1000, depth_crit: int = 5000, notify_after: int = 1):  # d√©marre un thread de surveillance continue
    """Start a background thread that monitors the log queue and listener liveness.  # d√©marre un thread en arri√®re-plan qui surveille la file et le listener

    This monitor runs periodically and emits structured KPIs and log warnings  # il s‚Äôex√©cute p√©riodiquement et √©met des KPI structur√©s + alertes
    to help detect and alert on issues with the asynchronous logging subsystem.  # pour d√©tecter les anomalies du syst√®me de logging asynchrone

    Args:  # param√®tres d‚Äôentr√©e
        interval: seconds between checks (float). Lower values increase sensitivity.  # intervalle entre deux v√©rifications
        depth_warn: queue depth threshold to emit a WARNING.  # seuil d‚Äôalerte (taille de file)
        depth_crit: queue depth threshold to emit an ERROR.  # seuil critique (taille de file)
        notify_after: number of consecutive dead checks before emitting log_listener_down KPI.  # nb de d√©tections cons√©cutives avant alerte "listener down"

    Behavior:  # comportement d√©taill√©
        - Every `interval` seconds the monitor reads the internal log queue size  # toutes les N secondes : lit la taille de la file interne
          and emits a KPI line: kpi ts=<float> event=log_queue depth=<n> dropped=<n>  # envoie une ligne KPI sur la profondeur de la file
          where `dropped` is a best-effort read of the global drop counter (if available).  # le champ dropped provient d‚Äôun compteur global (si pr√©sent)
        - If the QueueListener appears not alive for `notify_after` consecutive checks  # si le listener est mort plusieurs fois de suite
          the monitor emits kpi ts=... event=log_listener_down consecutive=<n>  # √©met un KPI "listener down"
          and logs a WARNING on logger `igt.monitor`.  # et journalise un avertissement
        - If the queue depth exceeds `depth_warn` a WARNING is logged; if it exceeds  # si la file est trop pleine
          `depth_crit` an ERROR is logged.  # log ERROR au-del√† du seuil critique

    Restart semantics:  # politique de red√©marrage
        - The health monitor is a daemon thread; it does not attempt to auto-restart the  # c‚Äôest un thread d√©mon, il ne red√©marre pas le listener
          QueueListener itself but will continue to emit KPIs describing queue depth and  # il se contente de signaler l‚Äô√©tat via KPI
          listener liveness. External orchestration (supervisor) should react to these KPIs.  # la supervision externe doit r√©agir

    KPIs emitted:  # types de KPI g√©n√©r√©s
        - event=log_queue: depth=<int> dropped=<int>  # KPI de profondeur de file
        - event=log_listener_down: consecutive=<int>  # KPI d‚Äô√©tat du listener

    Note: KPI emission is best-effort and must never raise exceptions into the monitor loop.  # le thread ne doit jamais planter m√™me si une exception survient
    
    KPIs produced by this monitor are written via the KPI logger (typically `logs/kpi.log`).  # les KPI sont envoy√©s dans logs/kpi.log
    When the optional KPI JSONL sink is enabled (KPI_JSONL=1) a structured `logs/kpi.jsonl` file  # si KPI_JSONL=1, un fichier structur√© est aussi √©crit
    is also written by the async logging subsystem when ASYNC_LOG=1.  # (seulement si le mode async est activ√©)
    """

    global _health_thread  # d√©clare la variable globale du thread de sant√©

    def _monitor_loop():  # boucle interne ex√©cut√©e dans le thread de surveillance
        import time  # pour la temporisation
        from logging import getLogger  # r√©cup√©ration du logger interne

        log = getLogger("igt.monitor")  # logger d√©di√© aux messages du moniteur
        consecutive_dead = 0  # compteur de d√©tections cons√©cutives de listener mort
        while True:  # boucle infinie (thread d√©mon)
            try:
                q = get_log_queue()  # r√©cup√®re la file de logs
                depth = q.qsize() if q is not None else 0  # lit sa profondeur (ou 0 si non cr√©√©e)
                # emit KPI for queue depth and drops  # √©met un KPI sur la profondeur + pertes
                try:
                    from core.monitoring.kpi import safe_log_kpi, format_kpi, get_drop_count  # fonctions utilitaires KPI

                    # include current drop counters if available  # ajoute le compteur global des drops si dispo
                    drops = 0  # valeur par d√©faut
                    try:
                        drops = int(get_drop_count("acq.drop_total"))  # tente de lire le compteur global "acq.drop_total"
                    except Exception:
                        drops = 0  # en cas d‚Äô√©chec, retombe √† 0

                    kmsg = format_kpi({"ts": time.time(), "event": "log_queue", "depth": depth, "dropped": drops})  # formatte le KPI log_queue
                    safe_log_kpi(kmsg)  # envoie le KPI au logger "igt.kpi"
                except Exception:
                    log.debug("Failed to emit log_queue KPI")  # message debug si l‚Äô√©mission √©choue

                # check listener liveness  # v√©rifie la vitalit√© du listener
                alive = is_listener_alive()  # appelle la fonction pr√©c√©dente
                if not alive:  # si le listener est mort
                    consecutive_dead += 1  # incr√©mente le compteur
                    if consecutive_dead >= notify_after:  # si d√©passe le seuil de notifications
                        # warn and emit KPI once per check interval  # alerte + KPI "listener down"
                        log.warning("Async log listener appears down (consecutive=%d)", consecutive_dead)  # warning dans logs
                        try:
                            from core.monitoring.kpi import safe_log_kpi, format_kpi  # r√©import minimal
                            kmsg = format_kpi({"ts": time.time(), "event": "log_listener_down", "consecutive": consecutive_dead})  # formate KPI d‚Äô√©tat
                            safe_log_kpi(kmsg)  # envoie le KPI
                        except Exception:
                            log.debug("Failed to emit log_listener_down KPI")  # log debug si l‚Äô√©mission √©choue
                else:
                    consecutive_dead = 0  # si listener vivant, reset du compteur

                # thresholds -> warning/error via monitor logger  # compare la taille de file aux seuils
                if depth >= depth_crit:  # si d√©passe seuil critique
                    log.error("Log queue depth critical=%d", depth)  # log ERROR
                elif depth >= depth_warn:  # sinon, si d√©passe seuil d‚Äôavertissement
                    log.warning("Log queue depth warning=%d", depth)  # log WARNING

                time.sleep(interval)  # attend avant la prochaine v√©rification
            except Exception:
                try:
                    log.exception("Exception in async health monitor loop")  # logge l‚Äôexception (sans casser la boucle)
                except Exception:
                    pass  # ignore toute erreur de logging
                time.sleep(interval)  # pause avant reprise pour √©viter boucle folle

    if _health_thread is None:  # ne cr√©e le thread qu‚Äôune seule fois
        import threading  # module de threads
        _health_thread = threading.Thread(target=_monitor_loop, name="AsyncLogHealth", daemon=True)  # cr√©e un thread d√©mon pour la boucle de surveillance
        _health_thread.start()  # lance le thread
    return _health_thread  # retourne la r√©f√©rence du thread (pour tests ou suivi)

