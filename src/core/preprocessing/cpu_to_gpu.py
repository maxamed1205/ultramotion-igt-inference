"""
CPU ‚Üí GPU Transfer Utility (Process B)
======================================

üí° Mise √† jour 20/10/2025 ‚Äî version ‚Äúsingle copy_async‚Äù
-------------------------------------------------------

Ce module correspond au **Process B** dans la pipeline Ultramotion (A‚ÜíB‚ÜíC‚ÜíD) :

    A. Acquisition         ‚Üí service/plus_client.py (PlusServer ‚Üí RawFrame)
    üëâ B. Pr√©processing     ‚Üí core/preprocessing/cpu_to_gpu.py (RawFrame ‚Üí GpuFrame)
    C. Inf√©rence           ‚Üí core/inference/detection_and_engine.py (GpuFrame ‚Üí ResultPacket)
    D. Sortie vers Slicer  ‚Üí service/slicer_server.py (ResultPacket ‚Üí 3D Slicer)

R√¥le du module
--------------
Assurer **un seul transfert CPU‚ÜíGPU par frame**, de mani√®re **asynchrone** et **non bloquante**,
avant l‚Äôinf√©rence D-FINE + MobileSAM. Ce module effectue :

1. la conversion numpy ‚Üí torch.Tensor,  
2. la normalisation et mise en forme (channels_first, dtype),  
3. l‚Äôallocation en m√©moire ‚Äúpinned‚Äù (fix√©e CPU pour transfert rapide),  
4. la copie asynchrone vers le GPU (copy_async sur un stream d√©di√©).

Une fois la frame convertie en `GpuFrame`, elle est d√©pos√©e dans `Queue_GPU`
et utilis√©e directement par `detection_and_engine.py` sans nouvelle copie.

Avantages :
-----------
- ‚úÖ Une seule copie CPU‚ÜíGPU pour tout le pipeline.
- ‚úÖ Transfert asynchrone (copy + compute se chevauchent).
- ‚úÖ Compatible CUDA streams pour D-FINE / MobileSAM.
- ‚úÖ Facile √† synchroniser en aval via `stream.wait_stream()`.

Flux sch√©matique :
------------------
    RawFrame (numpy)
         ‚îÇ
         ‚ñº
    prepare_frame_for_gpu()
         ‚îÇ
     copy_async CUDA stream
         ‚îÇ
         ‚ñº
    GpuFrame(tensor, meta, stream)
         ‚îÇ
         ‚ñº
    Queue_GPU  ‚Üí detection_and_engine.py

Fonctions principales :
-----------------------
- `prepare_frame_for_gpu(frame, device)` : pr√©pare et transfert CPU‚ÜíGPU (asynchrone)
- `transfer_to_gpu_async(tensor, stream)` : copie GPU d√©di√©e (optionnelle)
- `process_one_frame()` : consomme une frame RT et alimente Queue_GPU

Ce fichier d√©finit les squelettes des fonctions, √† impl√©menter dans la phase GPU
du Process B. Aucun calcul r√©el n‚Äôest effectu√© ici.
"""

from typing import Any, Optional
import logging
import time

from core.types import RawFrame, GpuFrame
from core.queues.buffers import (
    get_queue_rt_dyn,
    get_queue_gpu,
    try_dequeue,
    enqueue_nowait_gpu,
)


LOG = logging.getLogger("igt.gpu")
LOG_KPI = logging.getLogger("igt.kpi")


# ======================================================================
# 1. Pr√©paration et transfert CPU ‚Üí GPU
# ======================================================================

def prepare_frame_for_gpu(frame: RawFrame, device: str = "cuda", config: Optional[dict] = None) -> GpuFrame:
    """
    Pr√©pare une frame CPU (numpy) pour le GPU, via un **seul transfert asynchrone**.

    √âtapes attendues (√† impl√©menter) :
      1. Validation de la forme et du dtype (float32, [C,H,W]).
      2. Normalisation des intensit√©s (ex : /255.0 ou mean/std).
      3. Allocation m√©moire CPU en pinned memory.
      4. Transfert asynchrone vers GPU via `torch.cuda.Stream`.

    Args:
        frame: RawFrame contenant l‚Äôimage CPU (numpy array ou buffer √©quivalent).
        device: cible du transfert ('cuda', 'cuda:0', etc.)
        config: dictionnaire optionnel (normalisation, dtype, scale, etc.)

    Returns:
        GpuFrame : objet contenant le tensor GPU, les m√©tadonn√©es et le stream CUDA associ√©.

    Notes :
        - L‚Äôobjectif est d‚Äôassurer que **toute la pipeline C (inf√©rence)** travaille
          sur ce tensor unique sans reconversion CPU‚ÜíGPU.
        - Le transfert asynchrone permet le chevauchement avec le calcul du frame pr√©c√©dent.
    """
    raise NotImplementedError


def transfer_to_gpu_async(tensor: Any, stream_transfer: Optional[Any] = None, device: str = "cuda") -> Any:
    """
    Effectue un transfert asynchrone CPU‚ÜíGPU sur un stream CUDA fourni.

    Args:
        tensor: tensor CPU (torch.Tensor sur device='cpu').
        stream_transfer: stream CUDA d√©di√© au transfert.
        device: cible GPU ('cuda', 'cuda:0', etc.).

    Returns:
        tensor GPU (torch.Tensor sur le device cible).

    Comportement attendu :
        - Utiliser `with torch.cuda.stream(stream_transfer):`
          puis `tensor.to(device, non_blocking=True)`.
        - Retourner le tensor GPU pour r√©utilisation imm√©diate.
    """
    raise NotImplementedError


# ======================================================================
# 2. Int√©gration dans la boucle pipeline A‚ÜíB
# ======================================================================

def process_one_frame(config: Optional[dict] = None) -> None:
    """
    Consomme une RawFrame depuis la queue temps r√©el, effectue la pr√©paration GPU,
    et d√©pose le r√©sultat dans Queue_GPU (√©tape B du pipeline).

    √âtapes :
        1. D√©file une frame de Queue_RT_dyn (non bloquant).
        2. Appelle prepare_frame_for_gpu().
        3. Envoie le GpuFrame vers Queue_GPU (non bloquant).

    Notes :
        - Les m√©triques de saturation Queue_GPU sont publi√©es via KPI logs.
        - Les transferts asynchrones permettent le chevauchement CPU/GPU.
    """
    q_rt = get_queue_rt_dyn()
    raw = try_dequeue(q_rt)
    if raw is None:
        return

    if LOG.isEnabledFor(logging.DEBUG):
        fid = getattr(getattr(raw, "meta", None), "frame_id", None)
        LOG.debug("Dequeued RawFrame %s from RT queue", fid)

    # Pr√©paration GPU (asynchrone)
    gpu_frame = prepare_frame_for_gpu(raw)

    # Envoi vers la queue GPU
    q_gpu = get_queue_gpu()
    ok = enqueue_nowait_gpu(q_gpu, gpu_frame)

    if not ok:
        LOG.warning("GPU queue full, frame %s dropped", getattr(raw, "meta", None) and getattr(raw.meta, "frame_id", None))
        try:
            from core.monitoring.kpi import safe_log_kpi, format_kpi
            msg = format_kpi({
                "ts": time.time(),
                "event": "gpu_saturation",
                "frame": getattr(raw, "meta", None) and getattr(raw.meta, "frame_id", None),
                "q_gpu": q_gpu.qsize(),
            })
            safe_log_kpi(msg)
        except Exception:
            LOG.debug("Failed to emit KPI gpu_saturation")

    return