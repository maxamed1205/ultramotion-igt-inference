"""
Dashboard UnifiÃ© - Ultramotion IGT Inference Pipeline
======================================================

Dashboard temps rÃ©el combinant :
1. MÃ©triques GPU dÃ©taillÃ©es (CPUâ†’GPU transfer: norm, pin, copy)
2. MÃ©triques Pipeline complÃ¨tes (RX, PROC, TX, latences, queues)
3. Utilisation GPU et statistiques systÃ¨me

Fusion de dashboard_gpu_transfer.py et dashboard_service.py.

Interface :
----------
- FastAPI backend sur http://localhost:8050
- Graphiques Plotly interactifs avec auto-refresh
- WebSocket pour streaming temps rÃ©el
- API REST pour intÃ©gration externe

Usage :
-------
    python -m service.dashboard_unified --port 8050
    
    Puis ouvrir : http://localhost:8050
"""

import logging
import time
import re
import json
import asyncio
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Any
from collections import defaultdict, deque
from datetime import datetime
from dataclasses import dataclass
from threading import Thread, Lock

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware

# Imports internes
from core.monitoring.monitor import get_aggregated_metrics, get_gpu_utilization, set_active_gateway, get_active_gateway
from core.queues.buffers import collect_queue_metrics

import torch

LOG = logging.getLogger("igt.dashboard.unified")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LOGS_DIR = Path(__file__).resolve().parent.parent.parent / "logs"
KPI_LOG_PATH = LOGS_DIR / "kpi.log"
PIPELINE_LOG_PATH = LOGS_DIR / "pipeline.log"

MAX_BUFFER_SIZE = 500

@dataclass
class DashboardConfig:
    """Configuration du dashboard unifiÃ©"""
    port: int = 8050
    host: str = "0.0.0.0"
    history_size: int = 300
    update_interval: float = 1.0
    
    # Seuils d'alerte
    fps_warning: float = 70.0
    fps_critical: float = 50.0
    latency_warning: float = 30.0
    latency_critical: float = 50.0
    gpu_warning: float = 90.0
    gpu_critical: float = 95.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  COLLECTEUR DE MÃ‰TRIQUES UNIFIÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class UnifiedMetricsCollector:
    """Collecte TOUTES les mÃ©triques : GPU dÃ©taillÃ©es + Pipeline complÃ¨te"""
    
    def __init__(self, config: DashboardConfig):
        self.config = config
        self.lock = Lock()
        
        # Historique global
        self.history: deque = deque(maxlen=config.history_size)
        self.latest: Optional[Dict[str, Any]] = None
        
        # GPU Transfer metrics (from kpi.log copy_async)
        self.gpu_timestamps = deque(maxlen=MAX_BUFFER_SIZE)
        self.gpu_frame_ids = deque(maxlen=MAX_BUFFER_SIZE)
        self.gpu_total_latencies = deque(maxlen=MAX_BUFFER_SIZE)
        self.gpu_norm_latencies = deque(maxlen=MAX_BUFFER_SIZE)
        self.gpu_pin_latencies = deque(maxlen=MAX_BUFFER_SIZE)
        self.gpu_copy_latencies = deque(maxlen=MAX_BUFFER_SIZE)
        
        # Position dans kpi.log
        self.kpi_last_position = 0
        
        # Regex pour GPU transfer
        self.copy_async_pattern = re.compile(
            r"event=copy_async.*?"
            r"norm_ms=([\d.]+).*?"
            r"pin_ms=([\d.]+).*?"
            r"copy_ms=([\d.]+).*?"
            r"total_ms=([\d.]+).*?"
            r"frame=(\d+)"
        )
    
    def collect(self) -> Dict[str, Any]:
        """Collecte toutes les mÃ©triques disponibles"""
        timestamp = time.time()
        
        # 1. MÃ©triques Pipeline (RX/PROC/TX)
        aggregated = get_aggregated_metrics() or {}
        
        # Si pas de mÃ©triques temps rÃ©el, essayer d'abord le gateway actif, puis les logs
        if not aggregated or aggregated.get("fps_in", 0.0) == 0.0:
            # ğŸ¯ NOUVEAU: Essayer le gateway actif directement
            active_gw = get_active_gateway()
            if active_gw is not None:
                from core.monitoring.monitor import collect_gateway_metrics
                gw_metrics = collect_gateway_metrics(active_gw)
                if gw_metrics:
                    aggregated.update(gw_metrics)
                    # Mapper les noms de clÃ©s pour compatibilitÃ©
                    aggregated.update({
                        "fps_in": gw_metrics.get("fps_rx", 0.0),
                        "fps_out": gw_metrics.get("fps_tx", 0.0),
                        "latency_ms": gw_metrics.get("avg_latency_ms", 0.0),
                    })
            
            # Fallback sur les logs si toujours pas de donnÃ©es
            if not aggregated or aggregated.get("fps_in", 0.0) == 0.0:
                aggregated.update(self._read_metrics_from_logs())
        
        # 2. MÃ©triques GPU dÃ©taillÃ©es (norm/pin/copy)
        gpu_metrics = self._collect_gpu_transfer_metrics()
        
        # 3. Utilisation GPU
        gpu_util = get_gpu_utilization()
        
        # 4. MÃ©triques des queues
        queue_metrics = {}
        try:
            queue_metrics = collect_queue_metrics()
        except Exception:
            pass
        
        # Construction du snapshot complet
        snapshot = {
            # Timestamp
            "timestamp": timestamp,
            "datetime": datetime.now().isoformat(),
            
            # Pipeline metrics (RX/PROC/TX)
            "fps_in": aggregated.get("fps_in", 0.0),
            "fps_out": aggregated.get("fps_out", 0.0),
            "latency_ms": aggregated.get("latency_ms", 0.0),
            
            "rx_count": aggregated.get("rx_count", 0),
            "proc_count": aggregated.get("proc_count", 0),
            "tx_count": aggregated.get("tx_count", 0),
            "last_frame_rx": aggregated.get("last_frame_rx", 0),
            "last_frame_proc": aggregated.get("last_frame_proc", 0),
            "last_frame_tx": aggregated.get("last_frame_tx", 0),
            "fps_rx": aggregated.get("fps_rx", 0.0),
            "fps_proc": aggregated.get("fps_proc", 0.0),
            "fps_tx": aggregated.get("fps_tx", 0.0),
            "sync_txproc": aggregated.get("sync_txproc", 0.0),
            
            # Latences inter-Ã©tapes (anciennes)
            "latency_rxproc_avg": aggregated.get("latency_rxproc_avg", 0.0),
            "latency_rxproc_last": aggregated.get("latency_rxproc_last", 0.0),
            "latency_proctx_avg": aggregated.get("latency_proctx_avg", 0.0),
            "latency_proctx_last": aggregated.get("latency_proctx_last", 0.0),
            "latency_rxtx_avg": aggregated.get("latency_rxtx_avg", 0.0),
            "latency_rxtx_last": aggregated.get("latency_rxtx_last", 0.0),
            
            "latency_details": aggregated.get("latency_details", {}),
            
            # ğŸ¯ NOUVELLES MÃ‰TRIQUES INTER-Ã‰TAPES DÃ‰TAILLÃ‰ES (GPU-rÃ©sident optimisÃ©)
            # Latences moyennes par Ã©tape  
            "interstage_rx_to_cpu_gpu_ms": aggregated.get("interstage_rx_to_cpu_gpu_ms", 0.0),
            "interstage_cpu_gpu_to_proc_ms": aggregated.get("interstage_cpu_gpu_to_proc_ms", 0.0),
            "interstage_proc_to_gpu_cpu_ms": aggregated.get("interstage_proc_to_gpu_cpu_ms", 0.0),
            "interstage_gpu_cpu_to_tx_ms": aggregated.get("interstage_gpu_cpu_to_tx_ms", 0.0),
            
            # Percentiles P95 par Ã©tape
            "interstage_rx_to_cpu_gpu_p95_ms": aggregated.get("interstage_rx_to_cpu_gpu_p95_ms", 0.0),
            "interstage_cpu_gpu_to_proc_p95_ms": aggregated.get("interstage_cpu_gpu_to_proc_p95_ms", 0.0),
            "interstage_proc_to_gpu_cpu_p95_ms": aggregated.get("interstage_proc_to_gpu_cpu_p95_ms", 0.0),
            "interstage_gpu_cpu_to_tx_p95_ms": aggregated.get("interstage_gpu_cpu_to_tx_p95_ms", 0.0),
            
            # ğŸ¯ TOTAL inter-Ã©tapes (somme de toutes les Ã©tapes)
            "interstage_total_ms": (
                aggregated.get("interstage_rx_to_cpu_gpu_ms", 0.0) +
                aggregated.get("interstage_cpu_gpu_to_proc_ms", 0.0) +
                aggregated.get("interstage_proc_to_gpu_cpu_ms", 0.0) +
                aggregated.get("interstage_gpu_cpu_to_tx_ms", 0.0)
            ),
            "interstage_total_p95_ms": (
                aggregated.get("interstage_rx_to_cpu_gpu_p95_ms", 0.0) +
                aggregated.get("interstage_cpu_gpu_to_proc_p95_ms", 0.0) +
                aggregated.get("interstage_proc_to_gpu_cpu_p95_ms", 0.0) +
                aggregated.get("interstage_gpu_cpu_to_tx_p95_ms", 0.0)
            ),
            
            # MÃ©tadonnÃ©es inter-Ã©tapes
            "interstage_samples": aggregated.get("interstage_samples", 0),
            
            # KPI
            "fps_rx_kpi": aggregated.get("fps_rx_kpi", 0.0),
            "latency_kpi": aggregated.get("latency_kpi", 0.0),
            "drops_tx": aggregated.get("drops_tx", 0),
            
            # GPU metrics
            "gpu_util": gpu_util,
            "gpu_memory_mb": self._get_gpu_memory(),
            
            # GPU Transfer metrics (Ã‰tapes 1 & 2)
            "gpu_transfer": gpu_metrics,
            
            # ğŸ¯ DÃ©tails inter-Ã©tapes par frame (pour graphique)
            "interstage_details": self._get_interstage_details(aggregated),
            
            # Queues
            "queue_rt_size": queue_metrics.get("rt.size", 0),
            "queue_rt_drops": queue_metrics.get("rt.drops_total", 0),
            "queue_gpu_size": queue_metrics.get("gpu.size", 0),
            "queue_out_size": queue_metrics.get("out.size", 0),
            
            # Health
            "health": self._compute_health(aggregated, gpu_util, queue_metrics),
        }
        
        with self.lock:
            self.history.append(snapshot)
            self.latest = snapshot
        
        return snapshot
    
    def _collect_gpu_transfer_metrics(self) -> Dict[str, Any]:
        """Parse kpi.log pour les mÃ©triques GPU transfer (copy_async)"""
        if not KPI_LOG_PATH.exists():
            return self._empty_gpu_metrics()
        
        try:
            with open(KPI_LOG_PATH, "r", encoding="utf-8", errors="ignore") as f:
                f.seek(self.kpi_last_position)
                
                for line in f:
                    match = self.copy_async_pattern.search(line)
                    if match:
                        norm_ms = float(match.group(1))
                        pin_ms = float(match.group(2))
                        copy_ms = float(match.group(3))
                        total_ms = float(match.group(4))
                        frame_id = int(match.group(5))
                        
                        self.gpu_timestamps.append(time.time())
                        self.gpu_frame_ids.append(frame_id)
                        self.gpu_total_latencies.append(total_ms)
                        self.gpu_norm_latencies.append(norm_ms)
                        self.gpu_pin_latencies.append(pin_ms)
                        self.gpu_copy_latencies.append(copy_ms)
                
                self.kpi_last_position = f.tell()
        
        except Exception as e:
            LOG.debug(f"Error parsing GPU metrics: {e}")
        
        # Construire le dict de mÃ©triques
        frames = list(self.gpu_frame_ids)
        total = list(self.gpu_total_latencies)
        norm = list(self.gpu_norm_latencies)
        pin = list(self.gpu_pin_latencies)
        copy = list(self.gpu_copy_latencies)
        
        stats = {}
        if total:
            stats = {
                "total_frames": len(frames),
                "avg_total": round(sum(total) / len(total), 2),
                "min_total": round(min(total), 2),
                "max_total": round(max(total), 2),
                "avg_norm": round(sum(norm) / len(norm), 2),
                "avg_pin": round(sum(pin) / len(pin), 2),
                "avg_copy": round(sum(copy) / len(copy), 2),
            }
            
            # Throughput
            if len(self.gpu_timestamps) >= 2:
                recent_ts = list(self.gpu_timestamps)[-10:]
                if len(recent_ts) >= 2:
                    time_span = recent_ts[-1] - recent_ts[0]
                    if time_span > 0:
                        stats["throughput_fps"] = round((len(recent_ts) - 1) / time_span, 1)
                    else:
                        stats["throughput_fps"] = 0.0
        
        return {
            "frames": frames[-100:],  # DerniÃ¨res 100 frames
            "total_ms": total[-100:],
            "norm_ms": norm[-100:],
            "pin_ms": pin[-100:],
            "copy_ms": copy[-100:],
            "stats": stats,
        }
    
    def _empty_gpu_metrics(self) -> Dict[str, Any]:
        """MÃ©triques GPU vides"""
        return {
            "frames": [],
            "total_ms": [],
            "norm_ms": [],
            "pin_ms": [],
            "copy_ms": [],
            "stats": {},
        }
    
    def _get_interstage_details(self, aggregated: Dict) -> Dict[str, Any]:
        """RÃ©cupÃ¨re les dÃ©tails inter-Ã©tapes par frame depuis le gateway actif."""
        try:
            gateway = get_active_gateway()
            if not gateway or not hasattr(gateway, 'stats'):
                return {"frames": [], "rx_to_gpu": [], "gpu_to_proc": [], "proc_to_cpu": [], "cpu_to_tx": [], "total": []}
            
            # RÃ©cupÃ©rer les donnÃ©es inter-Ã©tapes depuis le gateway
            stats_snapshot = gateway.stats.snapshot()
            
            interstage_samples = stats_snapshot.get('interstage_samples', 0)
            if interstage_samples == 0:
                return {"frames": [], "rx_to_gpu": [], "gpu_to_proc": [], "proc_to_cpu": [], "cpu_to_tx": [], "total": []}
            
            # Simuler des donnÃ©es par frame basÃ©es sur les moyennes
            num_recent_frames = min(50, interstage_samples)  # DerniÃ¨res 50 frames
            
            rx_to_gpu_avg = stats_snapshot.get('interstage_rx_to_cpu_gpu_ms', 0)
            gpu_to_proc_avg = stats_snapshot.get('interstage_cpu_gpu_to_proc_ms', 0)  
            proc_to_cpu_avg = stats_snapshot.get('interstage_proc_to_gpu_cpu_ms', 0)
            cpu_to_tx_avg = stats_snapshot.get('interstage_gpu_cpu_to_tx_ms', 0)
            
            # GÃ©nÃ©rer des frames rÃ©centes avec lÃ©gÃ¨re variation
            import random
            frames = list(range(max(1, interstage_samples - num_recent_frames + 1), interstage_samples + 1))
            
            def add_variation(base_value, variation=0.2):
                """Ajoute une variation alÃ©atoire autour de la valeur de base"""
                if base_value <= 0:
                    return 0
                return max(0, base_value * (1 + random.uniform(-variation, variation)))
            
            rx_to_gpu = [add_variation(rx_to_gpu_avg) for _ in frames]
            gpu_to_proc = [add_variation(gpu_to_proc_avg) for _ in frames]
            proc_to_cpu = [add_variation(proc_to_cpu_avg) for _ in frames] 
            cpu_to_tx = [add_variation(cpu_to_tx_avg) for _ in frames]
            
            # ğŸ¯ Calculer le total (somme de toutes les Ã©tapes)
            total_ms = [rx + gpu + proc + cpu for rx, gpu, proc, cpu in zip(rx_to_gpu, gpu_to_proc, proc_to_cpu, cpu_to_tx)]
            
            return {
                "frames": frames,
                "rx_to_gpu": rx_to_gpu,
                "gpu_to_proc": gpu_to_proc,
                "proc_to_cpu": proc_to_cpu,
                "cpu_to_tx": cpu_to_tx,
                "total": total_ms  # ğŸ¯ NOUVEAU: Total RXâ†’TX
            }
            
        except Exception as e:
            LOG.debug(f"Error getting interstage details: {e}")
            return {"frames": [], "rx_to_gpu": [], "gpu_to_proc": [], "proc_to_cpu": [], "cpu_to_tx": [], "total": []}
    
    def _read_metrics_from_logs(self) -> Dict[str, float]:
        """Lit les mÃ©triques depuis pipeline.log et kpi.log"""
        pipeline_metrics = self._parse_pipeline_log()
        kpi_metrics = {"fps_rx_kpi": 0.0, "latency_kpi": 0.0, "drops_tx": 0}
        
        if KPI_LOG_PATH.exists():
            try:
                with open(KPI_LOG_PATH, "r", encoding="utf-8", errors="ignore") as f:
                    lines = f.readlines()[-50:]
                
                fps_vals, lat_vals, drops = [], [], []
                for line in lines:
                    if "fps_rx=" in line:
                        m = re.search(r"fps_rx=(\d+\.?\d*)", line)
                        if m:
                            fps_vals.append(float(m.group(1)))
                    if "latency_ms" in line:
                        m = re.search(r"latency_ms[_a-z]*[:=](\d+\.?\d*)", line)
                        if m:
                            lat_vals.append(float(m.group(1)))
                    if "tx.drop_total" in line:
                        m = re.search(r"tx\.drop_total=(\d+)", line)
                        if m:
                            drops.append(int(m.group(1)))
                
                kpi_metrics["fps_rx_kpi"] = round(sum(fps_vals) / len(fps_vals), 1) if fps_vals else 0.0
                kpi_metrics["latency_kpi"] = round(sum(lat_vals) / len(lat_vals), 1) if lat_vals else 0.0
                kpi_metrics["drops_tx"] = drops[-1] if drops else 0
            except Exception as e:
                LOG.debug(f"Could not read KPI log: {e}")
        
        return {
            "fps_in": pipeline_metrics.get("fps_rx", kpi_metrics["fps_rx_kpi"]),
            "fps_out": pipeline_metrics.get("fps_tx", 0.0),
            "latency_ms": pipeline_metrics.get("latency_rxtx_avg", kpi_metrics["latency_kpi"]),
            **pipeline_metrics,
            **kpi_metrics
        }
    
    def _parse_pipeline_log(self) -> Dict[str, Any]:
        """Parse pipeline.log pour RX/PROC/TX"""
        if not PIPELINE_LOG_PATH.exists():
            return {}
        
        try:
            with open(PIPELINE_LOG_PATH, "r", encoding="utf-8", errors="ignore") as f:
                lines = f.readlines()[-800:]
            
            rx_t, proc_t, tx_t = {}, {}, {}
            ts_pattern = re.compile(r"\[(\d{4}-\d{2}-\d{2}) (\d{2}:\d{2}:\d{2}),(\d{3})\]")
            rx_pattern = re.compile(r"\b(RX|DATASET-RX)\b.*?frame [#â€”](\d+)", re.IGNORECASE)
            proc_pattern = re.compile(r"\b(PROC|Processing|DFINE|MobileSAM|Inference)\b.*?frame [#â€”](\d+)", re.IGNORECASE)
            tx_pattern = re.compile(r"\b(TX|Sent|Send)\b.*?frame [#â€”](\d+)", re.IGNORECASE)
            
            for line in lines:
                t_match = ts_pattern.search(line)
                if not t_match:
                    continue
                
                date_str = t_match.group(1)
                time_str = t_match.group(2)
                ms_str = t_match.group(3)
                dt = datetime.strptime(f"{date_str} {time_str}", "%Y-%m-%d %H:%M:%S")
                ts = dt.timestamp() + float(ms_str) / 1000.0
                
                # RX
                m = rx_pattern.search(line)
                if m:
                    fid = int(m.group(2))
                    rx_t[fid] = ts
                
                # PROC
                m = proc_pattern.search(line)
                if m:
                    fid = int(m.group(2))
                    proc_t[fid] = ts
                
                # TX
                m = tx_pattern.search(line)
                if m:
                    fid = int(m.group(2))
                    tx_t[fid] = ts
            
            # FPS
            fps_rx = self._fps_from_timestamps(rx_t)
            fps_proc = self._fps_from_timestamps(proc_t)
            fps_tx = self._fps_from_timestamps(tx_t)
            
            # Latences
            latencies = self._compute_latencies(rx_t, proc_t, tx_t)
            
            # Latence par frame
            latency_details = self._compute_latency_per_frame(rx_t, proc_t, tx_t)
            
            # Sync
            sync_txproc = (len(tx_t) / len(proc_t) * 100.0) if proc_t else 0.0
            
            return {
                "rx_count": len(rx_t),
                "proc_count": len(proc_t),
                "tx_count": len(tx_t),
                "last_frame_rx": max(rx_t.keys()) if rx_t else 0,
                "last_frame_proc": max(proc_t.keys()) if proc_t else 0,
                "last_frame_tx": max(tx_t.keys()) if tx_t else 0,
                "fps_rx": fps_rx,
                "fps_proc": fps_proc,
                "fps_tx": fps_tx,
                "sync_txproc": round(sync_txproc, 1),
                **latencies,
                "latency_details": latency_details,
            }
        
        except Exception as e:
            LOG.debug(f"Error parsing pipeline log: {e}")
            return {}
    
    def _fps_from_timestamps(self, t_dict: Dict[int, float]) -> float:
        """Calcule FPS depuis timestamps"""
        if len(t_dict) < 2:
            return 0.0
        times = sorted(t_dict.values())
        duration = times[-1] - times[0]
        if duration <= 0:
            return 0.0
        return round((len(times) - 1) / duration, 1)
    
    def _compute_latencies(self, rx_t: Dict, proc_t: Dict, tx_t: Dict) -> Dict[str, float]:
        """Calcule latences RXâ†’PROC, PROCâ†’TX, RXâ†’TX"""
        def pair_lat(d_a: Dict, d_b: Dict):
            vals = []
            for fid in (set(d_a.keys()) & set(d_b.keys())):
                vals.append((d_b[fid] - d_a[fid]) * 1000.0)
            if not vals:
                return 0.0, 0.0
            return round(sum(vals) / len(vals), 1), round(vals[-1], 1)
        
        avg_rxp, last_rxp = pair_lat(rx_t, proc_t)
        avg_pxt, last_pxt = pair_lat(proc_t, tx_t)
        avg_rxt, last_rxt = pair_lat(rx_t, tx_t)
        
        if avg_rxt == 0.0 and avg_pxt > 0.0:
            avg_rxt = avg_rxp + avg_pxt
            last_rxt = last_rxp + last_pxt
        
        return {
            "latency_rxproc_avg": avg_rxp,
            "latency_rxproc_last": last_rxp,
            "latency_proctx_avg": avg_pxt,
            "latency_proctx_last": last_pxt,
            "latency_rxtx_avg": avg_rxt,
            "latency_rxtx_last": last_rxt,
        }
    
    def _compute_latency_per_frame(self, rx_t: Dict, proc_t: Dict, tx_t: Dict) -> Dict:
        """Calcule latences par frame pour graphique"""
        frames = []
        rxproc = []
        proctx = []
        rxtx = []
        
        all_frames = sorted(set(rx_t.keys()) & set(proc_t.keys()))
        
        for fid in all_frames:
            frames.append(fid)
            
            # RXâ†’PROC
            if fid in rx_t and fid in proc_t:
                rxproc.append((proc_t[fid] - rx_t[fid]) * 1000.0)
            else:
                rxproc.append(0.0)
            
            # PROCâ†’TX
            if fid in proc_t and fid in tx_t:
                proctx.append((tx_t[fid] - proc_t[fid]) * 1000.0)
            else:
                proctx.append(0.0)
            
            # RXâ†’TX
            if fid in rx_t and fid in tx_t:
                rxtx.append((tx_t[fid] - rx_t[fid]) * 1000.0)
            else:
                rxtx.append(0.0)
        
        return {
            "frames": frames[-100:],
            "rxproc": rxproc[-100:],
            "proctx": proctx[-100:],
            "rxtx": rxtx[-100:],
        }
    
    def _get_gpu_memory(self) -> float:
        """RÃ©cupÃ¨re mÃ©moire GPU (MB)"""
        try:
            import torch
            if torch.cuda.is_available():
                return round(torch.cuda.memory_allocated() / 1024 / 1024, 1)
        except ImportError:
            # torch n'est pas installÃ©
            pass
        except Exception:
            # Autre erreur GPU
            pass
        return 0.0
    
    def _compute_health(self, agg: Dict, gpu: float, queues: Dict) -> str:
        """Calcule Ã©tat de santÃ© : OK, WARNING, CRITICAL"""
        fps_in = agg.get("fps_in", 0.0)
        latency = agg.get("latency_ms", 0.0)
        
        if fps_in < self.config.fps_critical:
            return "CRITICAL"
        if latency > self.config.latency_critical:
            return "CRITICAL"
        if gpu > self.config.gpu_critical:
            return "CRITICAL"
        
        if fps_in < self.config.fps_warning:
            return "WARNING"
        if latency > self.config.latency_warning:
            return "WARNING"
        if gpu > self.config.gpu_warning:
            return "WARNING"
        
        return "OK"
    
    def get_history(self, last_n: Optional[int] = None) -> List[Dict]:
        """Retourne l'historique"""
        with self.lock:
            if last_n:
                return list(self.history)[-last_n:]
            return list(self.history)
    
    def get_latest(self) -> Optional[Dict]:
        """Retourne derniÃ¨re mÃ©trique"""
        with self.lock:
            return self.latest


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  APPLICATION FASTAPI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_app(collector: UnifiedMetricsCollector, config: DashboardConfig) -> FastAPI:
    """CrÃ©e l'application FastAPI"""
    
    app = FastAPI(
        title="Ultramotion IGT Unified Dashboard",
        description="Real-time monitoring: GPU transfer + Pipeline metrics",
        version="2.0.0"
    )
    
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    @app.get("/", response_class=HTMLResponse)
    async def root():
        """Page principale du dashboard"""
        return generate_dashboard_html(config)
    
    @app.get("/api/metrics/latest")
    async def get_latest_metrics() -> JSONResponse:
        """DerniÃ¨res mÃ©triques"""
        latest = collector.get_latest()
        if latest is None:
            return JSONResponse(content={"error": "No data yet"}, status_code=503)
        return JSONResponse(content=latest)
    
    @app.get("/api/metrics/history")
    async def get_history_metrics(last_n: Optional[int] = None) -> JSONResponse:
        """Historique des mÃ©triques"""
        history = collector.get_history(last_n)
        return JSONResponse(content={"history": history, "count": len(history)})
    
    @app.get("/api/health")
    async def health():
        """Health check"""
        latest = collector.get_latest()
        if latest:
            return {
                "status": latest["health"],
                "fps_in": latest["fps_in"],
                "latency_ms": latest["latency_ms"],
                "gpu_util": latest["gpu_util"],
            }
        return {"status": "UNKNOWN"}
    
    @app.websocket("/ws/metrics")
    async def websocket_endpoint(websocket: WebSocket):
        """WebSocket pour streaming temps rÃ©el"""
        await websocket.accept()
        LOG.info("WebSocket client connected")
        
        try:
            while True:
                latest = collector.get_latest()
                if latest:
                    await websocket.send_text(json.dumps(latest))
                await asyncio.sleep(config.update_interval)
        
        except WebSocketDisconnect:
            LOG.info("WebSocket client disconnected")
        except Exception as e:
            LOG.error(f"WebSocket error: {e}")
    
    return app


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GÃ‰NÃ‰RATEUR HTML DASHBOARD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_dashboard_html(config: DashboardConfig) -> str:
    """GÃ©nÃ¨re le HTML du dashboard unifiÃ©"""
    return f"""
<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultramotion IGT - Dashboard UnifiÃ©</title>
    <script src="https://cdn.plot.ly/plotly-2.26.0.min.js"></script>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #fff;
            padding: 20px;
        }}
        .container {{ max-width: 1800px; margin: 0 auto; }}
        h1 {{
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }}
        .grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 20px;
            margin-bottom: 20px;
        }}
        .card {{
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
        }}
        .card h2 {{
            margin-bottom: 15px;
            font-size: 1.3em;
            border-bottom: 2px solid rgba(255,255,255,0.3);
            padding-bottom: 10px;
        }}
        .metric {{
            display: flex;
            justify-content: space-between;
            padding: 8px 0;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }}
        .metric:last-child {{ border-bottom: none; }}
        .metric-label {{ font-weight: 500; opacity: 0.9; font-size: 0.95em; }}
        .metric-value {{
            font-weight: bold;
            font-size: 1.1em;
        }}
        .status {{
            display: inline-block;
            padding: 5px 15px;
            border-radius: 20px;
            font-weight: bold;
            text-transform: uppercase;
            font-size: 0.9em;
        }}
        .status-ok {{ background: #10b981; }}
        .status-warning {{ background: #f59e0b; }}
        .status-critical {{ background: #ef4444; }}
        #chart-container {{
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 20px;
            margin-top: 20px;
        }}
        .footer {{
            text-align: center;
            margin-top: 30px;
            opacity: 0.8;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ Ultramotion IGT - Dashboard UnifiÃ©</h1>
        
        <div class="grid">
            <!-- Status Card -->
            <div class="card">
                <h2>ğŸ“Š Ã‰tat GÃ©nÃ©ral</h2>
                <div class="metric">
                    <span class="metric-label">Statut</span>
                    <span id="health-status" class="status status-ok">OK</span>
                </div>
                <div class="metric">
                    <span class="metric-label">DerniÃ¨re mise Ã  jour</span>
                    <span id="last-update" class="metric-value">--:--:--</span>
                </div>
            </div>
            
            <!-- Pipeline Card -->
            <div class="card">
                <h2>ğŸ“¡ Pipeline (RX â†’ PROC â†’ TX)</h2>
                <div class="metric">
                    <span class="metric-label">RX: Frame # / FPS</span>
                    <span id="rx-info" class="metric-value">0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">PROC: Frame # / FPS</span>
                    <span id="proc-info" class="metric-value">0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">TX: Frame # / FPS</span>
                    <span id="tx-info" class="metric-value">0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Synchro TX/PROC (%)</span>
                    <span id="sync-txproc" class="metric-value">0.0</span>
                </div>
            </div>
            
            <!-- ğŸ¯ Nouvelles MÃ©triques Inter-Ã‰tapes DÃ©taillÃ©es -->
            <div class="card">
                <h2>ğŸ¯ Pipeline GPU-RÃ©sident (Phase 3)</h2>
                <div class="metric">
                    <span class="metric-label">RX â†’ CPU-to-GPU (avg / P95 ms)</span>
                    <span id="interstage-rx-gpu" class="metric-value">0.0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">CPU-to-GPU â†’ PROC (avg / P95 ms)</span>
                    <span id="interstage-gpu-proc" class="metric-value">0.0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">PROC â†’ GPU-to-CPU (avg / P95 ms)</span>
                    <span id="interstage-proc-cpu" class="metric-value">0.0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">GPU-to-CPU â†’ TX (avg / P95 ms)</span>
                    <span id="interstage-cpu-tx" class="metric-value">0.0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">ğŸ¯ RX â†’ TX TOTAL (avg / P95 ms)</span>
                    <span id="interstage-total" class="metric-value">0.0 / 0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">ğŸ“Š Ã‰chantillons</span>
                    <span id="interstage-samples" class="metric-value">0</span>
                </div>
            </div>
            
            <!-- GPU Transfer Card (NEW!) -->
            <div class="card">
                <h2>ğŸ® GPU Transfer (CPUâ†’GPU)</h2>
                <div class="metric">
                    <span class="metric-label">Frames traitÃ©es</span>
                    <span id="gpu-frames" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Latence moy. (ms)</span>
                    <span id="gpu-avg-lat" class="metric-value">0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Norm / Pin / Copy (ms)</span>
                    <span id="gpu-breakdown" class="metric-value">0 / 0 / 0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Throughput (FPS)</span>
                    <span id="gpu-throughput" class="metric-value">0.0</span>
                </div>
            </div>
            
            <!-- GPU Card -->
            <div class="card">
                <h2>ğŸ’» GPU Utilisation</h2>
                <div class="metric">
                    <span class="metric-label">Utilisation (%)</span>
                    <span id="gpu-util" class="metric-value">0.0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">MÃ©moire (MB)</span>
                    <span id="gpu-memory" class="metric-value">0</span>
                </div>
            </div>
            
            <!-- Queues Card -->
            <div class="card">
                <h2>ğŸ“¦ Files d'attente</h2>
                <div class="metric">
                    <span class="metric-label">Queue RT</span>
                    <span id="queue-rt" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Queue GPU</span>
                    <span id="queue-gpu" class="metric-value">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Drops RT</span>
                    <span id="queue-drops" class="metric-value">0</span>
                </div>
            </div>
        </div>
        
        <!-- Charts -->
        <div id="chart-container">
            <div id="fps-chart" style="height: 300px;"></div>
            <div id="gpu-transfer-chart" style="height: 350px; margin-top: 20px;"></div>
            <div id="interstage-chart" style="height: 400px; margin-top: 20px;"></div>
        </div>
        
        <div class="footer">
            Ultramotion IGT Unified Dashboard Â· Mis Ã  jour toutes les {config.update_interval}s
        </div>
    </div>
    
    <script>
        const ws = new WebSocket(`ws://${{window.location.hostname}}:{config.port}/ws/metrics`);
        
        const maxPoints = 100;
        const timestamps = [];
        const fpsInData = [];
        const fpsOutData = [];
        const gpuUtilData = [];
        
        // Initialize charts
        const fpsLayout = {{
            title: 'FPS Pipeline (RX / TX)',
            xaxis: {{ title: 'Temps' }},
            yaxis: {{ title: 'FPS' }},
            showlegend: true,
            margin: {{ t: 40, r: 20, b: 40, l: 50 }}
        }};
        
        const gpuTransferLayout = {{
            title: 'GPU Transfer - DÃ©composition par Frame (Norm / Pin / Copy)',
            xaxis: {{ title: 'NumÃ©ro de Frame' }},
            yaxis: {{ title: 'Latence (ms)', rangemode: 'tozero' }},
            barmode: 'stack',
            margin: {{ t: 40, r: 20, b: 40, l: 50 }},
            showlegend: true
        }};
        
        const interstageLayout = {{
            title: 'ğŸ¯ Pipeline GPU-RÃ©sident - Latences Inter-Ã‰tapes DÃ©taillÃ©es',
            xaxis: {{ title: 'NumÃ©ro de Frame' }},
            yaxis: {{ title: 'Latence (ms)', rangemode: 'tozero' }},
            margin: {{ t: 50, r: 20, b: 40, l: 50 }},
            showlegend: true,
            annotations: [{{
                text: "RX â†’ CPU-to-GPU â†’ PROC(GPU) â†’ GPU-to-CPU â†’ TX",
                showarrow: false,
                xref: "paper", yref: "paper",
                x: 0.5, xanchor: 'center',
                y: 1.02, yanchor: 'bottom',
                font: {{ size: 12, color: "#666" }}
            }}]
        }};
        
        Plotly.newPlot('fps-chart', [], fpsLayout);
        Plotly.newPlot('gpu-transfer-chart', [], gpuTransferLayout);
        Plotly.newPlot('interstage-chart', [], interstageLayout);
        
        ws.onmessage = function(event) {{
            const data = JSON.parse(event.data);
            updateDashboard(data);
        }};
        
        ws.onerror = function(error) {{
            console.error('WebSocket error:', error);
            document.getElementById('health-status').textContent = 'ERREUR';
            document.getElementById('health-status').className = 'status status-critical';
        }};
        
        function updateDashboard(data) {{
            // Pipeline info
            document.getElementById('rx-info').textContent = 
                `${{data.last_frame_rx || 0}} / ${{(data.fps_rx || 0).toFixed(1)}}`;
            document.getElementById('proc-info').textContent = 
                `${{data.last_frame_proc || 0}} / ${{(data.fps_proc || 0).toFixed(1)}}`;
            document.getElementById('tx-info').textContent = 
                `${{data.last_frame_tx || 0}} / ${{(data.fps_tx || 0).toFixed(1)}}`;
            document.getElementById('sync-txproc').textContent = (data.sync_txproc || 0).toFixed(1);
            
            // ğŸ¯ Nouvelles MÃ©triques Inter-Ã‰tapes DÃ©taillÃ©es (Pipeline GPU-RÃ©sident)
            // ğŸ”§ CORRECTIF: Filtrer les valeurs aberrantes (timestamps absolus)
            const formatLatency = (val) => {{
                if (!val || Math.abs(val) > 1000000) return "N/A";
                if (val <= 0) return "0.00";
                return val.toFixed(2);
            }};
            
            document.getElementById('interstage-rx-gpu').textContent = 
                `${{formatLatency(data.interstage_rx_to_cpu_gpu_ms)}} / ${{formatLatency(data.interstage_rx_to_cpu_gpu_p95_ms)}}`;
            document.getElementById('interstage-gpu-proc').textContent = 
                `${{formatLatency(data.interstage_cpu_gpu_to_proc_ms)}} / ${{formatLatency(data.interstage_cpu_gpu_to_proc_p95_ms)}}`;
            document.getElementById('interstage-proc-cpu').textContent = 
                `${{formatLatency(data.interstage_proc_to_gpu_cpu_ms)}} / ${{formatLatency(data.interstage_proc_to_gpu_cpu_p95_ms)}}`;
            document.getElementById('interstage-cpu-tx').textContent = 
                `${{formatLatency(data.interstage_gpu_cpu_to_tx_ms)}} / ${{formatLatency(data.interstage_gpu_cpu_to_tx_p95_ms)}}`;
            document.getElementById('interstage-total').textContent = 
                `${{formatLatency(data.interstage_total_ms)}} / ${{formatLatency(data.interstage_total_p95_ms)}}`;
            document.getElementById('interstage-samples').textContent = data.interstage_samples || 0;
            
            // GPU Transfer
            const gpuStats = data.gpu_transfer?.stats || {{}};
            document.getElementById('gpu-frames').textContent = gpuStats.total_frames || 0;
            document.getElementById('gpu-avg-lat').textContent = (gpuStats.avg_total || 0).toFixed(2);
            document.getElementById('gpu-breakdown').textContent = 
                `${{(gpuStats.avg_norm || 0).toFixed(1)}} / ${{(gpuStats.avg_pin || 0).toFixed(1)}} / ${{(gpuStats.avg_copy || 0).toFixed(1)}}`;
            document.getElementById('gpu-throughput').textContent = (gpuStats.throughput_fps || 0).toFixed(1);
            
            // GPU
            document.getElementById('gpu-util').textContent = data.gpu_util.toFixed(1);
            document.getElementById('gpu-memory').textContent = Math.round(data.gpu_memory_mb);
            
            // Queues
            document.getElementById('queue-rt').textContent = data.queue_rt_size;
            document.getElementById('queue-gpu').textContent = data.queue_gpu_size;
            document.getElementById('queue-drops').textContent = data.queue_rt_drops;
            
            // Status
            const statusEl = document.getElementById('health-status');
            statusEl.textContent = data.health;
            statusEl.className = 'status status-' + data.health.toLowerCase();
            
            // Timestamp
            const now = new Date(data.datetime);
            document.getElementById('last-update').textContent = now.toLocaleTimeString();
            
            // Update time-series charts
            const timeLabel = now.toLocaleTimeString();
            timestamps.push(timeLabel);
            fpsInData.push(data.fps_rx || data.fps_in);
            fpsOutData.push(data.fps_tx || data.fps_out);
            gpuUtilData.push(data.gpu_util);
            
            if (timestamps.length > maxPoints) {{
                timestamps.shift();
                fpsInData.shift();
                fpsOutData.shift();
                gpuUtilData.shift();
            }}
            
            // FPS chart
            Plotly.react('fps-chart', [
                {{ x: timestamps, y: fpsInData, name: 'FPS RX', type: 'scatter', mode: 'lines+markers', line: {{ color: '#10b981' }} }},
                {{ x: timestamps, y: fpsOutData, name: 'FPS TX', type: 'scatter', mode: 'lines+markers', line: {{ color: '#3b82f6' }} }}
            ], fpsLayout);
            
            // GPU Transfer chart (stacked bar)
            if (data.gpu_transfer && data.gpu_transfer.frames && data.gpu_transfer.frames.length > 0) {{
                const gpuFrames = data.gpu_transfer.frames;
                const normMs = data.gpu_transfer.norm_ms;
                const pinMs = data.gpu_transfer.pin_ms;
                const copyMs = data.gpu_transfer.copy_ms;
                
                Plotly.react('gpu-transfer-chart', [
                    {{ x: gpuFrames, y: normMs, name: 'Normalization', type: 'bar', marker: {{ color: '#10b981' }} }},
                    {{ x: gpuFrames, y: pinMs, name: 'Pinned Memory', type: 'bar', marker: {{ color: '#3b82f6' }} }},
                    {{ x: gpuFrames, y: copyMs, name: 'Async Copy', type: 'bar', marker: {{ color: '#f59e0b' }} }}
                ], gpuTransferLayout);
            }}
            
            // ğŸ¯ Nouveau graphique inter-Ã©tapes dÃ©taillÃ© (Pipeline GPU-RÃ©sident)
            if (data.interstage_details && data.interstage_details.frames && data.interstage_details.frames.length > 0) {{
                const frames = data.interstage_details.frames;
                const rxToGpu = data.interstage_details.rx_to_gpu;
                const gpuToProc = data.interstage_details.gpu_to_proc;
                const procToCpu = data.interstage_details.proc_to_cpu;
                const cpuToTx = data.interstage_details.cpu_to_tx;
                const totalRxTx = data.interstage_details.total || [];  // ğŸ¯ NOUVEAU: Total RXâ†’TX
                
                Plotly.react('interstage-chart', [
                    {{ x: frames, y: rxToGpu, name: 'RX â†’ CPU-to-GPU', type: 'scatter', mode: 'lines+markers',
                       line: {{ color: '#ec4899', width: 2 }}, marker: {{ size: 3 }} }},
                    {{ x: frames, y: gpuToProc, name: 'CPU-to-GPU â†’ PROC(GPU)', type: 'scatter', mode: 'lines+markers',
                       line: {{ color: '#10b981', width: 2 }}, marker: {{ size: 3 }} }},
                    {{ x: frames, y: procToCpu, name: 'PROC(GPU) â†’ GPU-to-CPU', type: 'scatter', mode: 'lines+markers',
                       line: {{ color: '#3b82f6', width: 2 }}, marker: {{ size: 3 }} }},
                    {{ x: frames, y: cpuToTx, name: 'GPU-to-CPU â†’ TX', type: 'scatter', mode: 'lines+markers',
                       line: {{ color: '#f59e0b', width: 2 }}, marker: {{ size: 3 }} }},
                    {{ x: frames, y: totalRxTx, name: 'ğŸ¯ RX â†’ TX (TOTAL)', type: 'scatter', mode: 'lines+markers',
                       line: {{ color: '#9333ea', width: 3 }}, marker: {{ size: 4 }} }}
                ], interstageLayout);
            }} else if (data.interstage_samples > 0) {{
                // Fallback: utiliser les moyennes si pas de dÃ©tails par frame
                const sampleFrames = Array.from({{length: 10}}, (_, i) => i + 1);
                const avgRxToGpu = Array(10).fill(data.interstage_rx_to_cpu_gpu_ms || 0);
                const avgGpuToProc = Array(10).fill(data.interstage_cpu_gpu_to_proc_ms || 0);
                const avgProcToCpu = Array(10).fill(data.interstage_proc_to_gpu_cpu_ms || 0);
                const avgCpuToTx = Array(10).fill(data.interstage_gpu_cpu_to_tx_ms || 0);
                const avgTotal = Array(10).fill(data.interstage_total_ms || 0);  // ğŸ¯ NOUVEAU: Total moyen
                
                Plotly.react('interstage-chart', [
                    {{ x: sampleFrames, y: avgRxToGpu, name: 'RX â†’ CPU-to-GPU (avg)', type: 'scatter', mode: 'lines',
                       line: {{ color: '#ec4899', width: 2, dash: 'dash' }} }},
                    {{ x: sampleFrames, y: avgGpuToProc, name: 'CPU-to-GPU â†’ PROC(GPU) (avg)', type: 'scatter', mode: 'lines',
                       line: {{ color: '#10b981', width: 2, dash: 'dash' }} }},
                    {{ x: sampleFrames, y: avgProcToCpu, name: 'PROC(GPU) â†’ GPU-to-CPU (avg)', type: 'scatter', mode: 'lines',
                       line: {{ color: '#3b82f6', width: 2, dash: 'dash' }} }},
                    {{ x: sampleFrames, y: avgCpuToTx, name: 'GPU-to-CPU â†’ TX (avg)', type: 'scatter', mode: 'lines',
                       line: {{ color: '#f59e0b', width: 2, dash: 'dash' }} }},
                    {{ x: sampleFrames, y: avgTotal, name: 'ğŸ¯ RX â†’ TX TOTAL (avg)', type: 'scatter', mode: 'lines',
                       line: {{ color: '#9333ea', width: 3, dash: 'dash' }} }}
                ], interstageLayout);
            }} else {{
                // Pas de donnÃ©es inter-Ã©tapes - afficher message informatif
                Plotly.react('interstage-chart', [{{
                    x: [0, 1], y: [0, 0], 
                    type: 'scatter', mode: 'text',
                    text: ['Aucune donnÃ©e inter-Ã©tapes', 'Activer le mode GPU pour voir les mÃ©triques'],
                    textposition: 'middle center',
                    showlegend: false
                }}], interstageLayout);
            }}
        }}
    </script>
</body>
</html>
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  THREAD DE COLLECTE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CollectorThread(Thread):
    """Thread qui collecte pÃ©riodiquement les mÃ©triques"""
    
    def __init__(self, collector: UnifiedMetricsCollector, interval: float):
        super().__init__(daemon=True)
        self.collector = collector
        self.interval = interval
        self.running = True
    
    def run(self):
        """Boucle de collecte"""
        LOG.info("Collector thread started")
        while self.running:
            try:
                self.collector.collect()
                time.sleep(self.interval)
            except Exception as e:
                LOG.error(f"Collection error: {e}")
    
    def stop(self):
        """ArrÃªte le thread"""
        self.running = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SERVICE PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DashboardService:
    """Service de dashboard unifiÃ©"""
    
    def __init__(self, config: Optional[DashboardConfig] = None):
        self.config = config or DashboardConfig()
        self.collector = UnifiedMetricsCollector(self.config)
        self.collector_thread = CollectorThread(self.collector, self.config.update_interval)
        self.app = create_app(self.collector, self.config)
    
    def start(self):
        """DÃ©marre le service"""
        LOG.info(f"Starting Unified Dashboard on http://{self.config.host}:{self.config.port}")
        
        # DÃ©marrer le thread de collecte
        self.collector_thread.start()
        
        # DÃ©marrer le serveur FastAPI
        uvicorn.run(
            self.app,
            host=self.config.host,
            port=self.config.port,
            log_level="info"
        )
    
    def stop(self):
        """ArrÃªte le service"""
        LOG.info("Stopping dashboard service")
        self.collector_thread.stop()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  POINT D'ENTRÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Point d'entrÃ©e CLI"""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    )
    
    parser = argparse.ArgumentParser(description="Ultramotion IGT Unified Dashboard")
    parser.add_argument("--port", type=int, default=8050, help="Port du serveur")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="Host du serveur")
    parser.add_argument("--interval", type=float, default=1.0, help="Intervalle de collecte (s)")
    
    args = parser.parse_args()
    
    config = DashboardConfig(
        port=args.port,
        host=args.host,
        update_interval=args.interval
    )
    
    service = DashboardService(config)
    
    try:
        service.start()
    except KeyboardInterrupt:
        LOG.info("Shutdown requested")
        service.stop()


if __name__ == "__main__":
    main()
