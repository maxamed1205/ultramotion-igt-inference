
"""
proc_simulator.py
-----------------
Simulation du traitement pipeline (CPU ou GPU).
"""
import time
import logging
import threading
import numpy as np

from core.preprocessing.cpu_to_gpu import prepare_frame_for_gpu
from service.gateway.manager import IGTGateway  #

LOG = logging.getLogger("igt.mock.proc")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#  Traitement PROC (seuillage) - INCHANG√â
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def simulate_processing(
    gateway: IGTGateway,
    stop_event: threading.Event,
    frame_ready: threading.Event,
    use_gpu: bool = True,
    gpu_device: str = "cpu"
):
    """Lit la mailbox, applique un seuillage (optionnellement sur GPU), envoie vers outbox via send_mask()."""
    proc_type = "GPU thresholding" if use_gpu else "simple thresholding"
    LOG.info(f"[PROC-SIM] Thread started ({proc_type}, device={gpu_device})")
    
    while not stop_event.is_set():
        # Attendre qu'une frame soit disponible (timeout 10ms pour √©viter blocage infini)
        if not frame_ready.wait(timeout=0.01):
            continue  # Timeout ‚Üí rev√©rifier stop_event
        frame_ready.clear()  # Reset l'event pour la prochaine frame
        
        try:
            frame = gateway.receive_image()
            if frame is None:
                continue
            
            frame_id = frame.meta.frame_id
            LOG.info(f"[PROC-SIM] Processing frame #{frame_id:03d}")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # üéØ M√âTRIQUES INTER-√âTAPES D√âTAILL√âES pour le workflow complet :
            # RX ‚Üí CPU-to-GPU ‚Üí PROC(GPU) ‚Üí GPU-to-CPU ‚Üí TX
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            # üîß CORRECTIF: Utiliser perf_counter() partout pour coh√©rence temporelle
            t_rx_relative = time.perf_counter()  # D√©but du workflow (horloge relative coh√©rente)
            
            # ‚è±Ô∏è Enregistrer d√©but du workflow inter-√©tapes
            gateway.stats.mark_interstage_rx(frame_id, t_rx_relative)
            
            if use_gpu:
                try:
                    # ‚è±Ô∏è √âtape 1: CPU ‚Üí GPU transfer
                    t1_start = time.perf_counter()
                    gpu_frame = prepare_frame_for_gpu(frame, device=gpu_device)
                    t1_end = time.perf_counter()
                    gateway.stats.mark_interstage_cpu_to_gpu(frame_id, t1_end)
                    cpu_to_gpu_ms = (t1_end - t1_start) * 1000.0
                    
                    # ‚è±Ô∏è √âtape 2: PROC (GPU processing)
                    t2_start = time.perf_counter()
                    tensor = gpu_frame.tensor
                    mask_tensor = (tensor > 0.5).float()  # Seuil √† 0.5 (√©quivalent 128/255)
                    t2_end = time.perf_counter()
                    gateway.stats.mark_interstage_proc_done(frame_id, t2_end)
                    proc_gpu_ms = (t2_end - t2_start) * 1000.0
                    
                    # ‚è±Ô∏è √âtape 3: GPU ‚Üí CPU transfer (final result)
                    t3_start = time.perf_counter()
                    mask = (mask_tensor.squeeze().cpu().numpy() * 255).astype(np.uint8)
                    t3_end = time.perf_counter()
                    gateway.stats.mark_interstage_gpu_to_cpu(frame_id, t3_end)
                    gpu_to_cpu_ms = (t3_end - t3_start) * 1000.0
                    
                    # ‚úÖ Calcul des latences inter-√©tapes par couples
                    rx_to_cpu_gpu = cpu_to_gpu_ms  # RX ‚Üí CPU-to-GPU (t1_start √©tait juste apr√®s RX)
                    cpu_gpu_to_proc = proc_gpu_ms   # CPU-to-GPU ‚Üí PROC(GPU)
                    proc_to_gpu_cpu = gpu_to_cpu_ms # PROC(GPU) ‚Üí GPU-to-CPU
                    # gpu_cpu_to_tx sera calcul√© automatiquement par mark_interstage_tx()
                    
                    # üìä Log d√©taill√© des m√©triques inter-√©tapes (toutes les 10 frames)
                    if frame_id % 10 == 0:
                        total_processing = cpu_to_gpu_ms + proc_gpu_ms + gpu_to_cpu_ms
                        LOG.info(f"[PROC-SIM]  Inter-stage latencies #{frame_id:03d}:")
                        LOG.info(f"  RX ‚Üí CPU-to-GPU:    {rx_to_cpu_gpu:.2f}ms")
                        LOG.info(f"  CPU-to-GPU ‚Üí PROC:  {cpu_gpu_to_proc:.2f}ms") 
                        LOG.info(f"  PROC ‚Üí GPU-to-CPU:  {proc_to_gpu_cpu:.2f}ms")
                        LOG.info(f"  Total processing:   {total_processing:.2f}ms | {gpu_device}")
                        
                        # üìà Afficher les statistiques cumul√©es si disponibles
                        try:
                            stats_snap = gateway.stats.snapshot()
                            interstage_samples = stats_snap.get('interstage_samples', 0)
                            if interstage_samples >= 5:  # Afficher seulement si assez d'√©chantillons
                                avg_proc = stats_snap.get('interstage_cpu_gpu_to_proc_ms', 0)
                                avg_total = (stats_snap.get('interstage_rx_to_cpu_gpu_ms', 0) + 
                                           avg_proc + 
                                           stats_snap.get('interstage_proc_to_gpu_cpu_ms', 0) + 
                                           stats_snap.get('interstage_gpu_cpu_to_tx_ms', 0))
                                LOG.info(f"  Moyennes cumul√©es ({interstage_samples} √©chantillons): PROC={avg_proc:.1f}ms, Total={avg_total:.1f}ms")
                        except Exception:
                            pass
                        
                except Exception as e:
                    LOG.warning(f"[PROC-SIM] GPU failed, fallback CPU: {e}")
                    # Fallback vers CPU (pas de m√©triques inter-√©tapes d√©taill√©es)
                    mask = (frame.image > 128).astype(np.uint8)
            else:
                # Traitement CPU classique (pas de transferts GPU)
                t_cpu_start = time.perf_counter()
                mask = (frame.image > 128).astype(np.uint8)
                t_cpu_end = time.perf_counter()
                cpu_proc_ms = (t_cpu_end - t_cpu_start) * 1000.0
                
                if frame_id % 10 == 0:
                    LOG.info(f"[PROC-SIM] CPU processing: {cpu_proc_ms:.2f}ms")
            
            # ‚úÖ Timestamp final pour PROC‚ÜíTX latency measurement
            t_proc_complete = time.perf_counter()
            meta = {
                "frame_id": frame_id,
                "ts": t_proc_complete,  # ‚è±Ô∏è Timestamp de fin de PROC (d√©but TX)
                "state": "VISIBLE",
            }
            
            # ‚è±Ô∏è TX final - ceci appellera mark_tx() et mark_interstage_tx() automatiquement
            gateway.send_mask(mask, meta)
            
        except Exception as e:
            LOG.exception(f"[PROC-SIM] Error: {e}")
    LOG.info("[PROC-SIM] Thread stopped.")