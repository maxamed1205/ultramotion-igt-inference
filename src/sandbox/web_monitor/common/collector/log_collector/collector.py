"""
collector.py
-------------
Coordonne la lecture, le parsing et la fusion des logs pipeline.log et kpi.log.
"""

import threading
import time
from queue import Queue, Empty
from .tailer import FileTailer
from .parser import LogParser
from .aggregator import FrameAggregator
from .profiler import CollectorProfiler
from . import logger


class LogCollector:
    """Service central : lecture, parsing, agr√©gation et snapshot."""

    def __init__(self, pipeline_path: str, kpi_path: str, history_size: int = 300):
        self.pipeline_path = pipeline_path
        self.kpi_path = kpi_path

        # Queues partag√©es
        self.q_pipeline = Queue(maxsize=500)
        self.q_kpi = Queue(maxsize=500)

        # Composants internes
        self.parser = LogParser()
        self.aggregator = FrameAggregator(max_history=history_size)
        self.profiler = CollectorProfiler()

        # Threads de lecture (tailers)
        self.t_pipeline = FileTailer(pipeline_path, self.q_pipeline)
        self.t_kpi = FileTailer(kpi_path, self.q_kpi)

        # Thread de consommation (fusion)
        self.t_consumer = threading.Thread(target=self._consume_loop, daemon=True)

        # Flag d‚Äôex√©cution thread-safe
        self.running = threading.Event()

    # ------------------------------------------------------------------ #
    def start(self):
        """D√©marre le syst√®me de collecte multi-thread."""
        logger.info("[Collector] D√©marrage des tailers et du thread consumer")
        self.running.set()
        self.t_pipeline.start()
        self.t_kpi.start()
        self.t_consumer.start()

    # ------------------------------------------------------------------ #
    def _consume_loop(self):
        """Boucle principale : lit les queues, parse et agr√®ge."""
        logger.info("[Collector] Thread consumer d√©marr√©")
        try:
            while self.running.is_set():
                t0 = time.perf_counter()
                self._drain_queue(self.q_pipeline, "pipeline")
                self._drain_queue(self.q_kpi, "kpi")
                self.profiler.add_sample(time.perf_counter() - t0)
                time.sleep(0.01)
        except Exception as e:
            logger.error(f"[Collector] Erreur dans _consume_loop: {e}")
        finally:
            logger.info("[Collector] Thread consumer arr√™t√© proprement (finally)")

    def _drain_queue(self, q, source: str):
        """Vide une queue jusqu‚Äô√† √©puisement."""
        while not q.empty():
            try:
                line = q.get_nowait()
            except Empty:
                break
            parsed = self.parser.parse_line(line, source)
            if parsed:
                self.aggregator.update(parsed)

    # ------------------------------------------------------------------ #
    def stop(self, timeout: float = 2.0):
        """Arr√™te proprement tous les threads du LogCollector."""
        if not self.running.is_set():
            logger.debug("[Collector] stop() appel√© alors que le collector n‚Äô√©tait pas actif.")
            return

        logger.info("[Collector] üîª Arr√™t demand√© du LogCollector")
        self.running.clear()

        # üßπ √âtape 1 ‚Äî stoppe les tailers
        try:
            self.t_pipeline.stop()
            self.t_kpi.stop()
            logger.debug("[Collector] Tailers stopp√©s.")
        except Exception as e:
            logger.warning(f"[Collector] Erreur lors de l‚Äôarr√™t des tailers: {e}")

        # üïí √âtape 2 ‚Äî attendre leur terminaison propre
        for t in (self.t_pipeline, self.t_kpi):
            if t.is_alive():
                t.join(timeout=timeout)
                if t.is_alive():
                    logger.warning(f"[Collector] ‚ö†Ô∏è Thread {t.name} n‚Äôa pas termin√© √† temps")
                else:
                    logger.info(f"[Collector] ‚úÖ Thread {t.name} arr√™t√© proprement")

        # üß© √âtape 3 ‚Äî arr√™ter la boucle consumer
        if self.t_consumer.is_alive():
            self.t_consumer.join(timeout=timeout)
            if self.t_consumer.is_alive():
                logger.warning("[Collector] ‚ö†Ô∏è Thread consumer bloqu√© (timeout)")
            else:
                logger.info("[Collector] ‚úÖ Thread consumer arr√™t√© proprement")

        logger.info("[Collector] ‚úÖ Tous les threads termin√©s proprement (shutdown complet)")


    # ------------------------------------------------------------------ #
    def snapshot(self):
        """Retourne un snapshot agr√©g√© complet (pour WS / tests)."""
        stats = self.profiler.stats()
        return self.aggregator.as_snapshot(profiler_stats=stats)

    def get_latest(self):
        """Retourne la derni√®re frame agr√©g√©e."""
        return self.aggregator.get_latest()

    def get_history(self, n=100):
        """Retourne l‚Äôhistorique r√©cent."""
        return self.aggregator.get_history(n)
