"""
collector.py
-------------
Coordonne la lecture, le parsing et la fusion des logs pipeline.log et kpi.log.
"""

import threading
import time
from queue import Queue, Empty
from .tailer import FileTailer
from .parser import LogParser
from .aggregator import FrameAggregator
from .profiler import CollectorProfiler
from . import logger


class LogCollector:
    """Service central : lecture, parsing, agrÃ©gation et snapshot."""

    def __init__(self, pipeline_path: str, kpi_path: str, history_size: int = 300):
        self.pipeline_path = pipeline_path
        self.kpi_path = kpi_path

        # Queues partagÃ©es
        self.q_pipeline = Queue(maxsize=500)
        self.q_kpi = Queue(maxsize=500)

        # Composants internes
        self.parser = LogParser()
        self.aggregator = FrameAggregator(max_history=history_size)
        self.profiler = CollectorProfiler()

        # Threads de lecture (tailers)
        self.t_pipeline = FileTailer(pipeline_path, self.q_pipeline)
        self.t_kpi = FileTailer(kpi_path, self.q_kpi)

        # Thread de consommation (fusion)
        self.t_consumer = threading.Thread(target=self._consume_loop, daemon=True)

        # Flag dâ€™exÃ©cution thread-safe
        self.running = threading.Event()

    # ------------------------------------------------------------------ #
    def start(self):
        """DÃ©marre le systÃ¨me de collecte multi-thread."""
        logger.info("[Collector] DÃ©marrage des tailers et du thread consumer")
        self.running.set()
        self.t_pipeline.start()
        self.t_kpi.start()
        self.t_consumer.start()

    # ------------------------------------------------------------------ #
    def _consume_loop(self):
        """Boucle principale : lit les queues, parse et agrÃ¨ge."""
        logger.info("[Collector] Thread consumer dÃ©marrÃ©")
        try:
            while self.running.is_set():
                t0 = time.perf_counter()
                self._drain_queue(self.q_pipeline, "pipeline")
                self._drain_queue(self.q_kpi, "kpi")
                self.profiler.add_sample(time.perf_counter() - t0)
                time.sleep(0.01)
        except Exception as e:
            logger.error(f"[Collector] Erreur dans _consume_loop: {e}")
        finally:
            logger.info("[Collector] Thread consumer arrÃªtÃ© proprement (finally)")

    # ------------------------------------------------------------------ #
    def _drain_queue(self, q, source: str):
        """Vide une queue jusquâ€™Ã  Ã©puisement."""
        drained = 0
        while not q.empty():
            try:
                line = q.get_nowait()
            except Empty:
                break

            drained += 1
            parsed = self.parser.parse_line(line, source)

            if parsed:
                logger.debug(f"[Collector] {source}: parsed frame_id={parsed.get('frame_id')} event={parsed.get('event')}")
                self.aggregator.update(parsed)
            else:
                logger.debug(f"[Collector] {source}: ligne ignorÃ©e (non parsable)")

        if drained > 0:
            logger.debug(f"[Collector] {source}: {drained} lignes traitÃ©es dans cette itÃ©ration.")


    # ------------------------------------------------------------------ #
    def stop(self, timeout: float = 2.0):
        """ArrÃªte proprement tous les threads du LogCollector."""
        if not self.running.is_set():
            logger.debug("[Collector] stop() appelÃ© alors que le collector nâ€™Ã©tait pas actif.")
            return

        logger.info("[Collector] ğŸ”» ArrÃªt demandÃ© du LogCollector")
        self.running.clear()

        # ğŸ§¹ Ã‰tape 1 â€” stoppe les tailers
        try:
            self.t_pipeline.stop()
            self.t_kpi.stop()
            logger.debug("[Collector] Tailers stoppÃ©s.")
        except Exception as e:
            logger.warning(f"[Collector] Erreur lors de lâ€™arrÃªt des tailers: {e}")

        # ğŸ•’ Ã‰tape 2 â€” attendre leur terminaison propre
        for t in (self.t_pipeline, self.t_kpi):
            if t.is_alive():
                t.join(timeout=timeout)
                if t.is_alive():
                    logger.warning(f"[Collector] âš ï¸ Thread {t.name} nâ€™a pas terminÃ© Ã  temps")
                else:
                    logger.info(f"[Collector] âœ… Thread {t.name} arrÃªtÃ© proprement")

        # ğŸ§© Ã‰tape 3 â€” arrÃªter la boucle consumer
        if self.t_consumer.is_alive():
            self.t_consumer.join(timeout=timeout)
            if self.t_consumer.is_alive():
                logger.warning("[Collector] âš ï¸ Thread consumer bloquÃ© (timeout)")
            else:
                logger.info("[Collector] âœ… Thread consumer arrÃªtÃ© proprement")

        logger.info("[Collector] âœ… Tous les threads terminÃ©s proprement (shutdown complet)")


    # ------------------------------------------------------------------ #
    def snapshot(self):
        """Retourne un snapshot agrÃ©gÃ© complet (pour WS / tests)."""
        stats = self.profiler.stats()
        return self.aggregator.as_snapshot(profiler_stats=stats)

    def get_latest(self):
        """Retourne la derniÃ¨re frame agrÃ©gÃ©e."""
        latest = self.aggregator.get_latest()
        if latest:
            logger.debug(f"[Collector] get_latest() â†’ frame#{latest.frame_id} total={getattr(latest.interstage, 'total', None)}ms")
        else:
            logger.debug("[Collector] get_latest() â†’ None (aucune frame complÃ¨te encore disponible)")
        return latest


    def get_history(self, n=100):
        """Retourne lâ€™historique rÃ©cent."""
        return self.aggregator.get_history(n)
