# ğŸš€ Orchestrator.py GPU-Resident Refactoring

## ğŸ“‹ RÃ©sumÃ© des changements

La fonction `prepare_inference_inputs()` dans `orchestrator.py` a Ã©tÃ© refactorisÃ©e pour Ã©liminer le transfert GPUâ†’CPU prÃ©maturÃ© qui causait des spikes de performance.

## âš¡ Avant/AprÃ¨s

### âŒ Avant (version originale)
```python
# ForÃ§ait un transfert GPUâ†’CPU pour tous les appels SAM
arr_np = arr[0].permute(1, 2, 0).detach().cpu().numpy()
# ... traitement en NumPy ...
mask = run_segmentation(sam_model, full_image)  # NumPy array
```

### âœ… AprÃ¨s (version optimisÃ©e)
```python
# Mode GPU-resident par dÃ©faut (sam_as_numpy=False)
prepare_inference_inputs(frame, dfine, sam)  # Garde tensors sur GPU

# Mode compatibilitÃ© (sam_as_numpy=True) 
prepare_inference_inputs(frame, dfine, sam, sam_as_numpy=True)  # Legacy CPU
```

## ğŸ¯ Changements techniques

### 1. Nouvelle signature
```python
def prepare_inference_inputs(
    frame_t: np.ndarray, 
    dfine_model: Any, 
    sam_model: Any, 
    tau_conf: float = 0.0001, 
    sam_as_numpy: bool = False  # ğŸ†• Nouveau paramÃ¨tre
) -> Dict[str, Any]:
```

### 2. Chemin GPU-resident (nouveau, par dÃ©faut)
```python
if hasattr(arr, "detach") and not sam_as_numpy:
    # âœ… GPU-resident path : SAM reÃ§oit directement le tensor CUDA
    if arr.ndim == 4 and arr.shape[0] == 1:
        full_image = arr[0].permute(1, 2, 0).contiguous()  # Reste sur GPU
        
        # Normalisation GPU-native
        if full_image.dtype != torch.float32:
            full_image = full_image.to(torch.float32)
        if full_image.max() > 1.0:
            full_image = full_image / 255.0
```

### 3. Chemin legacy (rÃ©trocompatibilitÃ©)
```python
else:
    # ğŸ§© Legacy CPU path (for backward compat)
    arr_np = arr[0].permute(1, 2, 0).detach().cpu().numpy()
    # ... ancien traitement NumPy prÃ©servÃ© ...
```

### 4. Appel SAM modifiÃ©
```python
# Avant
mask = run_segmentation(sam_model, full_image, bbox_xyxy=bbox_t)

# AprÃ¨s
mask = run_segmentation(sam_model, full_image, bbox_xyxy=bbox_t, as_numpy=sam_as_numpy)
```

## ğŸ“Š Monitoring KPI

L'instrumentation KPI log automatiquement:
```json
{
    "ts": 1698765432.0,
    "event": "prepare_inference_inputs",
    "sam_as_numpy": 0,  // 0=GPU-resident, 1=legacy mode
    "tensor_type": "<class 'torch.Tensor'>",
    "device": "cuda:0"
}
```

## ğŸ§­ Migration

### Usage recommandÃ© (GPU-resident)
```python
# Nouveau comportement par dÃ©faut - pas de transfert GPUâ†’CPU
result = prepare_inference_inputs(frame, dfine_model, sam_model)
# sam_as_numpy=False par dÃ©faut
```

### Usage de compatibilitÃ© (legacy)
```python
# Pour la rÃ©trocompatibilitÃ© temporaire
result = prepare_inference_inputs(frame, dfine_model, sam_model, sam_as_numpy=True)
```

## ğŸ§ª Tests

Les tests sont dans `tests/test_orchestrator_gpu_resident.py`:
```bash
# Lancer les tests
cd ultramotion-igt-inference
python -m pytest tests/test_orchestrator_gpu_resident.py -v
```

### Tests couverts:
- âœ… Mode GPU-resident avec tensors CUDA
- âœ… Mode legacy avec numpy arrays
- âœ… Comportement par dÃ©faut (GPU-resident)
- âœ… Instrumentation KPI
- âœ… Traitement spÃ©cifique tensors GPU

## ğŸ“ˆ BÃ©nÃ©fices attendus

1. **ğŸš€ Latence rÃ©duite**: Plus de transfert GPUâ†’CPU forcÃ© dans l'orchestrator
2. **ğŸ“Š Pipeline fluide**: Les tensors restent sur GPU entre DFINE et SAM
3. **âš¡ Performance stable**: Ã‰limination des spikes GPU Copy dans les mÃ©triques
4. **ğŸ”„ CompatibilitÃ©**: Code existant continue de fonctionner avec `sam_as_numpy=True`

## âš ï¸ ConsidÃ©rations

### GPU Memory
- Le mode GPU-resident garde plus de donnÃ©es sur GPU
- Surveiller l'usage mÃ©moire GPU en production

### CompatibilitÃ©
- `run_segmentation()` doit Ãªtre mis Ã  jour pour accepter `as_numpy` parameter
- Tests d'intÃ©gration nÃ©cessaires avec le pipeline complet

## ğŸ”— Flux de donnÃ©es

### Mode GPU-resident (sam_as_numpy=False)
```
Frame (GPU) â†’ DFINE (GPU) â†’ SAM (GPU) â†’ Mask (GPU) â†’ ResultPacket
     â†‘                                                      â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pas de transfert GPUâ†’CPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mode legacy (sam_as_numpy=True)  
```
Frame (GPU) â†’ DFINE (GPU) â†’ GPUâ†’CPU â†’ SAM (CPU) â†’ Mask (CPU) â†’ ResultPacket
                                â†‘
                        Transfert forcÃ©
```

## ğŸ”„ Rollback

En cas de problÃ¨me:
```python
# Forcer le mode legacy globalement
def prepare_inference_inputs(..., sam_as_numpy: bool = True):  # Temporaire
```

## ğŸš€ Ã‰tapes suivantes

1. âœ… **Orchestrator refactoring** (cette Ã©tape - TERMINÃ‰)
2. â³ **Update inference_sam.py**: Ajouter support du paramÃ¨tre `as_numpy`
3. â³ **Tests d'intÃ©gration**: Pipeline complet GPU-resident
4. â³ **Production monitoring**: VÃ©rifier les KPI et la stabilitÃ©

## ğŸ“Š MÃ©triques de validation

| MÃ©trique | Avant | AprÃ¨s (attendu) |
|----------|-------|-----------------|
| GPUâ†’CPU Copy events | ~3 par frame | 0 par frame |
| Latence SAM | Variable (spikes) | Stable |
| Memory GPU peak | Baseline | +10-15% |
| Throughput | Baseline | +15-25% |