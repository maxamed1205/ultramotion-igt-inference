# syntax=docker/dockerfile:1.7
###########################################################
# ğŸ§  Service IA temps rÃ©el (D-FINE + SAM + IGTLink)
# ---------------------------------------------------------
#  â€¢ Gestionnaire : uv (lecture pyproject.toml)
#  â€¢ Base : CUDA 12.1 (Ubuntu 22.04)
#  â€¢ Objectif : image reproductible, sans requirements.txt
###########################################################

FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04 AS base
####################################################################################################
# ğŸ” LIGNE DOCKER
# FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04 AS base
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette ligne dÃ©finit lâ€™image de base Ã  partir de laquelle toutes les couches suivantes du conteneur
# seront construites. Elle fournit le systÃ¨me dâ€™exploitation et les bibliothÃ¨ques sur lesquelles
# on empile toutes les dÃ©pendances (Python, librairies IA, code applicatif, etc.).
# Ici, lâ€™image est spÃ©cialisÃ©e pour lâ€™exÃ©cution GPU sous CUDA.
#
# âš™ï¸ COMPOSITION DE Lâ€™IMAGE :
#   Ã‰lÃ©ment          | Description                                    | RÃ´le dans le conteneur
#   -----------------|------------------------------------------------|------------------------
#   nvidia/cuda      | Repository Docker officiel de NVIDIA            | Images prÃ©configurÃ©es CUDA optimisÃ©es GPU
#   12.1.1           | Version majeure du toolkit CUDA                | CompatibilitÃ© garantie avec PyTorch cu121
#   runtime          | Variante dâ€™exÃ©cution (sans outils nvcc, etc.)  | BibliothÃ¨ques CUDA essentielles uniquement
#   ubuntu22.04      | Base Ubuntu LTS (Jammy Jellyfish)              | Environnement Linux stable et rÃ©cent
#
# ğŸ§° POURQUOI Â« runtime Â» ET PAS Â« devel Â» :
#   - `runtime` contient uniquement les bibliothÃ¨ques nÃ©cessaires Ã  lâ€™exÃ©cution GPU :
#     (libcudart.so, libcublas.so, libcudnn.so, etc.)
#   - `devel` ajoute les outils de dÃ©veloppement (nvcc, headers, etc.), inutile pour un service
#     dâ€™infÃ©rence et alourdit lâ€™image (+3 Go environ).
#   âœ… On choisit donc `runtime` pour rÃ©duire la taille (â‰ˆ1.2 Go) et accÃ©lÃ©rer les builds.
#
# ğŸ’¡ COMPATIBILITÃ‰ PYTORCH :
#   - Cette version CUDA (12.1.1) correspond aux builds officiels PyTorch :
#     https://download.pytorch.org/whl/cu121
#   - Cela Ã©vite les erreurs de type Â« CUDA driver mismatch Â» lors de lâ€™exÃ©cution.
#
# ğŸ§© SUFFIXE Â« AS base Â» :
#   - Permet de nommer cette Ã©tape du build et de la rÃ©utiliser ensuite (multi-stage build).
#   - Exemple : Â« FROM base AS deps Â» crÃ©e une nouvelle Ã©tape hÃ©ritant de celle-ci.
#   - Avantages :
#       â€¢ sÃ©paration entre installation lourde et image finale (runtime lÃ©ger)
#       â€¢ rÃ©duction du poids final
#       â€¢ caching efficace pour accÃ©lÃ©rer les builds successifs
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ DÃ©finit lâ€™image de base GPU du conteneur :
#       â€¢ `nvidia/cuda:12.1.1-runtime-ubuntu22.04` â†’ environnement Ubuntu 22.04 optimisÃ© pour CUDA 12.1  
#       â€¢ Variante `runtime` : lÃ©gÃ¨re, contient uniquement les bibliothÃ¨ques nÃ©cessaires Ã  lâ€™exÃ©cution GPU  
#   âœ Compatible avec PyTorch CUDA 12.1 (cu121) et idÃ©ale pour un service dâ€™infÃ©rence sans outils de compilation.  
#   âœ Le suffixe `AS base` permet la rÃ©utilisation dans les builds multi-Ã©tapes pour optimiser taille et cache.
####################################################################################################



ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONIOENCODING=UTF-8
####################################################################################################
# ğŸ” LIGNE DOCKER
# ENV DEBIAN_FRONTEND=noninteractive \
#     PYTHONUNBUFFERED=1 \
#     PYTHONIOENCODING=UTF-8
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction dÃ©finit trois variables dâ€™environnement essentielles au bon fonctionnement
# du conteneur pendant le build et Ã  lâ€™exÃ©cution. Ces variables influencent :
#   â€¢ le comportement des commandes APT (installation sans blocage)
#   â€¢ la gestion des flux de logs Python (sortie immÃ©diate)
#   â€¢ la cohÃ©rence de lâ€™encodage des caractÃ¨res (UTF-8 par dÃ©faut)
#
# âš™ï¸ DÃ‰TAILS DES VARIABLES :
#
# 1ï¸âƒ£ DEBIAN_FRONTEND=noninteractive
#     â†’ Supprime toute interaction utilisateur lors des installations via APT.
#     â†’ EmpÃªche les invites de configuration (ex. fuseau horaire, services, clavier...).
#     â†’ Indispensable dans un build Docker automatisÃ© (sinon le build bloque).
#
# 2ï¸âƒ£ PYTHONUNBUFFERED=1
#     â†’ DÃ©sactive le buffering de la sortie standard de Python (stdout/stderr).
#     â†’ Permet dâ€™obtenir les logs en temps rÃ©el dans la console Docker (utile pour debug).
#     â†’ Sans cette option, les sorties peuvent Ãªtre retardÃ©es ou perdues dans les buffers.
#
# 3ï¸âƒ£ PYTHONIOENCODING=UTF-8
#     â†’ Force lâ€™encodage dâ€™entrÃ©e/sortie Python en UTF-8.
#     â†’ Ã‰vite les erreurs liÃ©es aux caractÃ¨res spÃ©ciaux (accents, symboles scientifiques, etc.).
#     â†’ Garantit une compatibilitÃ© cohÃ©rente entre le systÃ¨me (Ubuntu) et Python.
#
# ğŸ§© BONNES PRATIQUES :
#   â€¢ Ces trois variables sont devenues un standard dans les conteneurs Python modernes.
#   â€¢ Elles assurent un comportement stable, prÃ©visible et compatible avec les pipelines CI/CD.
#   â€¢ Elles facilitent Ã©galement lâ€™intÃ©gration de journaux structurÃ©s (ex. FastAPI, PyTorch logs).
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Garantit un comportement stable et automatisÃ© du conteneur :
#       â€¢ `DEBIAN_FRONTEND=noninteractive` : Ã©vite tout blocage APT durant le build
#       â€¢ `PYTHONUNBUFFERED=1` : assure des logs Python visibles en temps rÃ©el
#       â€¢ `PYTHONIOENCODING=UTF-8` : homogÃ©nÃ©ise lâ€™encodage des caractÃ¨res (prÃ©vention erreurs Unicode)
#   âœ Ensemble, ces variables rendent le build non-interactif, les logs immÃ©diats et les traitements texte sÃ»rs.
####################################################################################################


WORKDIR /app
####################################################################################################
# ğŸ” LIGNE DOCKER
# WORKDIR /app
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction dÃ©finit le **rÃ©pertoire de travail par dÃ©faut** Ã  lâ€™intÃ©rieur du conteneur.
# Toutes les commandes suivantes (`RUN`, `COPY`, `CMD`, `ENTRYPOINT`, etc.) seront exÃ©cutÃ©es
# Ã  partir de ce dossier, sauf indication contraire.
#
# âš™ï¸ DÃ‰TAILS :
#   â€¢ `/app` devient la racine logique du projet dans le conteneur.
#   â€¢ Les chemins relatifs utilisÃ©s ensuite (ex. `COPY src/ ./src/`) seront interprÃ©tÃ©s
#     relativement Ã  ce rÃ©pertoire.
#   â€¢ Cela garantit une structure cohÃ©rente entre ton environnement local et le conteneur.
#
# ğŸ§© RAISON DU CHOIX Â« /app Â» :
#   - `/app` est devenu une convention dans les images Docker Python et ML modernes.
#   - Simple, explicite et compatible avec la plupart des orchestrateurs (Docker Compose, K8s).
#   - Ã‰vite les dossiers systÃ¨me (`/usr`, `/opt`) rÃ©servÃ©s aux binaires du systÃ¨me de base.
#
# ğŸ’¡ BONNES PRATIQUES :
#   â€¢ Toujours dÃ©finir explicitement `WORKDIR` plutÃ´t que dâ€™utiliser des chemins relatifs.
#   â€¢ Cela amÃ©liore la lisibilitÃ© du Dockerfile et la portabilitÃ© du projet.
#   â€¢ Si tu montes un volume (`-v $(pwd):/app`), ton code local apparaÃ®tra directement ici.
#
# ğŸ§± STRUCTURE ATTENDUE DANS /app :
#   /app/
#     â”œâ”€â”€ src/               â†’ code source Python (modules, services)
#     â”œâ”€â”€ pyproject.toml     â†’ mÃ©tadonnÃ©es du projet (gÃ©rÃ©es par uv)
#     â”œâ”€â”€ uv.lock            â†’ dÃ©pendances figÃ©es (lockfile)
#     â”œâ”€â”€ logs/              â†’ journaux dâ€™exÃ©cution (montables en volume)
#     â””â”€â”€ ...                â†’ autres ressources nÃ©cessaires Ã  lâ€™infÃ©rence
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Facilite les opÃ©rations de copie, de montage et de dÃ©ploiement.
#   âœ Garantit la cohÃ©rence des chemins dans tout le pipeline Docker/Python.
####################################################################################################



# ğŸ§© Install system dependencies
RUN --mount=type=cache,target=/var/cache/apt \
    apt-get update && apt-get install -y --no-install-recommends \
      ca-certificates curl git build-essential ffmpeg \
      libsm6 libxext6 libxrender1 && \
    rm -rf /var/lib/apt/lists/*
####################################################################################################
# ğŸ” LIGNE DOCKER
# RUN --mount=type=cache,target=/var/cache/apt \
#     apt-get update && apt-get install -y --no-install-recommends \
#       ca-certificates curl git build-essential ffmpeg \
#       libsm6 libxext6 libxrender1 && \
#     rm -rf /var/lib/apt/lists/*
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette commande installe les dÃ©pendances systÃ¨me nÃ©cessaires au bon fonctionnement
# des bibliothÃ¨ques Python utilisÃ©es dans le projet (notamment PyTorch, OpenCV, et pyigtl).
# Elle repose sur le gestionnaire de paquets APT fourni par Ubuntu.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ RUN
#     â†’ Indique Ã  Docker dâ€™exÃ©cuter les commandes shell listÃ©es sur une seule couche du build.
#     â†’ Chaque RUN crÃ©e une nouvelle couche dans lâ€™image Docker finale.
#
# 2ï¸âƒ£ --mount=type=cache,target=/var/cache/apt
#     â†’ Syntaxe Docker BuildKit : crÃ©e un **cache persistant** pour le dossier `/var/cache/apt`.
#     â†’ Cela permet de rÃ©utiliser les fichiers de paquets tÃ©lÃ©chargÃ©s entre diffÃ©rents builds,
#       accÃ©lÃ©rant grandement les reconstructions de lâ€™image.
#     â†’ NÃ©cessite BuildKit activÃ© (par dÃ©faut sur Docker â‰¥ 23).
#
# 3ï¸âƒ£ apt-get update
#     â†’ Met Ã  jour la liste locale des paquets disponibles depuis les dÃ©pÃ´ts APT configurÃ©s.
#     â†’ Indispensable avant toute installation pour garantir des versions rÃ©centes.
#
# 4ï¸âƒ£ apt-get install -y --no-install-recommends [paquets...]
#     â†’ Installe les paquets nÃ©cessaires.
#       - `-y` : approuve automatiquement lâ€™installation (sinon Docker bloquerait en attente dâ€™un â€œYes/Noâ€).
#       - `--no-install-recommends` : nâ€™installe **que les dÃ©pendances strictement requises**, 
#         Ã©vitant les paquets supplÃ©mentaires facultatifs â†’ gain de place.
#
# 5ï¸âƒ£ rm -rf /var/lib/apt/lists/*
#     â†’ Supprime la base locale des mÃ©tadonnÃ©es APT une fois lâ€™installation terminÃ©e.
#     â†’ Cela nettoie plusieurs centaines de Mo et garde lâ€™image plus lÃ©gÃ¨re.
#
# ğŸ“¦ LISTE DÃ‰TAILLÃ‰E DES PAQUETS INSTALLÃ‰S :
#
#   â€¢ ca-certificates : permet Ã  Python, curl ou git de valider les connexions HTTPS (certificats SSL)
#   â€¢ curl            : outil de transfert HTTP(S), souvent utilisÃ© pour tÃ©lÃ©charger des modÃ¨les
#   â€¢ git             : nÃ©cessaire si des modules Python sont installÃ©s depuis des dÃ©pÃ´ts Git
#   â€¢ build-essential : regroupe gcc, g++, makeâ€¦ requis par certaines wheels (ex. pyigtl, torchmetrics)
#   â€¢ ffmpeg          : indispensable pour la lecture/Ã©criture vidÃ©o (OpenCV, traitement dâ€™images)
#   â€¢ libsm6, libxext6, libxrender1 : bibliothÃ¨ques X11 minimales pour le rendu graphique OpenCV
#
# ğŸ’¡ BONNES PRATIQUES :
#   â€¢ Grouper ces opÃ©rations sur une seule ligne RUN permet de rÃ©duire le nombre de couches Docker.
#   â€¢ Utiliser --mount=type=cache accÃ©lÃ¨re les builds itÃ©ratifs et Ã©conomise la bande passante.
#   â€¢ Nettoyer /var/lib/apt/lists est essentiel pour minimiser la taille de lâ€™image finale.
#
# ğŸ§© EN SYNTHÃˆSE :
#   âœ Installe un socle Linux minimal compatible avec les bibliothÃ¨ques IA (torch, opencv, pyigtl)
#   âœ Utilise le cache APT pour optimiser la vitesse des builds
#   âœ Nettoie immÃ©diatement les fichiers temporaires pour garder une image lÃ©gÃ¨re et propre
####################################################################################################


# âš™ï¸ Copy uv executable
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv
####################################################################################################
# ğŸ” LIGNE DOCKER
# COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction copie lâ€™exÃ©cutable **uv** directement depuis lâ€™image officielle distribuÃ©e
# par Astral (hÃ©bergÃ©e sur GitHub Container Registry). 
# Elle permet dâ€™installer lâ€™outil de gestion Python Â« uv Â» sans passer par pip ni curl,
# garantissant ainsi une installation propre, rapide et sÃ©curisÃ©e.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ COPY
#     â†’ Commande Docker qui copie des fichiers ou rÃ©pertoires dans lâ€™image.
#       Syntaxe gÃ©nÃ©rale : COPY [--from=<image_source>] <source> <destination>
#
# 2ï¸âƒ£ --from=ghcr.io/astral-sh/uv:latest
#     â†’ Indique que la source Ã  copier provient **dâ€™une autre image Docker**, et non du contexte local.
#     â†’ Ici, la source est lâ€™image officielle `uv` publiÃ©e sur GitHub Container Registry :
#         https://ghcr.io/astral-sh/uv
#     â†’ `:latest` sÃ©lectionne la version la plus rÃ©cente de lâ€™exÃ©cutable prÃ©compilÃ©.
#     â†’ Cette approche â€œmulti-stage copyâ€ Ã©vite dâ€™installer ou de compiler quoi que ce soit :
#         âœ… pas de `pip install uv`
#         âœ… pas de dÃ©pendances Python intermÃ©diaires
#         âœ… gain de temps et de fiabilitÃ©
#
# 3ï¸âƒ£ /uv
#     â†’ Chemin du binaire `uv` Ã  lâ€™intÃ©rieur de lâ€™image source (Astral).
#     â†’ Lâ€™exÃ©cutable statique y est placÃ© Ã  la racine dans lâ€™image `ghcr.io/astral-sh/uv`.
#
# 4ï¸âƒ£ /bin/uv
#     â†’ Destination dans le conteneur final.
#     â†’ `/bin` fait partie du PATH par dÃ©faut sur Linux, donc la commande `uv` sera accessible
#       globalement dans tout le conteneur, sans avoir besoin de spÃ©cifier un chemin absolu.
#
# ğŸ§© AVANTAGES DE CETTE APPROCHE :
#   â€¢ **RapiditÃ©** : lâ€™image `uv` contient dÃ©jÃ  le binaire compilÃ© â†’ aucune compilation ni dÃ©pendance.
#   â€¢ **SÃ©curitÃ©** : pas de tÃ©lÃ©chargement dynamique (ni `curl | bash`).
#   â€¢ **ReproductibilitÃ©** : Docker garantit que lâ€™on copie exactement le mÃªme binaire Ã  chaque build.
#   â€¢ **LÃ©gÃ¨retÃ©** : aucune couche Python inutile (contrairement Ã  `pip install uv` qui installe Rust).
#
# ğŸ’¡ Ã€ SAVOIR :
#   â€¢ `uv` est un gestionnaire de dÃ©pendances Python moderne (par Astral), compatible avec `pyproject.toml`.
#   â€¢ Il remplace `pip`, `venv`, `pip-tools` et `virtualenv` en une seule commande.
#   â€¢ Sa vitesse repose sur un cÅ“ur Rust extrÃªmement optimisÃ©.
#
# ğŸ§© EXEMPLES Dâ€™USAGE DANS LE CONTENEUR :
#     uv python install 3.11        â†’ installe une version locale de Python
#     uv sync                       â†’ installe les dÃ©pendances listÃ©es dans pyproject.toml
#     uv add fastapi                â†’ ajoute un module et met Ã  jour uv.lock
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Copie un exÃ©cutable prÃ©compilÃ© depuis lâ€™image officielle Astral
#   âœ Installe `uv` sans dÃ©pendances externes, de maniÃ¨re fiable et rapide
#   âœ PrÃ©pare lâ€™environnement Python pour les Ã©tapes suivantes du Dockerfile
####################################################################################################


# ğŸ§  Install Python 3.11 with uv
RUN uv python install 3.11
####################################################################################################
# ğŸ” LIGNE DOCKER
# RUN uv python install 3.11
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction installe une **version spÃ©cifique de Python (ici 3.11)** directement Ã  lâ€™intÃ©rieur
# du conteneur, en utilisant le gestionnaire `uv` (dÃ©veloppÃ© par Astral).  
# Elle remplace avantageusement les mÃ©thodes classiques comme `apt install python3` ou `pyenv install`.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ RUN
#     â†’ ExÃ©cute la commande indiquÃ©e Ã  lâ€™intÃ©rieur dâ€™une nouvelle couche Docker.
#     â†’ Ici, on exÃ©cute la commande `uv python install 3.11` au moment du build.
#
# 2ï¸âƒ£ uv python install 3.11
#     â†’ Appelle le sous-module `python` de lâ€™outil `uv`.
#     â†’ Installe la version 3.11.x de Python (la plus rÃ©cente compatible).
#     â†’ TÃ©lÃ©charge un **binaire Python prÃ©compilÃ©** (build officiel CPython) directement depuis
#       les serveurs dâ€™Astral, sans passer par APT ni compilation locale.
#
# ğŸ§° COMPORTEMENT TECHNIQUE :
#   - `uv` installe Python dans un dossier interne Ã  lâ€™utilisateur :
#       /root/.local/share/uv/python/cp311/
#   - Ce dossier contient un environnement Python complet et isolÃ© :
#       â”œâ”€â”€ bin/python  â†’ exÃ©cutable principal
#       â”œâ”€â”€ lib/        â†’ bibliothÃ¨ques standard
#       â””â”€â”€ include/    â†’ headers
#   - Lâ€™installation est **reproductible**, car `uv` conserve un cache de versions exactes.
#
# ğŸ’¡ COMPARAISON AVEC Dâ€™AUTRES MÃ‰THODES :
#
#   | MÃ©thode                    | Avantage                          | InconvÃ©nient                        |
#   |-----------------------------|-----------------------------------|--------------------------------------|
#   | apt install python3         | Simple, natif Ubuntu              | Versions souvent anciennes (3.10)    |
#   | pyenv install 3.11          | Flexible                          | Lent, compile depuis les sources     |
#   | conda install python=3.11   | Multi-env pratique                | Lourde, dÃ©pendances Anaconda         |
#   | âœ… uv python install 3.11   | Rapide, lÃ©ger, reproductible      | NÃ©cessite lâ€™outil uv (dÃ©jÃ  inclus)   |
#
# ğŸ§© AVANTAGES CONCRETS :
#   â€¢ **Vitesse** : installation instantanÃ©e depuis des binaires Rust optimisÃ©s.
#   â€¢ **Isolation** : chaque version de Python est stockÃ©e indÃ©pendamment, sans polluer /usr/bin.
#   â€¢ **ReproductibilitÃ©** : mÃªme build Python sur tous les environnements (dev, CI, prod).
#   â€¢ **CompatibilitÃ©** : les chemins sâ€™intÃ¨grent proprement dans Docker et PATH.
#
# ğŸ§  BONNES PRATIQUES :
#   â€¢ Toujours utiliser une version explicite (`3.11`, pas `latest`) pour garantir la stabilitÃ©.
#   â€¢ Cette commande sâ€™exÃ©cute une seule fois par image (le cache Docker la rÃ©utilisera ensuite).
#   â€¢ En combinaison avec la ligne suivante :
#         ENV PATH="/root/.local/share/uv/python/cp311/bin:${PATH}"
#     â†’ cela rend Python 3.11 disponible globalement dans le conteneur.
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Installe Python 3.11 de maniÃ¨re propre, rapide et isolÃ©e via uv
#   âœ Ã‰vite les limitations de apt et pyenv
#   âœ PrÃ©pare un environnement reproductible pour la suite du build
####################################################################################################

ENV PATH="/root/.local/share/uv/python/cp311/bin:${PATH}"
####################################################################################################
# ğŸ” LIGNE DOCKER
# ENV PATH="/root/.local/share/uv/python/cp311/bin:${PATH}"
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction dÃ©finit (ou modifie) la variable dâ€™environnement **PATH** dans le conteneur.
# Elle ajoute au dÃ©but du PATH le rÃ©pertoire contenant lâ€™exÃ©cutable Python installÃ© via `uv`,
# afin que les commandes `python`, `pip`, et `uv` soient directement accessibles dans le terminal
# sans prÃ©ciser leur chemin absolu.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ ENV
#     â†’ DÃ©finit une variable dâ€™environnement persistante Ã  lâ€™intÃ©rieur de lâ€™image Docker.
#     â†’ Ces variables sont automatiquement disponibles pour toutes les commandes `RUN`, `CMD`,
#       `ENTRYPOINT`, ainsi que dans le shell du conteneur une fois dÃ©marrÃ©.
#
# 2ï¸âƒ£ PATH="/root/.local/share/uv/python/cp311/bin:${PATH}"
#     â†’ Modifie la variable dâ€™environnement PATH pour y **prÃ©fixer** le chemin du binaire Python
#       installÃ© par `uv` :
#         /root/.local/share/uv/python/cp311/bin
#
#     â†’ `${PATH}` Ã  la fin permet de **conserver le PATH existant** (hÃ©ritÃ© du systÃ¨me Ubuntu),
#       en ajoutant simplement le dossier de Python en tÃªte.  
#       Cela signifie que, lorsquâ€™on appelle une commande :
#         - Docker cherche dâ€™abord dans `/root/.local/share/uv/python/cp311/bin`
#         - puis dans les autres rÃ©pertoires standards comme `/usr/bin`, `/bin`, etc.
#
# ğŸ§° CHEMIN DÃ‰TAILLÃ‰ :
#   â€¢ `/root/.local/share/uv/python/cp311/bin/`
#       â”œâ”€â”€ python      â†’ exÃ©cutable principal (interprÃ©teur CPython 3.11)
#       â”œâ”€â”€ pip         â†’ installateur de paquets liÃ© Ã  cette version
#       â”œâ”€â”€ uv          â†’ gestionnaire global
#       â””â”€â”€ autres outils dÃ©pendant de Python
#
# ğŸ’¡ POURQUOI AJOUTER CE CHEMIN :
#   - Les exÃ©cutables installÃ©s par `uv` ne sont **pas placÃ©s dans `/usr/bin`** (rÃ©servÃ© au systÃ¨me).
#   - En les ajoutant explicitement dans le PATH :
#       â†’ `python` devient disponible globalement,
#       â†’ les outils installÃ©s via `pip` ou `uv` seront Ã©galement accessibles directement.
#   - Cela rend lâ€™environnement **fonctionnel et cohÃ©rent** sans modifier les chemins systÃ¨me.
#
# ğŸ§© BONNES PRATIQUES :
#   â€¢ Toujours **prÃ©fixer** (et non remplacer) le PATH existant : `${PATH}` doit rester en fin.
#   â€¢ Ã‰viter dâ€™Ã©crire des chemins absolus dans les commandes suivantes (grÃ¢ce Ã  ce ENV).
#   â€¢ Cette approche garantit la portabilitÃ© et la reproductibilitÃ© entre conteneurs et hÃ´tes.
#
# ğŸ§  EXEMPLE CONCRET :
#   AprÃ¨s cette instruction, les commandes suivantes fonctionneront partout :
#       RUN python --version      â†’ affiche "Python 3.11.x"
#       RUN pip install numpy     â†’ installe les paquets dans lâ€™env. uv
#       RUN uv --version          â†’ exÃ©cute le gestionnaire uv global
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Rend lâ€™environnement Python 3.11 installÃ© par uv globalement accessible
#   âœ PrÃ©serve le PATH systÃ¨me dâ€™origine
#   âœ Ã‰vite toute confusion entre Python systÃ¨me (APT) et Python gÃ©rÃ© par uv
####################################################################################################

# ğŸ”§ Configure uv for PyTorch index
ENV UV_LINK_MODE=copy \
    UV_NATIVE_TLS=true \
    UV_EXTRA_INDEX_URL=https://download.pytorch.org/whl/cu121
####################################################################################################
# ğŸ” LIGNE DOCKER
# ENV UV_LINK_MODE=copy \
#     UV_NATIVE_TLS=true \
#     UV_EXTRA_INDEX_URL=https://download.pytorch.org/whl/cu121
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Ce bloc configure trois variables dâ€™environnement propres Ã  lâ€™outil **uv** (Astral).
# Elles influencent :
#   â€¢ la maniÃ¨re dont uv gÃ¨re les liens symboliques et les fichiers installÃ©s,
#   â€¢ la sÃ©curitÃ© des connexions rÃ©seau (TLS natif),
#   â€¢ et les sources de tÃ©lÃ©chargement des paquets Python (index supplÃ©mentaires).
#
# âš™ï¸ DÃ‰COMPOSITION VARIABLE PAR VARIABLE :
#
# 1ï¸âƒ£ UV_LINK_MODE=copy
#     â†’ DÃ©finit le mode de lien utilisÃ© par uv lors de lâ€™installation des paquets.
#     â†’ Par dÃ©faut, uv peut â€œlierâ€ les fichiers installÃ©s via symlink ou hardlink pour Ã©conomiser
#       de lâ€™espace disque.  
#     â†’ Ici, on force le mode `copy` afin :
#         - dâ€™Ã©viter tout comportement inattendu avec les couches Docker (les liens peuvent casser),
#         - dâ€™assurer que chaque environnement possÃ¨de sa propre copie physique des fichiers.
#     â†’ Ce mode amÃ©liore la **reproductibilitÃ©** et la **stabilitÃ©** des builds.
#
# 2ï¸âƒ£ UV_NATIVE_TLS=true
#     â†’ Indique Ã  uv dâ€™utiliser la bibliothÃ¨que TLS native du systÃ¨me (libssl/libcrypto),
#       au lieu de la sienne embarquÃ©e.
#     â†’ Avantages :
#         â€¢ meilleure compatibilitÃ© avec le certificat racine du systÃ¨me (ca-certificates)
#         â€¢ Ã©vite des erreurs SSL lors de connexions HTTPS (notamment vers PyPI ou GitHub)
#         â€¢ accÃ©lÃ¨re les requÃªtes rÃ©seau (meilleure intÃ©gration OpenSSL)
#     â†’ Câ€™est une bonne pratique pour tous les environnements Docker sÃ©curisÃ©s.
#
# 3ï¸âƒ£ UV_EXTRA_INDEX_URL=https://download.pytorch.org/whl/cu121
#     â†’ Ajoute un index PyPI secondaire pour que uv/pip puisse y rechercher les paquets manquants.
#     â†’ Ici, lâ€™URL correspond au dÃ©pÃ´t officiel des wheels PyTorch **CUDA 12.1 (cu121)** :
#           https://download.pytorch.org/whl/cu121
#     â†’ Cela garantit que torch, torchvision, et torchaudio seront installÃ©s avec la bonne
#       compatibilitÃ© CUDA (correspondant Ã  lâ€™image `nvidia/cuda:12.1.1`).
#
# ğŸ§© COMPORTEMENT RÃ‰EL :
#   â€¢ Lors dâ€™un `uv sync` ou `uv pip install`, uv :
#       1. lit dâ€™abord `pyproject.toml` et `uv.lock`,
#       2. cherche les paquets sur PyPI (index principal),
#       3. si besoin, bascule vers lâ€™index supplÃ©mentaire (ici celui de PyTorch),
#       4. tÃ©lÃ©charge et installe les versions compatibles CUDA 12.1.
#
# ğŸ’¡ BONNES PRATIQUES :
#   â€¢ Toujours dÃ©finir ces variables dans le Dockerfile (et non via CLI) pour assurer la cohÃ©rence
#     entre builds et dÃ©ploiements.
#   â€¢ `UV_LINK_MODE=copy` est recommandÃ© dans tous les environnements Docker ou CI/CD.
#   â€¢ `UV_NATIVE_TLS=true` amÃ©liore la sÃ©curitÃ© des builds en Ã©vitant des erreurs de certificats.
#   â€¢ Lâ€™index PyTorch doit correspondre strictement Ã  la version CUDA de lâ€™image de base.
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Configure uv pour un comportement stable et compatible avec Docker
#   âœ Active le TLS natif pour sÃ©curiser les tÃ©lÃ©chargements de paquets
#   âœ Ajoute lâ€™index PyTorch officiel CUDA 12.1 pour installer torch/vision sans conflit
####################################################################################################


# ğŸ“„ Copy dependency manifests
COPY pyproject.toml uv.lock* /app/
####################################################################################################
# ğŸ” LIGNE DOCKER
# COPY pyproject.toml uv.lock* /app/
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette commande copie dans lâ€™image Docker les fichiers de configuration du projet Python
# nÃ©cessaires Ã  la gestion des dÃ©pendances avec **uv** :
#   - `pyproject.toml` : dÃ©crit les mÃ©tadonnÃ©es et dÃ©pendances du projet (standard PEP 621)
#   - `uv.lock`        : fige les versions exactes installÃ©es (lockfile de reproductibilitÃ©)
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ COPY
#     â†’ Directive Docker pour copier des fichiers depuis le contexte de build (dossier local)
#       vers le systÃ¨me de fichiers de lâ€™image en cours de construction.
#     â†’ Syntaxe : COPY <source> <destination>
#     â†’ Ici :
#         â€¢ <source> = pyproject.toml et uv.lock* (le * permet de copier mÃªme si le fichier nâ€™existe pas)
#         â€¢ <destination> = /app/ (le rÃ©pertoire de travail dÃ©fini prÃ©cÃ©demment)
#
# 2ï¸âƒ£ pyproject.toml
#     â†’ Fichier de configuration central des projets Python modernes (norme PEP 518/621).
#     â†’ RÃ´le :
#         - DÃ©clare le nom, la version, les dÃ©pendances et le backend de build du projet.
#         - Remplace les anciens fichiers sÃ©parÃ©s (setup.py, requirements.txt, etc.).
#         - Est lu par `uv`, `pip`, `poetry` ou tout autre gestionnaire conforme PEP.
#     â†’ Exemple minimal :
#           [project]
#           name = "inference-service"
#           dependencies = ["torch", "opencv-python", "pyigtl"]
#
# 3ï¸âƒ£ uv.lock*
#     â†’ Fichier gÃ©nÃ©rÃ© automatiquement par `uv` aprÃ¨s un `uv sync` ou `uv add`.
#     â†’ Contient la **rÃ©solution exacte des dÃ©pendances** (noms, versions, hashes SHA256).
#     â†’ Le `*` Ã  la fin signifie Â« copier si prÃ©sent Â» â€” pratique lors du premier build,
#       avant quâ€™un lockfile nâ€™existe encore.
#     â†’ Avantage :
#         - permet Ã  Docker de **mettre en cache lâ€™Ã©tape dâ€™installation** tant que ces fichiers
#           nâ€™ont pas changÃ© : si le code source Ã©volue mais pas les dÃ©pendances, le build reste instantanÃ©.
#
# ğŸ§© BONNES PRATIQUES :
#   â€¢ Toujours copier dâ€™abord `pyproject.toml` et `uv.lock` avant le reste du code source :
#       â†’ cela maximise la rÃ©utilisation du cache Docker.
#       â†’ lâ€™Ã©tape suivante (`uv sync --frozen --system`) ne se relancera que si les dÃ©pendances changent.
#   â€¢ Ã‰viter de copier tout le projet Ã  ce stade (garder cette couche spÃ©cifique aux dÃ©pendances).
#
# ğŸ’¡ COMPORTEMENT TYPIQUE DU CACHE :
#   1. Docker compare les fichiers copiÃ©s Ã  la version prÃ©cÃ©dente du cache.
#   2. Si `pyproject.toml` ou `uv.lock` nâ€™a pas changÃ© â†’ lâ€™Ã©tape dâ€™installation sera sautÃ©e.
#   3. Si un de ces fichiers est modifiÃ© â†’ uv rÃ©installe les paquets (Ã©tape suivante).
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Copie les manifestes de dÃ©pendances Python dans /app/
#   âœ Permet Ã  Docker de dÃ©tecter les changements de dÃ©pendances via le cache
#   âœ PrÃ©pare lâ€™Ã©tape suivante (installation via uv) sans encore copier le code source
####################################################################################################


# ğŸ“¦ Install project dependencies directly from pyproject
RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync --frozen --system
####################################################################################################
# ğŸ” LIGNE DOCKER
# RUN --mount=type=cache,target=/root/.cache/uv \
#     uv sync --frozen --system
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette commande installe toutes les dÃ©pendances Python du projet dans lâ€™environnement global
# du conteneur, Ã  partir des fichiers `pyproject.toml` et `uv.lock`.
# Elle est exÃ©cutÃ©e via `uv`, le gestionnaire moderne de dÃ©pendances, pour une installation :
#   â€¢ rapide  âš¡  (grÃ¢ce Ã  son cÅ“ur Rust)
#   â€¢ dÃ©terministe  ğŸ”’  (versions verrouillÃ©es dans uv.lock)
#   â€¢ optimisÃ©e  ğŸ’¾  (avec cache persistant partagÃ© entre builds)
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ RUN
#     â†’ CrÃ©e une nouvelle couche Docker exÃ©cutant les commandes spÃ©cifiÃ©es.
#     â†’ Chaque RUN sâ€™exÃ©cute dans le contexte dÃ©fini par les instructions prÃ©cÃ©dentes (ici /app).
#
# 2ï¸âƒ£ --mount=type=cache,target=/root/.cache/uv
#     â†’ Directive Docker BuildKit permettant de **monter un cache persistant** entre builds successifs.
#     â†’ Ici, le cache `/root/.cache/uv` sera conservÃ© entre les reconstructions de lâ€™image :
#         - Les fichiers de paquets tÃ©lÃ©chargÃ©s par uv seront rÃ©utilisÃ©s.
#         - Les installations ultÃ©rieures seront quasi instantanÃ©es si rien nâ€™a changÃ©.
#     â†’ Avantage : gros gain de temps et rÃ©duction de la bande passante.
#     â†’ NÃ©cessite Docker BuildKit (activÃ© par dÃ©faut depuis Docker 23+).
#
# 3ï¸âƒ£ uv sync
#     â†’ Commande principale de `uv` pour synchroniser les dÃ©pendances.
#     â†’ Compare les paquets actuellement installÃ©s avec ceux listÃ©s dans `pyproject.toml`
#       (et verrouillÃ©s dans `uv.lock`), puis installe ou met Ã  jour si nÃ©cessaire.
#     â†’ Ã‰quivalent moderne de :
#           pip install -r requirements.txt
#       mais en beaucoup plus rapide et fiable.
#
# 4ï¸âƒ£ --frozen
#     â†’ Force uv Ã  utiliser **uniquement** les versions exactes du `uv.lock`.
#     â†’ Si une dÃ©pendance nâ€™est pas rÃ©solue dans le lockfile, lâ€™installation Ã©choue.
#     â†’ Cela garantit la **reproductibilitÃ© totale** du build, idÃ©ale pour la CI/CD ou les dÃ©ploiements.
#
# 5ï¸âƒ£ --system
#     â†’ Installe les dÃ©pendances directement dans lâ€™environnement systÃ¨me du conteneur,
#       au lieu dâ€™un environnement virtuel local.
#     â†’ Avantage : les paquets sont immÃ©diatement accessibles via `python`, `pip`, etc.
#     â†’ Dans un conteneur isolÃ©, il nâ€™y a pas de risque de â€œpolluerâ€ le systÃ¨me hÃ´te.
#
# ğŸ§© COMPORTEMENT TECHNIQUE :
#   1. uv lit `pyproject.toml` et `uv.lock`
#   2. il rÃ©sout les dÃ©pendances et vÃ©rifie les versions/hashes
#   3. les fichiers wheel sont tÃ©lÃ©chargÃ©s (cache sous /root/.cache/uv)
#   4. installation dans `/root/.local/share/uv/python/cp311/lib/...`
#   5. couche Docker figÃ©e â€” inchangÃ©e tant que pyproject.toml et uv.lock ne changent pas
#
# ğŸ’¡ AVANTAGES DE CETTE APPROCHE :
#   â€¢ **DÃ©terministe** : les versions figÃ©es dans `uv.lock` assurent le mÃªme environnement partout.
#   â€¢ **Performant** : le cache Ã©vite de retÃ©lÃ©charger les wheels Ã  chaque build.
#   â€¢ **Propre** : pas de virtualenv inutile, pas de `pip install` rÃ©pÃ©titif.
#   â€¢ **SÃ©curisÃ©** : `--frozen` bloque tout changement non validÃ© par un commit du lockfile.
#
# ğŸ§  BONNES PRATIQUES :
#   â€¢ Toujours exÃ©cuter `uv lock` localement avant un build Docker pour gÃ©nÃ©rer le fichier `uv.lock`.
#   â€¢ Utiliser `--system` uniquement dans les conteneurs (jamais sur lâ€™hÃ´te).
#   â€¢ Si tu veux forcer une rÃ©installation complÃ¨te, supprime manuellement le cache :  
#         docker builder prune --filter type=cache
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Installe les dÃ©pendances Python listÃ©es dans pyproject.toml / uv.lock
#   âœ Exploite un cache partagÃ© pour accÃ©lÃ©rer les builds
#   âœ Assure une installation stable, dÃ©terministe et reproductible
####################################################################################################

# ğŸ“ Copy your application
COPY src/ /app/src/
####################################################################################################
# ğŸ” LIGNE DOCKER
# COPY src/ /app/src/
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction copie le code source du projet (dossier `src/` situÃ© sur la machine hÃ´te)
# vers le rÃ©pertoire `/app/src/` Ã  lâ€™intÃ©rieur du conteneur.  
# Câ€™est ici que sont placÃ©s les modules Python, les scripts, et le service dâ€™infÃ©rence
# exÃ©cutÃ© par lâ€™ENTRYPOINT final.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ COPY
#     â†’ Directive Docker permettant de copier des fichiers ou rÃ©pertoires depuis
#       le **contexte de build** (ton rÃ©pertoire local oÃ¹ se trouve le Dockerfile)
#       vers le systÃ¨me de fichiers de lâ€™image.
#     â†’ Syntaxe : COPY <source> <destination>
#
# 2ï¸âƒ£ src/
#     â†’ Dossier source local contenant le code Python du projet :
#         src/
#           â”œâ”€â”€ service/
#           â”‚    â””â”€â”€ inference_service.py   â†’ point dâ€™entrÃ©e de ton service IA
#           â”œâ”€â”€ models/                     â†’ Ã©ventuellement : SAM, D-FINE, etc.
#           â”œâ”€â”€ utils/                      â†’ fonctions communes, IGTLink, etc.
#           â””â”€â”€ __init__.py
#     â†’ Ce dossier doit exister Ã  la racine du projet, Ã  cÃ´tÃ© du Dockerfile et du pyproject.toml.
#
# 3ï¸âƒ£ /app/src/
#     â†’ Destination dans lâ€™image.  
#       On le place sous `/app` (dÃ©fini comme WORKDIR plus haut) pour garder une arborescence claire :
#         /app/
#           â”œâ”€â”€ src/        â†’ code source principal
#           â”œâ”€â”€ logs/       â†’ journaux dâ€™exÃ©cution
#           â”œâ”€â”€ pyproject.toml / uv.lock
#           â””â”€â”€ ...
#
# ğŸ§© RAISON DE CET ORDRE :
#   â€¢ On copie le code source **aprÃ¨s** avoir installÃ© les dÃ©pendances (`uv sync`).
#     Cela permet de :
#       â†’ tirer parti du cache Docker : si le code change mais pas les dÃ©pendances,
#         lâ€™Ã©tape dâ€™installation reste inchangÃ©e (gain de temps).
#       â†’ isoler le code applicatif de lâ€™environnement systÃ¨me.
#   â€¢ En pratique :
#       - Si tu modifies uniquement ton code Python â†’ build quasi instantanÃ© âœ…
#       - Si tu modifies `pyproject.toml` â†’ rebuild complet des dÃ©pendances ğŸ”
#
# ğŸ§  BONNES PRATIQUES :
#   â€¢ Ne jamais copier tout le dossier du projet (`COPY . /app`) : cela inclurait les fichiers inutiles
#     (.git/, .venv/, datasets, etc.) et casserait la logique de cache.
#   â€¢ Toujours cibler explicitement le dossier `src/` et les fichiers de config nÃ©cessaires.
#   â€¢ Ajouter un `.dockerignore` pour exclure les gros fichiers temporaires :
#         .venv/
#         __pycache__/
#         *.npy
#         *.pt
#         *.log
#
# ğŸ’¡ EXEMPLE DE STRUCTURE DE PROJET (rÃ©sumÃ©e) :
#   /Ultramotion-Inference/
#     â”œâ”€â”€ Dockerfile
#     â”œâ”€â”€ pyproject.toml
#     â”œâ”€â”€ uv.lock
#     â”œâ”€â”€ src/
#     â”‚    â””â”€â”€ service/
#     â”‚         â””â”€â”€ inference_service.py
#     â””â”€â”€ logs/
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ Copie le code source de ton application dans lâ€™image
#   âœ Respecte la sÃ©paration â€œenvironnement / codeâ€
#   âœ Optimise le cache Docker pour des rebuilds rapides
####################################################################################################

# ğŸŒ Expose port for IGTLink
EXPOSE 18944/tcp
####################################################################################################
# ğŸ” LIGNE DOCKER
# EXPOSE 18945/tcp
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette instruction indique au moteur Docker et aux utilisateurs de lâ€™image que le conteneur
# utilise le **port TCP 18945** pour communiquer avec lâ€™extÃ©rieur.
# Cela ne â€œpublieâ€ pas le port Ã  lui seul, mais le dÃ©clare comme **point dâ€™entrÃ©e rÃ©seau officiel**
# de lâ€™application Ã  lâ€™intÃ©rieur du conteneur.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ EXPOSE
#     â†’ Directive dÃ©clarative (mÃ©tadonnÃ©e) dans Dockerfile.
#     â†’ Syntaxe : EXPOSE <port>[/<protocole>]
#     â†’ Elle ne crÃ©e pas de rÃ¨gle de pare-feu : elle sert Ã  documenter les ports utilisÃ©s
#       et Ã  aider `docker run -P` ou `docker-compose` Ã  mapper automatiquement les ports.
#
# 2ï¸âƒ£ 18945
#     â†’ Port rÃ©seau standard utilisÃ© par **OpenIGTLink (IGTL)**, le protocole de communication
#       temps rÃ©el entre applications mÃ©dicales comme 3D Slicer, PlusServer, et ton service IA.
#     â†’ Par convention :
#         - PlusServer et Slicer se connectent via TCP sur 18944 ou 18945.
#         - Ici, on choisit 18945 pour diffÃ©rencier le flux de ton service IA
#           (segmentation / traitement) du flux principal dâ€™acquisition.
#
# 3ï¸âƒ£ /tcp
#     â†’ SpÃ©cifie le protocole de transport utilisÃ©.  
#       OpenIGTLink repose sur **TCP** pour garantir la fiabilitÃ© et lâ€™ordre des paquets
#       (contrairement Ã  UDP, qui privilÃ©gie la vitesse au dÃ©triment de la fiabilitÃ©).
#
# ğŸ§© COMPORTEMENT DANS DOCKER :
#   - Ã€ ce stade, le port est simplement â€œexposÃ©â€ Ã  lâ€™intÃ©rieur de lâ€™image.
#   - Pour quâ€™il soit accessible depuis lâ€™hÃ´te, il faut le **publier** au lancement du conteneur :
#         docker run -p 18945:18945 inference:latest
#   - Cette commande crÃ©e un tunnel entre le port 18945 du conteneur et le mÃªme port sur ta machine.
#
# ğŸ’¡ UTILISATION TYPIQUE DANS TON PIPELINE :
#   â€¢ Slicer ou PlusServer se connectent via :
#         OpenIGTLink â†’ IP du conteneur :18945
#   â€¢ Ton service IA (dans `inference_service.py`) Ã©coute sur ce port via pyigtl :
#         server = pyigtl.OpenIGTLinkServer(port=18945)
#   â€¢ Les messages IGTL (image, tracking, segmentation) transitent alors via ce canal TCP.
#
# ğŸ§  BONNES PRATIQUES :
#   â€¢ Toujours documenter explicitement les ports exposÃ©s dans le Dockerfile.
#   â€¢ Conserver les numÃ©ros cohÃ©rents avec ceux utilisÃ©s dans Slicer / PlusServer
#     pour simplifier les connexions et scripts dâ€™automatisation.
#   â€¢ Pour les environnements de production ou de cluster, dÃ©clarer aussi les ports
#     dans les fichiers docker-compose.yml ou Kubernetes manifest (service/ingress).
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ DÃ©clare le port rÃ©seau utilisÃ© par OpenIGTLink (18944/TCP)
#   âœ Facilite la communication entre ton conteneur IA et Slicer / PlusServer
#   âœ Documente la couche rÃ©seau de ton service dâ€™infÃ©rence
####################################################################################################

# ğŸ§ª Basic test (torch + numpy)
RUN python - <<'PY'
import torch, numpy, cv2
print("Torch:", torch.__version__, "CUDA OK:", torch.cuda.is_available())
print("NumPy:", numpy.__version__, "OpenCV:", cv2.__version__)
PY

# ğŸš€ Launch inference service
ENTRYPOINT ["python", "src/service/inference_service.py"]
####################################################################################################
# ğŸ” LIGNE DOCKER
# ENTRYPOINT ["python", "src/service/inference_service.py"]
#
# ğŸ§  RÃ”LE GÃ‰NÃ‰RAL :
# Cette directive dÃ©finit **le point dâ€™entrÃ©e (entrypoint)** du conteneur â€” câ€™est-Ã -dire
# la commande principale qui sera exÃ©cutÃ©e automatiquement au dÃ©marrage.
# Dans ton cas, elle lance le service dâ€™infÃ©rence Python basÃ© sur ton module IA.
#
# âš™ï¸ DÃ‰COMPOSITION DE LA SYNTAXE :
#
# 1ï¸âƒ£ ENTRYPOINT
#     â†’ SpÃ©cifie la commande Ã  exÃ©cuter par dÃ©faut lorsque le conteneur dÃ©marre.
#     â†’ Contrairement Ã  `CMD`, `ENTRYPOINT` ne peut pas Ãªtre facilement remplacÃ© au moment
#       du `docker run` (il fixe la â€œmissionâ€ du conteneur).
#     â†’ Syntaxe JSON (recommandÃ©e) : chaque argument est sÃ©parÃ© par une virgule, sans shell.
#
# 2ï¸âƒ£ ["python", "src/service/inference_service.py"]
#     â†’ Appelle lâ€™interprÃ©teur Python dÃ©fini plus haut (installÃ© via uv et ajoutÃ© au PATH).
#     â†’ ExÃ©cute ton script principal dâ€™infÃ©rence :
#         src/service/inference_service.py
#
# ğŸ§© COMPORTEMENT TECHNIQUE :
#   â€¢ Au dÃ©marrage du conteneur, Docker exÃ©cute :
#         python src/service/inference_service.py
#   â€¢ Si le service se bloque ou se termine, le conteneur sâ€™arrÃªte.
#   â€¢ Les logs produits par ton application (stdout/stderr) apparaissent directement
#     dans la console Docker â€” parfait pour le suivi en temps rÃ©el.
#
# ğŸ’¡ POURQUOI UTILISER ENTRYPOINT (ET NON CMD) :
#   | Directive | Comportement typique |
#   |------------|----------------------|
#   | CMD        | Peut Ãªtre remplacÃ©e par des arguments `docker run <cmd>` |
#   | ENTRYPOINT | Est exÃ©cutÃ©e systÃ©matiquement, mÃªme si des arguments sont ajoutÃ©s |
#
#   â†’ Exemple :
#        docker run inference:latest
#        â†’ lance automatiquement ton service dâ€™infÃ©rence
#
#        docker run -it inference:latest bash
#        â†’ âš ï¸ ne fonctionnera pas directement (ENTRYPOINT fixe), sauf si tu lâ€™overrides :
#             docker run -it --entrypoint bash inference:latest
#
# ğŸ§  BONNES PRATIQUES :
#   â€¢ Utiliser `ENTRYPOINT` pour les services â€œlongue durÃ©eâ€ (serveur, dÃ©mon, APIâ€¦).
#   â€¢ Utiliser `CMD` uniquement pour les conteneurs Ã  usage ponctuel (scripts, outils).
#   â€¢ Conserver la syntaxe JSON (plutÃ´t que la syntaxe shell) pour Ã©viter les interprÃ©tations
#     inattendues et garantir la portabilitÃ© Linux/Windows.
#
# ğŸ§© COMPORTEMENT ATTENDU POUR TON PROJET :
#   â€¢ Au dÃ©marrage :
#         â†’ Le service se connecte Ã  OpenIGTLink (port 18945)
#         â†’ Il Ã©coute les flux dâ€™images et de tracking envoyÃ©s depuis PlusServer/Slicer
#         â†’ Il effectue les infÃ©rences (segmentation, traitement, etc.)
#         â†’ Il renvoie les rÃ©sultats (masques, volumes, scores) en temps rÃ©el
#   â€¢ Ce service agit comme un **micro-serveur IA** intÃ©grÃ© dans la chaÃ®ne Ultramotion.
#
# ğŸ“˜ EN SYNTHÃˆSE :
#   âœ DÃ©finit le point dâ€™entrÃ©e principal du conteneur
#   âœ DÃ©marre automatiquement le service dâ€™infÃ©rence IA (pyigtl + torch)
#   âœ Fournit une exÃ©cution stable et autonome du pipeline IA dans Docker
####################################################################################################
