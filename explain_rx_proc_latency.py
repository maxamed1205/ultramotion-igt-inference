"""
Diagnostic : identifier d'oÃ¹ vient la latence RXâ†’PROC (0-2ms)
"""

# La latence mesurÃ©e dans les logs est :
# timestamp_log_PROC - timestamp_log_RX

# MAIS attention :
# 1. Le LOG RX est APRÃˆS gateway._inject_frame()
# 2. Le LOG PROC est APRÃˆS gateway.receive_image()

# Donc la latence mesurÃ©e inclut :
# A. Temps d'injection dans _mailbox (quasi-0)
# B. Temps d'attente avant que PROC ne lise (variable)
# C. Temps d'extraction depuis _mailbox (quasi-0)
# D. Overhead des logs asynchrones (quelques Âµs)

print("=" * 80)
print("ANALYSE DE LA LATENCE RXâ†’PROC (0-2ms)")
print("=" * 80)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  THREAD RX                          THREAD PROC                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  frame = RawFrame(...)                                          â”‚
â”‚  gateway._inject_frame(frame)  â”€â”€â†’  [_mailbox]                 â”‚
â”‚       â†“ (injection = ~0Âµs)                   â†“                  â”‚
â”‚  LOG.info("[RX] Generated")                  â†“                  â”‚
â”‚       â†“                                       â†“                  â”‚
â”‚  â±ï¸ TIMESTAMP LOG RX capturÃ© ici             â†“                  â”‚
â”‚       â†“                                       â†“                  â”‚
â”‚       â†“                            if len(_mailbox) == 0:       â”‚
â”‚       â†“                                sleep(0.0005) â† 0.5ms !  â”‚
â”‚       â†“                            frame = receive_image()      â”‚
â”‚       â†“                                       â†“                  â”‚
â”‚       â†“                            LOG.info("[PROC] Processed") â”‚
â”‚       â†“                                       â†“                  â”‚
â”‚       â†“                            â±ï¸ TIMESTAMP LOG PROC capturÃ©â”‚
â”‚       â†“                                                          â”‚
â”‚  [LATENCE MESURÃ‰E] = temps entre les 2 timestamps              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ” SOURCES DE LA LATENCE (0-2ms) :

1ï¸âƒ£  Python GIL (Global Interpreter Lock)
    â†’ 1 seul thread Python actif Ã  la fois
    â†’ Changement de contexte RXâ†’PROC = 100-500Âµs
    â†’ Explique la base de ~1ms

2ï¸âƒ£  Le sleep(0.0005) dans PROC (ligne 94)
    â†’ Si mailbox vide, PROC dort 0.5ms
    â†’ Mais mÃªme si pleine, cycle de vÃ©rification non-instantanÃ©
    â†’ Ajoute 0-1ms

3ï¸âƒ£  Ordonnancement OS (Windows Thread Scheduler)
    â†’ 3 threads daemon Python concurrents
    â†’ CPU peut allouer le temps Ã  TX au lieu de PROC
    â†’ Ajoute 0-1ms dans les pires cas

4ï¸âƒ£  Logs asynchrones (QueueHandler)
    â†’ LOG.info() envoie vers une queue
    â†’ Timestamp capturÃ© au moment du log
    â†’ Petit overhead (~50-100Âµs) mais nÃ©gligeable

5ï¸âƒ£  CrÃ©ation de l'image numpy (512x512)
    â†’ np.random.rand() + astype() dans RX
    â†’ Prend ~200-500Âµs
    â†’ MAIS ne compte PAS dans la latence (avant injection)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š DISTRIBUTION OBSERVÃ‰E :

- 0 ms (18%) : PROC Ã©tait dÃ©jÃ  bloquÃ© sur receive_image()
               â†’ RÃ©cupÃ©ration quasi-instantanÃ©e dÃ¨s injection
               
- 1 ms (77%) : CAS NORMAL - PROC vÃ©rifie mailbox dans son cycle
               â†’ GIL switch + cycle de vÃ©rification â‰ˆ 1ms
               
- 2 ms (5%)  : CONTENTION - PROC prÃ©emptÃ© par TX ou autre
               â†’ Doit attendre son tour CPU â†’ +1ms supplÃ©mentaire

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ CONCLUSION :

La latence 0-2ms n'est PAS un problÃ¨me de la pipeline !
C'est la COMBINAISON de :
  â€¢ Python GIL (mono-thread CPU)
  â€¢ sleep(0.0005) dans PROC
  â€¢ Ordonnancement OS non-dÃ©terministe
  â€¢ 3 threads concurrents se battant pour le CPU

âœ… 1ms est EXCELLENT pour une communication inter-thread Python !
âœ… Pas de bug, pas d'inefficacitÃ©, c'est la nature de Python threading

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ SI ON VOULAIT RÃ‰DUIRE Ã€ ~0ms (mais pas nÃ©cessaire) :

1. Remplacer sleep(0.0005) par un Event ou Condition
   â†’ PROC se rÃ©veillerait immÃ©diatement Ã  chaque injection
   
2. Utiliser multiprocessing au lieu de threading
   â†’ Ã‰viter le GIL, CPU parallÃ¨le rÃ©el
   â†’ MAIS overhead de sÃ©rialisation des frames
   
3. Logger AVANT receive_image() dans PROC
   â†’ Mais fausserait la vraie latence de traitement !

""")
