# ğŸ§­ AUDIT COMPLET DES TRANSFERTS GPUâ†’CPU

## ğŸ“Š RÃ©sumÃ© ExÃ©cutif

**Date du rapport:** 29 octobre 2025  
**PÃ©rimÃ¨tre:** `src/` et `tests/` - 25 conversions GPUâ†’CPU dÃ©tectÃ©es  
**Impact critique:** 4 transferts Ã  fort impact performance identifiÃ©s

## ğŸ“ˆ Statistiques Globales

### RÃ©partition par CatÃ©gorie
- ğŸ”µ **NÃ©cessaires (gardez):** 15 conversions (60%)
- ğŸŸ  **Redondants (optimisables):** 5 conversions (20%)  
- ğŸ”´ **Dangereux pour perf (prioritÃ©):** 4 conversions (16%)
- ğŸ§ª **Tests uniquement:** 1 conversion (4%)

### Impact Performance
- **Ã‰levÃ©:** 4 conversions (masques SAM, image preprocessing)
- **Moyen:** 8 conversions (bounding boxes, matrices)
- **Faible:** 13 conversions (scalaires, tests, cleanup)

## ğŸš¨ TOP 5 des Conversions Critiques

### 1. ğŸ”´ **MobileSAM Predictor** (PrioritÃ© P1)
**Fichier:** `src/core/inference/MobileSAM/mobile_sam/predictor.py`  
**Lignes:** 164-166  
**ProblÃ¨me:** Triple conversion massive `masks`, `iou_predictions`, `low_res_masks`
```python
masks_np = masks[0].detach().cpu().numpy()           # âš ï¸ GROS IMPACT
iou_predictions_np = iou_predictions[0].detach().cpu().numpy()
low_res_masks_np = low_res_masks[0].detach().cpu().numpy()  # Potentiellement inutile
```
**Impact:** Transfert de gros tenseurs (masques haute rÃ©solution) Ã  chaque frame  
**Recommandation:** Garder en tenseurs GPU jusqu'au `ResultPacket` final

### 2. ğŸ”´ **Orchestrator SAM Input** (PrioritÃ© P1)
**Fichier:** `src/core/inference/engine/orchestrator.py`  
**Ligne:** 88  
**ProblÃ¨me:** Conversion RGB premature pour SAM
```python
arr_np = arr[0].permute(1, 2, 0).detach().cpu().numpy()  # âš ï¸ GPUâ†’CPUâ†’GPU chain
```
**Impact:** Chain GPUâ†’CPUâ†’GPU si SAM traite l'image ensuite  
**Recommandation:** Passer directement le tensor GPU Ã  SAM ou convertir SAM vers GPU

### 3. ğŸŸ  **D-FINE Frame Debug** (PrioritÃ© P2)
**Fichier:** `src/core/inference/dfine_infer.py`  
**Ligne:** 145  
**ProblÃ¨me:** Conversion pour debug uniquement
```python
frame_cpu = frame_mono.detach().to("cpu", non_blocking=False)  # Debug only?
```
**Recommandation:** Supprimer si utilisÃ© uniquement pour debug

### 4. ğŸŸ  **Matcher Cost Matrix** (PrioritÃ© P2)
**Fichier:** `src/core/inference/d_fine/matcher.py`  
**Ligne:** 112  
**ProblÃ¨me:** Matrice de coÃ»t sur CPU
```python
C = C.view(bs, num_queries, -1).cpu()  # Hungarian matching on CPU
```
**Recommandation:** VÃ©rifier si Hungarian matching peut rester sur GPU

### 5. ğŸ”µ **D-FINE Final Output** (Garder - NÃ©cessaire)
**Fichiers:** `src/core/inference/dfine_infer.py`  
**Lignes:** 178, 243  
**Justification:** Conversion finale pour rÃ©sultat Slicer - appropriÃ©e
```python
return box_xyxy.to(dtype=torch.float32).cpu().numpy(), conf  # âœ… Final output OK
```

## ğŸ”„ ChaÃ®nes de Conversions DÃ©tectÃ©es

### ChaÃ®ne ProblÃ©matique IdentifiÃ©e:
```
orchestrator.py:88   â†’  arr.detach().cpu().numpy()     (GPUâ†’CPU)
                     â†’  [passage vers SAM]
mobile_sam/predictor.py  â†’  masks.detach().cpu().numpy()  (GPUâ†’CPU)
```

**ProblÃ¨me:** Double transfert GPUâ†’CPU au lieu d'une pipeline entiÃ¨rement GPU

## ğŸ’¡ Plan de Refactor RecommandÃ©

### Phase 1: Optimisations Critiques (P1)
1. **Modifier MobileSAM Predictor**
   - Retourner tenseurs GPU au lieu de NumPy arrays
   - DiffÃ©rer `.cpu().numpy()` au moment du `ResultPacket`
   
2. **Pipeline GPU-to-GPU pour SAM**
   - Ã‰liminer conversion dans `orchestrator.py:88`  
   - Configurer SAM pour accepter tenseurs GPU directement

### Phase 2: Optimisations Moyennes (P2)
3. **Nettoyer D-FINE Debug**
   - Supprimer `frame_cpu` si debug uniquement
   
4. **Optimiser Hungarian Matching**
   - Investiguer si matching peut rester sur GPU

### Phase 3: Consolidation Finale
5. **Architecture GPU-Resident**
   ```python
   # Objectif: Pipeline entiÃ¨rement GPU jusqu'Ã  ResultPacket
   D-FINE (GPU) â†’ SAM (GPU) â†’ PostProcess (GPU) â†’ ResultPacket.cpu().numpy()
   ```

## ğŸ¯ Objectif Final

### Pipeline OptimisÃ©e Cible:
```
[Input Image] â†’ GPU tensor
    â†“
[D-FINE] â†’ GPU tensors (bbox, scores)
    â†“  
[SAM] â†’ GPU tensors (masks, iou)
    â†“
[Post-processing] â†’ GPU tensors
    â†“
[ResultPacket crÃ©ation] â†’ âš¡ UN SEUL .cpu().numpy() final
```

### BÃ©nÃ©fices Attendus:
- **RÃ©duction transferts:** 4â†’1 conversions par frame
- **Latence rÃ©duite:** Ã‰limination GPUâ†”CPU overhead  
- **DÃ©bit amÃ©liorÃ©:** Pipeline continue sur GPU
- **MÃ©moire optimisÃ©e:** Moins de copies temporaires

## âœ… CritÃ¨res de Validation

- [ ] MobileSAM retourne tenseurs GPU
- [ ] Orchestrator passe tenseurs GPU Ã  SAM  
- [ ] Un seul `.cpu().numpy()` final dans ResultPacket
- [ ] Tests de rÃ©gression passent
- [ ] Benchmarks montrent amÃ©lioration latence >20%

## ğŸ“‹ Actions ImmÃ©diates

1. **Modifier** `mobile_sam/predictor.py` pour retourner tenseurs
2. **Analyser** si SAM peut traiter input GPU directement
3. **Tester** impact sur latence avec profiling dÃ©taillÃ©
4. **ImplÃ©menter** conversion unique finale

---
**ğŸ En rÃ©sumÃ©:** 4 conversions critiques identifiÃ©es, plan de refactor vers pipeline GPU-resident prÃªt Ã  implÃ©menter.